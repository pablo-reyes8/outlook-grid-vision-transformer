{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":28376,"sourceType":"datasetVersion","datasetId":22090},{"sourceId":285982,"sourceType":"datasetVersion","datasetId":6057}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms\nfrom torchvision.transforms import RandAugment\n\ndef get_cifar100_datasets(\n    data_dir: str = \"./data\",\n    val_split: float = 0.0,\n    ra_num_ops: int = 2,\n    ra_magnitude: int = 7,\n    random_erasing_p: float = 0.25,\n    erasing_scale=(0.02, 0.20),\n    erasing_ratio=(0.3, 3.3),\n    img_size: int = 32,):\n\n    \"\"\"\n    CIFAR-100 datasets con augmentations \"mix-friendly\":\n    diseñadas para complementar Mixup/CutMix (en el loop) sin pasarse.\n\n    img_size:\n      - 32 (default): CIFAR nativo.\n      - >32: upsample (p.ej. 64) para experimentos (más tokens/compute).\n    \"\"\"\n    if img_size < 32:\n        raise ValueError(f\"img_size must be >= 32 for CIFAR-100. Got {img_size}.\")\n\n    cifar100_mean = (0.5071, 0.4867, 0.4408)\n    cifar100_std  = (0.2675, 0.2565, 0.2761)\n\n    # Si subimos resolución, primero hacemos resize y adaptamos crop/padding.\n    # Padding recomendado proporcional: 32->4, 64->8, etc.\n\n    crop_padding = max(4, img_size // 8)\n\n    train_ops = []\n    if img_size != 32:\n        train_ops.append(transforms.Resize(img_size, interpolation=transforms.InterpolationMode.BICUBIC))\n\n    train_ops += [\n        transforms.RandomCrop(img_size, padding=crop_padding),\n        transforms.RandomHorizontalFlip(),\n        RandAugment(num_ops=ra_num_ops, magnitude=ra_magnitude),\n        transforms.ToTensor(),\n        transforms.Normalize(cifar100_mean, cifar100_std),\n        transforms.RandomErasing(\n            p=random_erasing_p,\n            scale=erasing_scale,\n            ratio=erasing_ratio,\n            value=\"random\",),]\n\n    train_transform = transforms.Compose(train_ops)\n\n    test_ops = []\n    if img_size != 32:\n        test_ops.append(transforms.Resize(img_size, interpolation=transforms.InterpolationMode.BICUBIC))\n\n    test_ops += [\n        transforms.ToTensor(),\n        transforms.Normalize(cifar100_mean, cifar100_std),]\n\n    test_transform = transforms.Compose(test_ops)\n\n    full_train_dataset = datasets.CIFAR100(\n        root=data_dir, train=True, download=True, transform=train_transform)\n\n    test_dataset = datasets.CIFAR100(\n        root=data_dir, train=False, download=True, transform=test_transform)\n\n    if val_split > 0.0:\n        n_total = len(full_train_dataset)\n        n_val = int(n_total * val_split)\n        n_train = n_total - n_val\n        train_dataset, val_dataset = random_split(\n            full_train_dataset,\n            [n_train, n_val],\n            generator=torch.Generator().manual_seed(7),)\n\n    else:\n        train_dataset = full_train_dataset\n        val_dataset = None\n\n    return train_dataset, val_dataset, test_dataset\n\n\ndef get_cifar100_dataloaders(\n    batch_size: int = 128,\n    data_dir: str = \"./data\",\n    num_workers: int = 2,\n    val_split: float = 0.0,\n    pin_memory: bool = True,\n    ra_num_ops: int = 2,\n    ra_magnitude: int = 7,\n    random_erasing_p: float = 0.25,\n    img_size: int = 32,):\n    \"\"\"\n    Dataloaders CIFAR-100 listos para entrenar con Mixup/CutMix en el loop.\n    Augmentations no tan agresivas.\n\n    img_size:\n      - 32 (default): CIFAR nativo.\n      - 64: experimento de upsample (ojo: más compute).\n    \"\"\"\n    train_ds, val_ds, test_ds = get_cifar100_datasets(\n        data_dir=data_dir,\n        val_split=val_split,\n        ra_num_ops=ra_num_ops,\n        ra_magnitude=ra_magnitude,\n        random_erasing_p=random_erasing_p,\n        img_size=img_size,)\n\n    train_loader = DataLoader(\n        train_ds,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        persistent_workers=(num_workers > 0),)\n\n    val_loader = None\n    if val_ds is not None:\n        val_loader = DataLoader(\n            val_ds,\n            batch_size=batch_size,\n            shuffle=False,\n            num_workers=num_workers,\n            pin_memory=pin_memory,\n            persistent_workers=(num_workers > 0),)\n\n    test_loader = DataLoader(\n        test_ds,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        persistent_workers=(num_workers > 0),)\n\n    return train_loader, val_loader, test_loader","metadata":{"id":"2Szc_5HDk-up","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T22:57:46.676338Z","iopub.execute_input":"2026-01-06T22:57:46.676554Z","iopub.status.idle":"2026-01-06T22:57:55.644059Z","shell.execute_reply.started":"2026-01-06T22:57:46.676536Z","shell.execute_reply":"2026-01-06T22:57:55.643481Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"train_loader, val_loader, test_loader = get_cifar100_dataloaders(\n    batch_size=64,\n    data_dir=\"./data/cifar100\",\n    num_workers=2,\n    val_split=0.1,\n    img_size=64)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gcvYzk_fX9zK","outputId":"3df751a9-f620-4a55-93fc-b9d47df374f7","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T23:04:05.121365Z","iopub.execute_input":"2026-01-06T23:04:05.122009Z","iopub.status.idle":"2026-01-06T23:04:06.839053Z","shell.execute_reply.started":"2026-01-06T23:04:05.121982Z","shell.execute_reply":"2026-01-06T23:04:06.838344Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nfrom torchvision.utils import make_grid\nfrom torchvision import datasets\nfrom collections import Counter, defaultdict\nimport math\n\nCIFAR100_MEAN = (0.5071, 0.4867, 0.4408)\nCIFAR100_STD  = (0.2675, 0.2565, 0.2761)\n\n\n\ndef describe_loader(loader, name=\"loader\", max_batches_for_stats=50):\n    ds = loader.dataset\n    n = len(ds)\n\n    print(\"\\n\" + \"=\"*90)\n    print(f\"{name.upper()} SUMMARY\")\n    print(\"=\"*90)\n\n    print(f\"Dataset type        : {type(ds).__name__}\")\n    if hasattr(ds, \"dataset\") and hasattr(ds, \"indices\"):\n        print(f\"  ↳ Wrapped dataset  : {type(ds.dataset).__name__} (Subset-like)\")\n        print(f\"  ↳ Subset size      : {len(ds.indices)}\")\n\n    print(f\"Num samples         : {n}\")\n    print(f\"Batch size          : {getattr(loader, 'batch_size', None)}\")\n    print(f\"Num workers         : {getattr(loader, 'num_workers', None)}\")\n    print(f\"Pin memory          : {getattr(loader, 'pin_memory', None)}\")\n    print(f\"Drop last           : {getattr(loader, 'drop_last', None)}\")\n\n    sampler = getattr(loader, \"sampler\", None)\n    sampler_name = type(sampler).__name__ if sampler is not None else None\n    print(f\"Sampler             : {sampler_name}\")\n\n    num_batches = len(loader)\n    bs = loader.batch_size if loader.batch_size is not None else \"?\"\n    approx_batches = math.ceil(n / loader.batch_size) if loader.batch_size else \"?\"\n    print(f\"len(loader) (#batches): {num_batches} (≈ ceil({n}/{bs}) = {approx_batches})\")\n\n    x, y = next(iter(loader))\n    print(\"\\nFirst batch:\")\n    print(f\"  x.shape           : {tuple(x.shape)}\")\n    print(f\"  y.shape           : {tuple(y.shape)}\")\n    print(f\"  x.dtype           : {x.dtype}\")\n    print(f\"  y.dtype           : {y.dtype}\")\n    print(f\"  x.min/max         : {float(x.min()):.4f} / {float(x.max()):.4f}\")\n    print(f\"  y.min/max         : {int(y.min())} / {int(y.max())}\")\n    print(f\"  unique labels (batch): {len(torch.unique(y))}\")\n    print(f\"\\nQuick stats over up to {max_batches_for_stats} batches:\")\n\n    n_seen = 0\n    sum_ = 0.0\n    sumsq_ = 0.0\n    class_counts = Counter()\n\n    for bi, (xb, yb) in enumerate(loader):\n        if bi >= max_batches_for_stats:\n            break\n        xb = xb.float()\n        n_pix = xb.numel()\n        sum_ += xb.sum().item()\n        sumsq_ += (xb * xb).sum().item()\n        n_seen += n_pix\n\n        class_counts.update(yb.tolist())\n\n    mean = sum_ / max(1, n_seen)\n    var = (sumsq_ / max(1, n_seen)) - mean**2\n    std = math.sqrt(max(0.0, var))\n\n    print(f\"  Approx mean        : {mean:.6f}\")\n    print(f\"  Approx std         : {std:.6f}\")\n    top5 = class_counts.most_common(5)\n    print(f\"  Seen label counts  : {len(class_counts)} classes (in sampled batches)\")\n    print(f\"  Top-5 labels       : {top5}\")\n\n    targets = None\n    if hasattr(ds, \"targets\"):\n        targets = ds.targets\n    elif hasattr(ds, \"labels\"):\n        targets = ds.labels\n    elif hasattr(ds, \"dataset\") and hasattr(ds.dataset, \"targets\") and hasattr(ds, \"indices\"):\n        base_targets = ds.dataset.targets\n        targets = [base_targets[i] for i in ds.indices]\n\n    if targets is not None:\n        full_counts = Counter(list(map(int, targets)))\n        k = len(full_counts)\n        print(f\"\\nFull dataset label distribution:\")\n        print(f\"  #classes detected  : {k}\")\n        if k > 0:\n            mn = min(full_counts.values())\n            mx = max(full_counts.values())\n            print(f\"  min/max per class  : {mn} / {mx}\")\n            first10 = sorted(full_counts.items(), key=lambda t: t[0])[:10]\n            print(f\"  first 10 classes   : {first10}\")\n            if mn == mx:\n                print(\"  balance check      : perfectly balanced\")\n            else:\n                print(\"  balance check      : not perfectly balanced\")\n    else:\n        print(\"\\nFull dataset label distribution: (couldn't find targets/labels attribute)\")\n\n    print(\"=\"*90)\n\n\ndescribe_loader(train_loader, \"train_loader\", max_batches_for_stats=50)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CUbtacnUYMKF","outputId":"ddf22534-e60c-4c8d-bcd1-5a623b1a8545","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T22:47:13.136519Z","iopub.execute_input":"2026-01-06T22:47:13.136767Z","iopub.status.idle":"2026-01-06T22:47:17.578274Z","shell.execute_reply.started":"2026-01-06T22:47:13.136740Z","shell.execute_reply":"2026-01-06T22:47:17.576966Z"}},"outputs":[{"name":"stdout","text":"\n==========================================================================================\nTRAIN_LOADER SUMMARY\n==========================================================================================\nDataset type        : Subset\n  ↳ Wrapped dataset  : CIFAR100 (Subset-like)\n  ↳ Subset size      : 45000\nNum samples         : 45000\nBatch size          : 128\nNum workers         : 2\nPin memory          : True\nDrop last           : False\nSampler             : RandomSampler\nlen(loader) (#batches): 352 (≈ ceil(45000/128) = 352)\n\nFirst batch:\n  x.shape           : (128, 3, 64, 64)\n  y.shape           : (128,)\n  x.dtype           : torch.float32\n  y.dtype           : torch.int64\n  x.min/max         : -4.1116 / 4.1302\n  y.min/max         : 0 / 98\n  unique labels (batch): 77\n\nQuick stats over up to 50 batches:\n  Approx mean        : -0.282753\n  Approx std         : 1.119806\n  Seen label counts  : 100 classes (in sampled batches)\n  Top-5 labels       : [(20, 80), (15, 77), (5, 76), (80, 76), (11, 76)]\n\nFull dataset label distribution:\n  #classes detected  : 100\n  min/max per class  : 436 / 463\n  first 10 classes   : [(0, 457), (1, 439), (2, 448), (3, 455), (4, 446), (5, 447), (6, 451), (7, 457), (8, 448), (9, 453)]\n  balance check      : not perfectly balanced\n==========================================================================================\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"\n\ndef unnormalize(images: torch.Tensor,\n                mean=CIFAR100_MEAN,\n                std=CIFAR100_STD):\n    \"\"\"\n    Des-normaliza un batch de imágenes.\n    images: tensor [B, C, H, W] normalizado.\n    \"\"\"\n    mean = torch.tensor(mean, device=images.device).view(1, -1, 1, 1)\n    std = torch.tensor(std, device=images.device).view(1, -1, 1, 1)\n    return images * std + mean\n\n\ndef show_batch(images: torch.Tensor,\n               labels: torch.Tensor,\n               class_names=None,\n               n: int = 8):\n    \"\"\"\n    Muestra las primeras n imágenes de un batch con sus labels.\n\n    Args:\n        images: tensor [B, C, H, W] (normalizado).\n        labels: tensor [B].\n        class_names: lista de nombres de clases (len = 100).\n        n: cuántas imágenes mostrar (en una fila).\n    \"\"\"\n    images = images[:n].cpu()\n    labels = labels[:n].cpu()\n    images_unnorm = unnormalize(images)\n\n    grid = make_grid(images_unnorm, nrow=n, padding=2)\n    npimg = grid.permute(1, 2, 0).numpy()\n\n    plt.figure(figsize=(2 * n, 2.5))\n    plt.imshow(npimg)\n    plt.axis(\"off\")\n\n    if class_names is not None:\n        title = \" | \".join(class_names[int(lbl)] for lbl in labels)\n        plt.title(title, fontsize=10)\n    plt.show()\n\ncifar100_train = datasets.CIFAR100(\n    root=\"./data/cifar100\",\n    train=True,\n    download=False)\n\nclass_names = cifar100_train.classes\nimages, labels = next(iter(train_loader))\nshow_batch(images, labels, class_names=class_names, n=8)","metadata":{"id":"u08t_5gzYXoN","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T22:59:02.916498Z","iopub.execute_input":"2026-01-06T22:59:02.916793Z","iopub.status.idle":"2026-01-06T22:59:02.942678Z","shell.execute_reply.started":"2026-01-06T22:59:02.916769Z","shell.execute_reply":"2026-01-06T22:59:02.940941Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/3000145677.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m def unnormalize(images: torch.Tensor,\n\u001b[0;32m----> 2\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCIFAR100_MEAN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                 std=CIFAR100_STD):\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0mDes\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnormaliza\u001b[0m \u001b[0mun\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0mde\u001b[0m \u001b[0mimágenes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'CIFAR100_MEAN' is not defined"],"ename":"NameError","evalue":"name 'CIFAR100_MEAN' is not defined","output_type":"error"}],"execution_count":3},{"cell_type":"markdown","source":"---\n","metadata":{"id":"XnzAvcYaY_rK"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass LayerNorm2d(nn.Module):\n    \"\"\"\n    LayerNorm sobre el canal C para tensores [B, C, H, W].\n    Normaliza por posición (h,w) a través de C (como LN de ViT).\n    \"\"\"\n    def __init__(self, num_channels: int, eps: float = 1e-6, affine: bool = True):\n        super().__init__()\n        self.ln = nn.LayerNorm(num_channels, eps=eps, elementwise_affine=affine)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        # x: [B, C, H, W] -> [B, H, W, C] -> LN -> [B, C, H, W]\n        x = x.permute(0, 2, 3, 1).contiguous()\n        x = self.ln(x)\n        x = x.permute(0, 3, 1, 2).contiguous()\n        return x\n\n\nclass MLP2d(nn.Module):\n    \"\"\"\n    FFN estilo Transformer pero en mapas: 1x1 conv expand/contract.\n    x: [B,C,H,W] -> [B,C,H,W]\n    \"\"\"\n    def __init__(self, dim: int, mlp_ratio: float = 4.0, drop: float = 0.0):\n        super().__init__()\n        hidden = int(dim * mlp_ratio)\n        self.fc1 = nn.Conv2d(dim, hidden, kernel_size=1, bias=True)\n        self.act = nn.GELU()\n        self.fc2 = nn.Conv2d(hidden, dim, kernel_size=1, bias=True)\n        self.drop = nn.Dropout(drop)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.fc1(x)\n        x = self.act(x)\n        x = self.drop(x)\n        x = self.fc2(x)\n        x = self.drop(x)\n        return x\n\n\nclass OutlookAttention2d(nn.Module):\n    \"\"\"\n    OutlookAttention on [B,C,H,W] (NCHW) with dynamic local aggregation.\n    \"\"\"\n    def __init__(\n        self,\n        dim: int,\n        num_heads: int = 6,\n        kernel_size: int = 3,\n        stride: int = 1,\n        attn_drop: float = 0.0,\n        proj_drop: float = 0.0,\n        qkv_bias: bool = True,\n    ):\n        super().__init__()\n        assert dim % num_heads == 0, \"dim must be divisible by num_heads\"\n        if kernel_size <= 0 or kernel_size % 2 == 0:\n            raise ValueError(\"kernel_size must be odd and >0 (e.g., 3,5,7)\")\n        if stride <= 0:\n            raise ValueError(\"stride must be > 0\")\n\n        self.dim = dim\n        self.num_heads = num_heads\n        self.head_dim = dim // num_heads\n        self.kernel_size = kernel_size\n        self.stride = stride\n\n        kk = kernel_size * kernel_size\n        bias = bool(qkv_bias)\n\n        # logits per spatial position\n        self.attn = nn.Conv2d(dim, num_heads * kk, kernel_size=1, bias=bias)\n        # values\n        self.v = nn.Conv2d(dim, dim, kernel_size=1, bias=bias)\n\n        self.attn_drop = nn.Dropout(attn_drop)\n        self.proj = nn.Conv2d(dim, dim, kernel_size=1, bias=True)\n        self.proj_drop = nn.Dropout(proj_drop)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        B, C, H, W = x.shape\n        k = self.kernel_size\n        s = self.stride\n        heads = self.num_heads\n        hd = self.head_dim\n        kk = k * k\n\n        # attn logits: [B, heads*kk, H, W] -> (optional) pool if stride>1\n        a = self.attn(x)\n        if s > 1:\n            a = F.avg_pool2d(a, kernel_size=s, stride=s)\n        _, _, Hs, Ws = a.shape\n\n        # [B, heads, kk, Hs, Ws] -> [B, Hs*Ws, heads, kk]\n        a = a.view(B, heads, kk, Hs, Ws).flatten(3).permute(0, 3, 1, 2).contiguous()\n        a = F.softmax(a, dim=-1)\n        a = self.attn_drop(a)\n\n        # values + unfold neighborhoods\n        v = self.v(x)  # [B,C,H,W]\n        pad = k // 2\n        v_unf = F.unfold(v, kernel_size=k, padding=pad, stride=s)  # [B, C*kk, Hs*Ws]\n\n        # -> [B, Hs*Ws, heads, hd, kk]\n        v_unf = v_unf.view(B, heads, hd, kk, Hs * Ws).permute(0, 4, 1, 2, 3).contiguous()\n\n        # weighted sum over kk\n        y = (v_unf * a.unsqueeze(3)).sum(dim=-1)  # [B, Hs*Ws, heads, hd]\n        y = y.permute(0, 2, 3, 1).contiguous().view(B, C, Hs, Ws)\n\n        y = self.proj(y)\n        y = self.proj_drop(y)\n        return y","metadata":{"id":"ll76DN0Hx6FR","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T22:59:35.730326Z","iopub.execute_input":"2026-01-06T22:59:35.730984Z","iopub.status.idle":"2026-01-06T22:59:35.746313Z","shell.execute_reply.started":"2026-01-06T22:59:35.730957Z","shell.execute_reply":"2026-01-06T22:59:35.745769Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class DropPath(nn.Module):\n    \"\"\"\n    DropPath / Stochastic Depth. Works for any tensor shape with batch in dim 0.\n    \"\"\"\n    def __init__(self, drop_prob: float = 0.0):\n        super().__init__()\n        self.drop_prob = float(drop_prob)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        if self.drop_prob == 0.0 or (not self.training):\n            return x\n        keep_prob = 1.0 - self.drop_prob\n        # shape: [B, 1, 1, 1, ...]\n        shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n        mask = torch.empty(shape, device=x.device, dtype=x.dtype).bernoulli_(keep_prob)\n        return x * mask / keep_prob\n\n\nclass LayerNorm2d(nn.Module):\n    def __init__(self, C, eps=1e-6):\n        super().__init__()\n        self.ln = nn.LayerNorm(C, eps=eps)\n\n    def forward(self, x):\n        # [B,C,H,W] -> [B,H,W,C] -> LN -> [B,C,H,W]\n        return self.ln(x.permute(0,2,3,1)).permute(0,3,1,2).contiguous()\n\ndef _make_activation(act: str) -> nn.Module:\n    act = act.lower()\n    if act == \"silu\":\n        return nn.SiLU(inplace=True)\n    if act == \"relu\":\n        return nn.ReLU(inplace=True)\n    if act == \"gelu\":\n        return nn.GELU()\n    raise ValueError(f\"Unknown activation '{act}'. Use one of: silu|gelu|relu\")\n\n\nclass MLP2d(nn.Module):\n    def __init__(self, dim, mlp_ratio=4.0, drop=0.0, act=\"gelu\"):\n        super().__init__()\n        hidden = max(1, int(dim * mlp_ratio))\n        self.fc1 = nn.Conv2d(dim, hidden, 1)\n        self.act = _make_activation(act)\n        self.drop1 = nn.Dropout(drop)\n        self.fc2 = nn.Conv2d(hidden, dim, 1)\n        self.drop2 = nn.Dropout(drop)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act(x)\n        x = self.drop1(x)\n        x = self.fc2(x)\n        x = self.drop2(x)\n        return x\n\n\nclass OutlookerBlock2d(nn.Module):\n    \"\"\"\n    x (NCHW) -> LN2d -> OutlookAttention2d -> DropPath + res\n             -> LN2d -> MLP2d            -> DropPath + res\n    \"\"\"\n    def __init__(\n        self,\n        dim: int,\n        num_heads: int,\n        kernel_size: int = 3,\n        stride: int = 1,\n        mlp_ratio: float = 2.0,\n        attn_drop: float = 0.0,\n        proj_drop: float = 0.0,\n        drop_path: float = 0.0,\n        mlp_drop: float = 0.0,\n        act: str = \"gelu\",\n        norm_eps: float = 1e-6):\n\n        super().__init__()\n        self.norm1 = LayerNorm2d(dim, eps=norm_eps)\n        self.attn = OutlookAttention2d(\n            dim=dim,\n            num_heads=num_heads,\n            kernel_size=kernel_size,\n            stride=stride,\n            attn_drop=attn_drop,\n            proj_drop=proj_drop)\n\n        self.dp1 = DropPath(drop_path) if drop_path > 0 else nn.Identity()\n\n        self.norm2 = LayerNorm2d(dim, eps=norm_eps)\n        self.mlp = MLP2d(dim=dim, mlp_ratio=mlp_ratio, drop=mlp_drop, act=act)\n        self.dp2 = DropPath(drop_path) if drop_path > 0 else nn.Identity()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = x + self.dp1(self.attn(self.norm1(x)))\n        x = x + self.dp2(self.mlp(self.norm2(x)))\n        return x","metadata":{"id":"At2AT2hN0hw8","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T22:59:38.148317Z","iopub.execute_input":"2026-01-06T22:59:38.149025Z","iopub.status.idle":"2026-01-06T22:59:38.160520Z","shell.execute_reply.started":"2026-01-06T22:59:38.148993Z","shell.execute_reply":"2026-01-06T22:59:38.159748Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"x = torch.randn(8, 96, 16, 16)\nblk = OutlookerBlock2d(dim=96, num_heads=6, kernel_size=3, stride=1)\ny = blk(x)\nprint(x.shape, y.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_InvOziU0nKb","outputId":"17a209dc-f3c8-4129-d847-0592f357eeaa"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([8, 96, 16, 16]) torch.Size([8, 96, 16, 16])\n"]}],"execution_count":null},{"cell_type":"code","source":"from typing import Literal\nfrom dataclasses import dataclass\n\nclass SqueezeExcite(nn.Module):\n    def __init__(self, channels: int, se_ratio: float = 0.25, act: str = \"silu\"):\n        super().__init__()\n        if not (0.0 < se_ratio <= 1.0):\n            raise ValueError(\"se_ratio must be in (0, 1].\")\n\n        hidden = max(1, int(channels * se_ratio))\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.fc1 = nn.Conv2d(channels, hidden, kernel_size=1, bias=True)\n        self.act = _make_activation(act)\n        self.fc2 = nn.Conv2d(hidden, channels, kernel_size=1, bias=True)\n        self.gate = nn.Sigmoid()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        s = self.pool(x)\n        s = self.fc1(s)\n        s = self.act(s)\n        s = self.fc2(s)\n        return x * self.gate(s)\n\n\nActType = Literal[\"silu\", \"gelu\", \"relu\"]\n\n@dataclass(frozen=True)\nclass MBConvConfig:\n    expand_ratio: float = 4.0\n    se_ratio: float = 0.25\n    act: ActType = \"silu\"\n    use_bn: bool = True\n    drop_path: float = 0.0\n\nclass MBConv(nn.Module):\n    \"\"\"\n    MBConv block (NCHW):\n      Expand 1x1 -> Depthwise 3x3 -> SE -> Project 1x1\n      Residual if stride=1 and in_ch==out_ch\n    \"\"\"\n    def __init__(self, in_ch: int, out_ch: int, stride: int = 1, cfg: MBConvConfig = MBConvConfig()):\n        super().__init__()\n        if in_ch <= 0 or out_ch <= 0:\n            raise ValueError(\"in_ch and out_ch must be > 0\")\n        if stride not in (1, 2):\n            raise ValueError(\"stride must be 1 or 2\")\n\n        self.in_ch = in_ch\n        self.out_ch = out_ch\n        self.stride = stride\n\n        bn = (lambda c: nn.BatchNorm2d(c)) if cfg.use_bn else (lambda c: nn.Identity())\n        act = _make_activation(cfg.act)\n\n        mid_ch = max(1, int(round(in_ch * cfg.expand_ratio)))\n\n        if mid_ch != in_ch:\n            self.expand = nn.Sequential(\n                nn.Conv2d(in_ch, mid_ch, kernel_size=1, bias=not cfg.use_bn),\n                bn(mid_ch),\n                act,)\n\n        else:\n            self.expand = nn.Identity()\n\n        self.depthwise = nn.Sequential(\n            nn.Conv2d(mid_ch, mid_ch, kernel_size=3, stride=stride, padding=1,\n                      groups=mid_ch, bias=not cfg.use_bn),\n            bn(mid_ch),\n            act,)\n\n        self.se = SqueezeExcite(mid_ch, se_ratio=cfg.se_ratio, act=cfg.act) if cfg.se_ratio > 0 else nn.Identity()\n\n        self.project = nn.Sequential(\n            nn.Conv2d(mid_ch, out_ch, kernel_size=1, bias=not cfg.use_bn),\n            bn(out_ch),)\n\n        self.use_res = (stride == 1 and in_ch == out_ch)\n        self.drop_path = DropPath(cfg.drop_path) if (cfg.drop_path and cfg.drop_path > 0) else nn.Identity()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        out = self.expand(x)\n        out = self.depthwise(out)\n        out = self.se(out)\n        out = self.project(out)\n\n        if self.use_res:\n            out = x + self.drop_path(out)\n        return out\n\nclass LayerNorm2d(nn.Module):\n    \"\"\"\n    LayerNorm over channels for [B,C,H,W] by converting to BHWC temporarily.\n    \"\"\"\n    def __init__(self, channels: int, eps: float = 1e-6):\n        super().__init__()\n        self.ln = nn.LayerNorm(channels, eps=eps)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        # [B,C,H,W] -> [B,H,W,C] -> LN -> [B,C,H,W]\n        return self.ln(x.permute(0, 2, 3, 1)).permute(0, 3, 1, 2).contiguous()\n\n","metadata":{"id":"fV4IUh9G222y","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T22:59:39.987421Z","iopub.execute_input":"2026-01-06T22:59:39.988220Z","iopub.status.idle":"2026-01-06T22:59:40.010366Z","shell.execute_reply.started":"2026-01-06T22:59:39.988172Z","shell.execute_reply":"2026-01-06T22:59:40.009585Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"---","metadata":{"id":"WYQXRj5I3aIq"}},{"cell_type":"code","source":"def grid_partition(x: torch.Tensor, grid_size: int):\n    if x.ndim != 4:\n        raise ValueError(f\"Expected x.ndim==4 (BHWC). Got shape {tuple(x.shape)}\")\n    B, H, W, C = x.shape\n    g = grid_size\n    if g <= 0:\n        raise ValueError(\"grid_size must be > 0\")\n    if (H % g) != 0 or (W % g) != 0:\n        raise ValueError(f\"H and W must be divisible by grid_size. Got H={H}, W={W}, g={g}\")\n\n    Hg, Wg = H // g, W // g\n    x = x.view(B, Hg, g, Wg, g, C)  # [B, Hg, g, Wg, g, C]\n    grids = x.permute(0, 2, 4, 1, 3, 5).contiguous().view(B * g * g, Hg, Wg, C)\n    meta = (B, H, W, C, g)\n    return grids, meta\n\n\ndef grid_unpartition(grids: torch.Tensor, meta) -> torch.Tensor:\n    if grids.ndim != 4:\n        raise ValueError(f\"Expected grids.ndim==4. Got shape {tuple(grids.shape)}\")\n    B, H, W, C, g = meta\n    Hg, Wg = H // g, W // g\n    if grids.shape[0] != B * g * g:\n        raise ValueError(f\"grids.shape[0] must be B*g*g = {B*g*g}. Got {grids.shape[0]}\")\n    if grids.shape[1] != Hg or grids.shape[2] != Wg or grids.shape[3] != C:\n        raise ValueError(f\"grids shape mismatch. Expected (*,{Hg},{Wg},{C}) got {tuple(grids.shape)}\")\n\n    x = grids.view(B, g, g, Hg, Wg, C)\n    x = x.permute(0, 3, 1, 4, 2, 5).contiguous().view(B, H, W, C)\n    return x","metadata":{"id":"-3CfVPEG3Z0Q","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T22:59:41.766185Z","iopub.execute_input":"2026-01-06T22:59:41.766691Z","iopub.status.idle":"2026-01-06T22:59:41.773615Z","shell.execute_reply.started":"2026-01-06T22:59:41.766666Z","shell.execute_reply":"2026-01-06T22:59:41.772933Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from dataclasses import dataclass\nfrom typing import Literal\n\n\nAttnMode = Literal[\"grid\"]\n\n@dataclass(frozen=True)\nclass AttentionConfig:\n    dim: int\n    num_heads: int\n    qkv_bias: bool = True\n    attn_drop: float = 0.0\n    proj_drop: float = 0.0\n\n\n@dataclass(frozen=True)\nclass LocalAttention2DConfig:\n    mode: AttnMode\n    dim: int\n    num_heads: int\n    grid_size: int\n    window_size: int = 1\n    qkv_bias: bool = True\n    attn_drop: float = 0.0\n    proj_drop: float = 0.0\n\n\nclass MultiHeadSelfAttention(nn.Module):\n    \"\"\"\n    Standard MHSA for token sequences.\n\n    Input:  x [B, N, C]\n    Output: y [B, N, C]\n\n    Works for both window and grid partitions because both can be flattened to [Bgrp, N, C].\n    \"\"\"\n\n    def __init__(self, cfg: AttentionConfig):\n        super().__init__()\n        if cfg.dim <= 0:\n            raise ValueError(\"cfg.dim must be > 0\")\n        if cfg.num_heads <= 0:\n            raise ValueError(\"cfg.num_heads must be > 0\")\n        if cfg.dim % cfg.num_heads != 0:\n            raise ValueError(f\"dim ({cfg.dim}) must be divisible by num_heads ({cfg.num_heads})\")\n\n        self.dim = cfg.dim\n        self.num_heads = cfg.num_heads\n        self.head_dim = cfg.dim // cfg.num_heads\n        self.scale = self.head_dim ** -0.5\n\n        self.qkv = nn.Linear(cfg.dim, 3 * cfg.dim, bias=cfg.qkv_bias)\n        self.attn_drop = nn.Dropout(cfg.attn_drop)\n        self.proj = nn.Linear(cfg.dim, cfg.dim, bias=True)\n        self.proj_drop = nn.Dropout(cfg.proj_drop)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        if x.ndim != 3:\n            raise ValueError(f\"Expected x.ndim==3 with shape [B, N, C]. Got {tuple(x.shape)}\")\n        B, N, C = x.shape\n        if C != self.dim:\n            raise ValueError(f\"Expected last dim C={self.dim}. Got C={C}\")\n\n        # qkv: [B, N, 3C] -> [B, N, 3, heads, head_dim] -> [3, B, heads, N, head_dim]\n        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n        q, k, v = qkv[0], qkv[1], qkv[2]\n\n        # attention: [B, heads, N, N]\n        attn = (q @ k.transpose(-2, -1)) * self.scale\n        attn = attn.softmax(dim=-1)\n        attn = self.attn_drop(attn)\n\n        # out: [B, heads, N, head_dim] -> [B, N, C]\n        out = (attn @ v).transpose(1, 2).reshape(B, N, C)\n        out = self.proj(out)\n        out = self.proj_drop(out)\n        return out\n\n\nclass LocalAttention2D(nn.Module):\n    \"\"\"\n    Grid attention wrapper.\n\n    Input/Output: x BHWC [B,H,W,C] -> [B,H,W,C]\n    \"\"\"\n    def __init__(self, cfg: LocalAttention2DConfig):\n        super().__init__()\n        if cfg.mode != \"grid\":\n            raise ValueError(\"This minimal version only supports mode='grid'\")\n        self.cfg = cfg\n        self.mhsa = MultiHeadSelfAttention(\n            AttentionConfig(\n                dim=cfg.dim,\n                num_heads=cfg.num_heads,\n                qkv_bias=cfg.qkv_bias,\n                attn_drop=cfg.attn_drop,\n                proj_drop=cfg.proj_drop,))\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        if x.ndim != 4:\n            raise ValueError(f\"Expected x.ndim==4 (BHWC). Got {tuple(x.shape)}\")\n        B, H, W, C = x.shape\n        if C != self.cfg.dim:\n            raise ValueError(f\"Expected C=={self.cfg.dim}. Got C={C}\")\n\n        g = self.cfg.grid_size\n        grids, meta = grid_partition(x, g)         # [B*g*g, Hg, Wg, C]\n        Bgrp, Hg, Wg, _ = grids.shape\n        tokens = grids.view(Bgrp, Hg * Wg, C)      # [Bgrp, N, C]\n        tokens = self.mhsa(tokens)\n        grids = tokens.view(Bgrp, Hg, Wg, C)\n        out = grid_unpartition(grids, meta)\n        return out","metadata":{"id":"vhrwKG8K3cJU","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T22:59:43.800823Z","iopub.execute_input":"2026-01-06T22:59:43.801399Z","iopub.status.idle":"2026-01-06T22:59:43.821617Z","shell.execute_reply.started":"2026-01-06T22:59:43.801375Z","shell.execute_reply":"2026-01-06T22:59:43.820452Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class MLP(nn.Module):\n    \"\"\"\n    MLP para BHWC: aplica sobre el último dim C.\n    x: [..., C] -> [..., C]\n    \"\"\"\n    def __init__(self, dim: int, mlp_ratio: float = 4.0, drop: float = 0.0, act: str = \"gelu\"):\n        super().__init__()\n        hidden = max(1, int(dim * mlp_ratio))\n        self.fc1 = nn.Linear(dim, hidden)\n        self.act = _make_activation(act)\n        self.drop1 = nn.Dropout(drop)\n        self.fc2 = nn.Linear(hidden, dim)\n        self.drop2 = nn.Dropout(drop)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        if x.shape[-1] != self.fc1.in_features:\n            raise ValueError(f\"MLP expected last dim={self.fc1.in_features}, got {x.shape[-1]}\")\n        x = self.fc1(x)\n        x = self.act(x)\n        x = self.drop1(x)\n        x = self.fc2(x)\n        x = self.drop2(x)\n        return x\n\n\nclass MaxOutBlock(nn.Module):\n    \"\"\"\n    Híbrido: Outlooker (local dinámico) -> MBConv -> Grid-MHSA -> MLP\n    Input/Output: [B, C, H, W]\n    \"\"\"\n    def __init__(self, cfg):\n        super().__init__()\n        C = cfg.dim\n\n        # Outlooker en NCHW\n        self.outlook = OutlookerBlock2d(\n            dim=C,\n            num_heads=cfg.outlook_heads,          # nuevo hyperparam\n            kernel_size=cfg.outlook_kernel,       # nuevo hyperparam\n            stride=1,\n            mlp_ratio=cfg.outlook_mlp_ratio,      # opcional, puedes fijar 0 o 2\n            attn_drop=cfg.attn_drop,\n            proj_drop=cfg.proj_drop,\n            mlp_drop=cfg.ffn_drop,\n            drop_path=cfg.drop_path,\n            act=cfg.mlp_act,)\n\n        # MBConv NCHW\n        self.mbconv = MBConv(\n            in_ch=C, out_ch=C, stride=1,\n            cfg=MBConvConfig(\n                expand_ratio=cfg.mbconv_expand_ratio,\n                se_ratio=cfg.mbconv_se_ratio,\n                act=cfg.mbconv_act,\n                use_bn=cfg.use_bn,\n                drop_path=0.0,\n            ),)\n\n        # Grid attention BHWC\n        self.norm2 = nn.LayerNorm(C)\n        self.grid_attn = LocalAttention2D(\n            LocalAttention2DConfig(\n                mode=\"grid\",\n                dim=C,\n                num_heads=cfg.num_heads,\n                window_size=cfg.window_size,\n                grid_size=cfg.grid_size,\n                qkv_bias=True,\n                attn_drop=cfg.attn_drop,\n                proj_drop=cfg.proj_drop,\n            ))\n        self.dp2 = DropPath(cfg.drop_path) if cfg.drop_path > 0 else nn.Identity()\n\n        # 4) MLP BHWC\n        self.norm3 = nn.LayerNorm(C)\n        self.mlp = MLP(dim=C, mlp_ratio=cfg.mlp_ratio, drop=cfg.ffn_drop, act=cfg.mlp_act)\n        self.dp3 = DropPath(cfg.drop_path) if cfg.drop_path > 0 else nn.Identity()\n\n    def forward(self, x):\n        B, C, H, W = x.shape\n\n        # Outlooker + MBConv (NCHW)\n        x = self.outlook(x)\n        x = self.mbconv(x)\n\n        # to BHWC for grid + mlp\n        x_bhwc = x.permute(0, 2, 3, 1).contiguous()\n\n        y = self.norm2(x_bhwc)\n        y = self.grid_attn(y)\n        x_bhwc = x_bhwc + self.dp2(y)\n\n        y = self.norm3(x_bhwc)\n        y = self.mlp(y)\n        x_bhwc = x_bhwc + self.dp3(y)\n\n        # back to NCHW\n        return x_bhwc.permute(0, 3, 1, 2).contiguous()","metadata":{"id":"V8D_s4nb18n2","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T22:59:46.051582Z","iopub.execute_input":"2026-01-06T22:59:46.052332Z","iopub.status.idle":"2026-01-06T22:59:46.063029Z","shell.execute_reply.started":"2026-01-06T22:59:46.052308Z","shell.execute_reply":"2026-01-06T22:59:46.062194Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Test del nuevo modelo","metadata":{"id":"YPvZ6KnH4SEG"}},{"cell_type":"code","source":"@dataclass\nclass DummyCfg:\n    dim: int = 96\n\n    # Outlooker\n    outlook_heads: int = 6\n    outlook_kernel: int = 3\n    outlook_mlp_ratio: float = 2.0\n\n    # MBConv\n    mbconv_expand_ratio: float = 4.0\n    mbconv_se_ratio: float = 0.25\n    mbconv_act: str = \"silu\"\n    use_bn: bool = True\n\n    # Grid MHSA\n    num_heads: int = 6\n    grid_size: int = 4\n    window_size: int = 8  # no se usa en grid-only, pero tu ctor lo pasa\n\n    # Drops\n    attn_drop: float = 0.0\n    proj_drop: float = 0.0\n    ffn_drop: float = 0.0\n    drop_path: float = 0.0\n\n    # MLP (BHWC)\n    mlp_ratio: float = 4.0\n    mlp_act: str = \"gelu\"","metadata":{"id":"Y9Hj9lsp4TqM","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T22:54:12.426163Z","iopub.execute_input":"2026-01-06T22:54:12.426454Z","iopub.status.idle":"2026-01-06T22:54:12.431947Z","shell.execute_reply.started":"2026-01-06T22:54:12.426412Z","shell.execute_reply":"2026-01-06T22:54:12.431377Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def _assert_shape(x: torch.Tensor, shape: tuple, name: str = \"tensor\"):\n    assert tuple(x.shape) == tuple(shape), f\"{name}: expected shape {shape}, got {tuple(x.shape)}\"\n\ndef _assert_ndim(x: torch.Tensor, ndim: int, name: str = \"tensor\"):\n    assert x.ndim == ndim, f\"{name}: expected ndim={ndim}, got ndim={x.ndim}, shape={tuple(x.shape)}\"\n\ndef _assert_finite(x: torch.Tensor, name: str = \"tensor\"):\n    assert torch.isfinite(x).all().item(), f\"{name}: found non-finite values (nan/inf)\"\n\ndef _assert_divisible_hw(H: int, W: int, g: int):\n    assert (H % g) == 0 and (W % g) == 0, f\"H,W must be divisible by grid_size g={g}. Got H={H}, W={W}\"\n","metadata":{"id":"vaIRHjm74Wd0"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@torch.no_grad()\ndef test_outlooker_stage(block: MaxOutBlock, x: torch.Tensor):\n    _assert_ndim(x, 4, \"x\")\n    B, C, H, W = x.shape\n    _assert_shape(x, (B, block.outlook.norm1.ln.normalized_shape[0], H, W), \"x (pre)\")  # C check\n\n    y = block.outlook(x)\n    _assert_shape(y, (B, C, H, W), \"outlook(x)\")\n    _assert_finite(y, \"outlook(x)\")\n    return y\n\n@torch.no_grad()\ndef test_mbconv_stage(block: MaxOutBlock, x: torch.Tensor):\n    B, C, H, W = x.shape\n    y = block.mbconv(x)\n    _assert_shape(y, (B, C, H, W), \"mbconv(x)\")\n    _assert_finite(y, \"mbconv(x)\")\n    return y\n\n\n@torch.no_grad()\ndef test_grid_stage(block: MaxOutBlock, x_nchw: torch.Tensor):\n    B, C, H, W = x_nchw.shape\n    x_bhwc = x_nchw.permute(0, 2, 3, 1).contiguous()\n    _assert_shape(x_bhwc, (B, H, W, C), \"x_bhwc\")\n\n    # divisibilidad\n    g = block.grid_attn.cfg.grid_size\n    _assert_divisible_hw(H, W, g)\n\n    y = block.norm2(x_bhwc)\n    _assert_shape(y, (B, H, W, C), \"norm2(x_bhwc)\")\n    y = block.grid_attn(y)\n    _assert_shape(y, (B, H, W, C), \"grid_attn(norm2(x_bhwc))\")\n    _assert_finite(y, \"grid_attn output\")\n\n    out = x_bhwc + block.dp2(y)\n    _assert_shape(out, (B, H, W, C), \"residual after grid\")\n    _assert_finite(out, \"after grid residual\")\n\n    return out  # BHWC\n\n\n@torch.no_grad()\ndef test_mlp_stage(block: MaxOutBlock, x_bhwc: torch.Tensor):\n    B, H, W, C = x_bhwc.shape\n\n    y = block.norm3(x_bhwc)\n    _assert_shape(y, (B, H, W, C), \"norm3(x_bhwc)\")\n    y = block.mlp(y)\n    _assert_shape(y, (B, H, W, C), \"mlp(norm3(x_bhwc))\")\n    _assert_finite(y, \"mlp output\")\n\n    out = x_bhwc + block.dp3(y)\n    _assert_shape(out, (B, H, W, C), \"residual after mlp\")\n    _assert_finite(out, \"after mlp residual\")\n    return out\n\n@torch.no_grad()\ndef test_full_forward_matches_stages(block: MaxOutBlock, x: torch.Tensor, atol=1e-6, rtol=1e-5):\n    block.eval()\n\n    # manual pipeline\n    a = test_outlooker_stage(block, x)\n    b = test_mbconv_stage(block, a)\n    c = test_grid_stage(block, b)         # BHWC\n    d = test_mlp_stage(block, c)          # BHWC\n    manual = d.permute(0, 3, 1, 2).contiguous()\n\n    # direct forward\n    direct = block(x)\n\n    _assert_shape(direct, x.shape, \"block(x)\")\n    _assert_finite(direct, \"block(x)\")\n    assert torch.allclose(manual, direct, atol=atol, rtol=rtol), \\\n        \"Manual staged pipeline != block.forward output (check wiring/residuals/norms).\"\n\n    return direct\n","metadata":{"id":"s7ajSLwC4YDU","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T22:59:50.264970Z","iopub.execute_input":"2026-01-06T22:59:50.265252Z","iopub.status.idle":"2026-01-06T22:59:50.275859Z","shell.execute_reply.started":"2026-01-06T22:59:50.265229Z","shell.execute_reply":"2026-01-06T22:59:50.275091Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def run_all_tests():\n    torch.manual_seed(0)\n\n    cfg = DummyCfg(dim=96, grid_size=4)\n    blk = MaxOutBlock(cfg).eval()\n\n    x = torch.randn(2, 96, 16, 16)\n    assert x.shape[2] % cfg.grid_size == 0 and x.shape[3] % cfg.grid_size == 0\n\n    y = test_full_forward_matches_stages(blk, x)\n    print(\"All tests passed. y:\", y.shape)\n\nrun_all_tests()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HAkYN2aS4irq","outputId":"0850564f-8d9b-4a50-88b5-8ffb18ca1c36"},"outputs":[{"output_type":"stream","name":"stdout","text":["All tests passed. y: torch.Size([2, 96, 16, 16])\n"]}],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{"id":"Ffdc4VMM6DuG"}},{"cell_type":"code","source":"class MaxOutStage(nn.Module):\n    def __init__(self, block_cfg, depth: int):\n        super().__init__()\n        self.blocks = nn.ModuleList([MaxOutBlock(block_cfg) for _ in range(depth)])\n\n    def forward(self, x):\n        for b in self.blocks:\n            x = b(x)\n        return x\n\nclass GridOnlyBlock(nn.Module):\n    \"\"\"\n    MBConv -> Grid-MHSA -> MLP (sin window attn).\n    Input/Output: [B,C,H,W]\n    \"\"\"\n    def __init__(self, cfg):\n        super().__init__()\n        C = cfg.dim\n\n        self.mbconv = MBConv(\n            in_ch=C, out_ch=C, stride=1,\n            cfg=MBConvConfig(\n                expand_ratio=cfg.mbconv_expand_ratio,\n                se_ratio=cfg.mbconv_se_ratio,\n                act=cfg.mbconv_act,\n                use_bn=cfg.use_bn,\n                drop_path=0.0,\n            )\n        )\n\n        self.norm2 = nn.LayerNorm(C)\n        self.grid_attn = LocalAttention2D(\n            LocalAttention2DConfig(\n                mode=\"grid\",\n                dim=C,\n                num_heads=cfg.num_heads,\n                window_size=getattr(cfg, \"window_size\", 1),\n                grid_size=cfg.grid_size,\n                qkv_bias=True,\n                attn_drop=cfg.attn_drop,\n                proj_drop=cfg.proj_drop,\n            )\n        )\n        self.dp2 = DropPath(cfg.drop_path) if cfg.drop_path > 0 else nn.Identity()\n\n        self.norm3 = nn.LayerNorm(C)\n        self.mlp = MLP(dim=C, mlp_ratio=cfg.mlp_ratio, drop=cfg.ffn_drop, act=cfg.mlp_act)\n        self.dp3 = DropPath(cfg.drop_path) if cfg.drop_path > 0 else nn.Identity()\n\n    def forward(self, x):\n        B, C, H, W = x.shape\n        x = self.mbconv(x)\n\n        x_bhwc = x.permute(0, 2, 3, 1).contiguous()\n\n        y = self.norm2(x_bhwc)\n        y = self.grid_attn(y)\n        x_bhwc = x_bhwc + self.dp2(y)\n\n        y = self.norm3(x_bhwc)\n        y = self.mlp(y)\n        x_bhwc = x_bhwc + self.dp3(y)\n\n        return x_bhwc.permute(0, 3, 1, 2).contiguous()\n","metadata":{"id":"gQ-aect-5ywp","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T22:59:52.480628Z","iopub.execute_input":"2026-01-06T22:59:52.480909Z","iopub.status.idle":"2026-01-06T22:59:52.489085Z","shell.execute_reply.started":"2026-01-06T22:59:52.480888Z","shell.execute_reply":"2026-01-06T22:59:52.488495Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class StageOutThenGrid(nn.Module):\n    \"\"\"\n    Outlooker una vez al inicio del stage, luego varios GridOnlyBlock.\n    \"\"\"\n    def __init__(self, cfg, depth: int, out_depth: int = 1):\n        super().__init__()\n        self.outlookers = nn.ModuleList([\n            OutlookerBlock2d(\n                dim=cfg.dim,\n                num_heads=cfg.outlook_heads,\n                kernel_size=cfg.outlook_kernel,\n                stride=1,\n                mlp_ratio=cfg.outlook_mlp_ratio,\n                attn_drop=cfg.attn_drop,\n                proj_drop=cfg.proj_drop,\n                mlp_drop=cfg.ffn_drop,\n                drop_path=cfg.drop_path,\n                act=cfg.mlp_act,)\n\n            for _ in range(out_depth)])\n\n        self.blocks = nn.ModuleList([GridOnlyBlock(cfg) for _ in range(depth)])\n\n    def forward(self, x):\n        for o in self.outlookers:\n            x = o(x)\n        for b in self.blocks:\n            x = b(x)\n        return x","metadata":{"id":"9OYFcY695-Ct","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T22:59:54.290271Z","iopub.execute_input":"2026-01-06T22:59:54.290971Z","iopub.status.idle":"2026-01-06T22:59:54.296218Z","shell.execute_reply.started":"2026-01-06T22:59:54.290948Z","shell.execute_reply":"2026-01-06T22:59:54.295686Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# DownSampling","metadata":{"id":"hJTafDZ-6Lpv"}},{"cell_type":"code","source":"DownsampleType = Literal[\"conv\", \"pool\"]\nActType = Literal[\"silu\", \"gelu\", \"relu\"]\n\ndef _make_activation(act) -> nn.Module:\n    act = act.lower()\n    if act == \"silu\":\n        return nn.SiLU(inplace=True)\n    if act == \"relu\":\n        return nn.ReLU(inplace=True)\n    if act == \"gelu\":\n        return nn.GELU()\n    raise ValueError(f\"Unknown activation '{act}'. Use one of: silu|gelu|relu\")\n\n@dataclass(frozen=True)\nclass DownsampleConfig:\n    kind: DownsampleType = \"conv\"  # \"conv\" or \"pool\"\n    act: ActType = \"silu\"\n    use_bn: bool = True\n\n\nclass Downsample(nn.Module):\n    \"\"\"\n    Downsample block:\n      - \"conv\": Conv3x3 stride2 padding1 (in_ch -> out_ch) + BN + Act\n      - \"pool\": AvgPool2x2 + Conv1x1 (in_ch -> out_ch) + BN + Act\n\n    Input:  [B, in_ch, H, W]\n    Output: [B, out_ch, H/2, W/2]\n    \"\"\"\n\n    def __init__(self, in_ch: int, out_ch: int, cfg: DownsampleConfig = DownsampleConfig()):\n        super().__init__()\n        if in_ch <= 0 or out_ch <= 0:\n            raise ValueError(\"in_ch and out_ch must be > 0\")\n\n        self.in_ch = in_ch\n        self.out_ch = out_ch\n        self.kind = cfg.kind\n\n        bn = (lambda c: nn.BatchNorm2d(c)) if cfg.use_bn else (lambda c: nn.Identity())\n        act = _make_activation(cfg.act)\n\n        if cfg.kind == \"conv\":\n            self.op = nn.Sequential(\n                nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=2, padding=1, bias=not cfg.use_bn),\n                bn(out_ch),\n                act,)\n        elif cfg.kind == \"pool\":\n            self.op = nn.Sequential(\n                nn.AvgPool2d(kernel_size=2, stride=2),\n                nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=1, padding=0, bias=not cfg.use_bn),\n                bn(out_ch),\n                act,)\n        else:\n            raise ValueError(\"cfg.kind must be 'conv' or 'pool'\")\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        return self.op(x)","metadata":{"id":"HTosN2946LkG","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T22:59:55.824724Z","iopub.execute_input":"2026-01-06T22:59:55.824985Z","iopub.status.idle":"2026-01-06T22:59:55.833855Z","shell.execute_reply.started":"2026-01-06T22:59:55.824966Z","shell.execute_reply":"2026-01-06T22:59:55.833156Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"---","metadata":{"id":"t68ZJmMX6P8A"}},{"cell_type":"code","source":"from dataclasses import dataclass\nfrom typing import List\n\n@dataclass\nclass StageCfg:\n    # core dims\n    dim: int\n    depth: int\n\n    # grid attention\n    num_heads: int\n    grid_size: int\n    window_size: int = 8  # no se usa en grid-only, pero lo mantenemos compatible\n\n    # outlooker\n    outlook_heads: int = 6\n    outlook_kernel: int = 3\n    outlook_mlp_ratio: float = 2.0\n\n    # MBConv\n    mbconv_expand_ratio: float = 4.0\n    mbconv_se_ratio: float = 0.25\n    mbconv_act: str = \"silu\"\n    use_bn: bool = True\n\n    # drops\n    attn_drop: float = 0.0\n    proj_drop: float = 0.0\n    ffn_drop: float = 0.0\n    drop_path: float = 0.0\n\n    # MLP (BHWC)\n    mlp_ratio: float = 4.0\n    mlp_act: str = \"gelu\"\n\n\ndef make_dpr(total_blocks: int, dpr_max: float) -> List[float]:\n    if total_blocks <= 1:\n        return [dpr_max]\n    return [dpr_max * i / (total_blocks - 1) for i in range(total_blocks)]\n\n\nclass ConvStem(nn.Module):\n    def __init__(self, in_ch: int, out_ch: int, act: str = \"silu\", use_bn: bool = True):\n        super().__init__()\n        \n        bn = (lambda c: nn.BatchNorm2d(c)) if use_bn else (lambda c: nn.Identity())\n        \n        self.stem = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=not use_bn),\n            bn(out_ch),\n            _make_activation(act),)\n\n    def forward(self, x):\n        return self.stem(x)\n\n\n","metadata":{"id":"JPh2vPeh7FEk","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T22:59:58.821071Z","iopub.execute_input":"2026-01-06T22:59:58.821332Z","iopub.status.idle":"2026-01-06T22:59:58.829453Z","shell.execute_reply.started":"2026-01-06T22:59:58.821314Z","shell.execute_reply":"2026-01-06T22:59:58.828790Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class OutlookerFrontGridNet(nn.Module):\n    \"\"\"\n    Modelo A:\n      Stem -> OutlookerFront (L bloques) -> (Stage: GridOnlyBlock x depth + Downsample) -> Head\n    \"\"\"\n    def __init__(\n        self,\n        num_classes: int,\n        stages: List[StageCfg],\n        in_ch: int = 3,\n        stem_dim: int = 64,\n        outlooker_front_depth: int = 2,   # <- varios outlookers \"tipo VOLO\"\n        dpr_max: float = 0.1,\n        down_cfg: DownsampleConfig = DownsampleConfig(kind=\"conv\", act=\"silu\", use_bn=True),):\n\n        super().__init__()\n        assert len(stages) >= 1\n        self.stem = ConvStem(in_ch, stem_dim, act=\"silu\", use_bn=True)\n\n        # proyección para entrar a dim del stage1 si stem_dim != stage1.dim\n        self.proj_in = nn.Identity()\n        if stem_dim != stages[0].dim:\n            self.proj_in = nn.Conv2d(stem_dim, stages[0].dim, kernel_size=1, bias=True)\n\n        # schedule global de drop_path por bloque (front + sum(stage.depth))\n        total_blocks = outlooker_front_depth + sum(s.depth for s in stages)\n        dprs = make_dpr(total_blocks, dpr_max)\n        idx = 0\n\n        # Outlooker front (NCHW) con residual + DropPath interno\n        front_cfg = stages[0]\n        self.front = nn.ModuleList()\n        for _ in range(outlooker_front_depth):\n            c = front_cfg\n            self.front.append(\n                OutlookerBlock2d(\n                    dim=c.dim,\n                    num_heads=c.outlook_heads,\n                    kernel_size=c.outlook_kernel,\n                    stride=1,\n                    mlp_ratio=c.outlook_mlp_ratio,\n                    attn_drop=c.attn_drop,\n                    proj_drop=c.proj_drop,\n                    mlp_drop=c.ffn_drop,\n                    drop_path=dprs[idx],\n                    act=c.mlp_act,))\n\n            idx += 1\n\n        # stages: GridOnlyBlock stacks + downsample between stages\n        self.stages = nn.ModuleList()\n        self.downs = nn.ModuleList()\n\n        for si, scfg in enumerate(stages):\n            blocks = nn.ModuleList()\n            for _ in range(scfg.depth):\n                # clonar cfg pero con drop_path asignado por bloque\n                bcfg = StageCfg(**{**scfg.__dict__, \"drop_path\": dprs[idx]})\n                blocks.append(GridOnlyBlock(bcfg))\n                idx += 1\n            self.stages.append(blocks)\n\n            # downsample (except after last stage)\n            if si < len(stages) - 1:\n                self.downs.append(Downsample(scfg.dim, stages[si+1].dim, cfg=down_cfg))\n\n        # head\n        self.head_norm = nn.BatchNorm2d(stages[-1].dim)\n        self.classifier = nn.Linear(stages[-1].dim, num_classes)\n\n    def forward(self, x):\n        x = self.stem(x)\n        x = self.proj_in(x)\n\n        # front outlooker\n        for blk in self.front:\n            x = blk(x)\n\n        # grid-only stages\n        for si, blocks in enumerate(self.stages):\n            for blk in blocks:\n                x = blk(x)\n            if si < len(self.downs):\n                x = self.downs[si](x)\n\n        # global pool + cls\n        x = self.head_norm(x)\n        x = x.mean(dim=(2, 3))\n\n        return self.classifier(x)","metadata":{"id":"JarHZhH77WcT","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T23:00:00.505814Z","iopub.execute_input":"2026-01-06T23:00:00.506348Z","iopub.status.idle":"2026-01-06T23:00:00.516186Z","shell.execute_reply.started":"2026-01-06T23:00:00.506325Z","shell.execute_reply":"2026-01-06T23:00:00.515485Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"class MaxOutNet(nn.Module):\n    \"\"\"\n    Modelo B:\n      Stem -> (Stage: MaxOutBlock x depth + Downsample) -> Head\n    \"\"\"\n    def __init__(\n        self,\n        num_classes: int,\n        stages: List[StageCfg],\n        in_ch: int = 3,\n        stem_dim: int = 64,\n        dpr_max: float = 0.1,\n        down_cfg: DownsampleConfig = DownsampleConfig(kind=\"conv\", act=\"silu\", use_bn=True),):\n\n        super().__init__()\n        assert len(stages) >= 1\n        \n        self.stem = ConvStem(in_ch, stem_dim, act=\"silu\", use_bn=True)\n\n        self.proj_in = nn.Identity()\n\n        if stem_dim != stages[0].dim:\n            self.proj_in = nn.Conv2d(stem_dim, stages[0].dim, kernel_size=1, bias=True)\n\n        total_blocks = sum(s.depth for s in stages)\n        dprs = make_dpr(total_blocks, dpr_max)\n        idx = 0\n\n        self.stages = nn.ModuleList()\n        self.downs = nn.ModuleList()\n\n        for si, scfg in enumerate(stages):\n            blocks = nn.ModuleList()\n            for _ in range(scfg.depth):\n                bcfg = StageCfg(**{**scfg.__dict__, \"drop_path\": dprs[idx]})\n\n                blocks.append(MaxOutBlock(bcfg))\n                idx += 1\n            self.stages.append(blocks)\n\n            if si < len(stages) - 1:\n                self.downs.append(Downsample(scfg.dim, stages[si+1].dim, cfg=down_cfg))\n\n        self.head_norm = nn.BatchNorm2d(stages[-1].dim)\n        self.classifier = nn.Linear(stages[-1].dim, num_classes)\n\n    def forward(self, x):\n        x = self.stem(x)\n        x = self.proj_in(x)\n\n        for si, blocks in enumerate(self.stages):\n            for blk in blocks:\n                x = blk(x)\n            if si < len(self.downs):\n                x = self.downs[si](x)\n\n        x = self.head_norm(x)\n        x = x.mean(dim=(2, 3))\n        return self.classifier(x)","metadata":{"id":"STtT8-Jq7i16","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T23:00:03.178401Z","iopub.execute_input":"2026-01-06T23:00:03.179098Z","iopub.status.idle":"2026-01-06T23:00:03.188369Z","shell.execute_reply.started":"2026-01-06T23:00:03.179073Z","shell.execute_reply":"2026-01-06T23:00:03.187634Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"---\n","metadata":{"id":"KC8-JW5-7ryG"}},{"cell_type":"code","source":"def cifar64_stages_tiny():\n    # resoluciones esperadas: 64 -> 32 -> 16 -> 8 -> 4\n    '''\n    dim: #canales del feature map en ese stage\n    depth: cuántos bloques repites en ese stage\n    num_heads: #heads de la Grid-MHSA en ese stage\n    grid_size: cómo se parte la imagen para grid attention (debe dividir H y W)\n    outlook_heads: #heads del Outlooker (si ese modelo lo usa en ese stage)\n    '''\n\n    return [\n        StageCfg(dim=96,  depth=2, num_heads=3, grid_size=8, outlook_heads=3),\n        StageCfg(dim=192, depth=2, num_heads=6, grid_size=8, outlook_heads=6),\n        StageCfg(dim=384, depth=5, num_heads=12, grid_size=4, outlook_heads=12),\n        StageCfg(dim=768, depth=2, num_heads=12, grid_size=2, outlook_heads=12),]\n\n\nstages = cifar64_stages_tiny()\n\nmA = OutlookerFrontGridNet(num_classes=100, stages=stages, stem_dim=96, outlooker_front_depth=2, dpr_max=0.1)\nmB = MaxOutNet(num_classes=100, stages=stages, stem_dim=96, dpr_max=0.1)\n\nx = torch.randn(2, 3, 64, 64)\nyA = mA(x)\nyB = mB(x)\nprint(yA.shape, yB.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NrUgyIa-7tH7","outputId":"8aeb5f56-bded-4f98-ae87-00cf14be2575"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 100]) torch.Size([2, 100])\n"]}],"execution_count":null},{"cell_type":"markdown","source":"---\n\n# Training","metadata":{"id":"k_91feMK85Xy"}},{"cell_type":"code","source":"import os\nimport math\nimport time\nimport random\nimport inspect\nfrom dataclasses import dataclass\nfrom contextlib import contextmanager, nullcontext\nfrom typing import Optional, Dict, Tuple, Any\nimport torch\n\ndef seed_everything(seed: int = 0, deterministic: bool = False):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    if deterministic:\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n    else:\n        torch.backends.cudnn.benchmark = True\n\n\nDTYPE_MAP = {\n    \"bf16\": torch.bfloat16, \"bfloat16\": torch.bfloat16,\n    \"fp16\": torch.float16,  \"float16\": torch.float16,\n    \"fp32\": torch.float32,  \"float32\": torch.float32,}\n\ndef _cuda_dtype_supported(dtype: torch.dtype) -> bool:\n    if not torch.cuda.is_available():\n        return False\n    return dtype in (torch.float16, torch.bfloat16)\n\ndef make_grad_scaler(device: str = \"cuda\", enabled: bool = True):\n    if not enabled:\n        return None\n\n    if hasattr(torch, \"amp\") and hasattr(torch.amp, \"GradScaler\"):\n        try:\n            sig = inspect.signature(torch.amp.GradScaler)\n            if len(sig.parameters) >= 1:\n                return torch.amp.GradScaler(device if device in (\"cuda\", \"cpu\") else \"cuda\")\n            return torch.amp.GradScaler()\n        except Exception:\n            pass\n\n    if hasattr(torch.cuda, \"amp\") and hasattr(torch.cuda.amp, \"GradScaler\"):\n        return torch.cuda.amp.GradScaler()\n    return None\n\n\n@contextmanager\ndef autocast_ctx(\n    device: str = \"cuda\",\n    enabled: bool = True,\n    dtype: str = \"fp16\",\n    cache_enabled: bool = True,):\n    \"\"\"\n    Context manager de autocast:\n      - cuda: fp16 por defecto (ideal en T4)\n      - cpu: bfloat16 si está disponible\n    \"\"\"\n    if not enabled:\n        with nullcontext():\n            yield\n        return\n\n    if device == \"cuda\":\n        want = DTYPE_MAP.get(dtype.lower(), torch.float16)\n        use = want if _cuda_dtype_supported(want) else torch.float16\n        with torch.amp.autocast(device_type=\"cuda\", dtype=use, cache_enabled=cache_enabled):\n            yield\n        return\n\n    if device == \"cpu\":\n        try:\n            with torch.amp.autocast(device_type=\"cpu\", dtype=torch.bfloat16, cache_enabled=cache_enabled):\n                yield\n        except Exception:\n            with nullcontext():\n                yield\n        return\n\n    with nullcontext():\n        yield","metadata":{"id":"G9XteOq588JY","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T23:00:06.886574Z","iopub.execute_input":"2026-01-06T23:00:06.887289Z","iopub.status.idle":"2026-01-06T23:00:06.896798Z","shell.execute_reply.started":"2026-01-06T23:00:06.887262Z","shell.execute_reply":"2026-01-06T23:00:06.896017Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"\ndef save_checkpoint(\n    path: str,\n    model,\n    optimizer,\n    scheduler,\n    scaler,\n    epoch: int,\n    best_top1: float,\n    extra: dict | None = None,):\n\n    ckpt = {\n        \"model\": model.state_dict(),\n        \"optimizer\": optimizer.state_dict() if optimizer is not None else None,\n        \"scheduler\": scheduler.state_dict() if scheduler is not None else None,\n        \"scaler\": scaler.state_dict() if scaler is not None else None,\n        \"epoch\": epoch,\n        \"best_top1\": best_top1,\n        \"extra\": extra or {},}\n    torch.save(ckpt, path)\n\n\ndef load_checkpoint(\n    path: str,\n    model,\n    optimizer=None,\n    scheduler=None,\n    scaler=None,\n    map_location=\"cpu\",\n    strict: bool = True,):\n    ckpt = torch.load(path, map_location=map_location)\n    model.load_state_dict(ckpt[\"model\"], strict=strict)\n\n    if optimizer is not None and ckpt.get(\"optimizer\") is not None:\n        optimizer.load_state_dict(ckpt[\"optimizer\"])\n    if scheduler is not None and ckpt.get(\"scheduler\") is not None:\n        scheduler.load_state_dict(ckpt[\"scheduler\"])\n    if scaler is not None and ckpt.get(\"scaler\") is not None:\n        scaler.load_state_dict(ckpt[\"scaler\"])\n    return ckpt","metadata":{"id":"kYQ732DP9CCM","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T23:00:10.577742Z","iopub.execute_input":"2026-01-06T23:00:10.578264Z","iopub.status.idle":"2026-01-06T23:00:10.584375Z","shell.execute_reply.started":"2026-01-06T23:00:10.578240Z","shell.execute_reply":"2026-01-06T23:00:10.583664Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"@torch.no_grad()\ndef accuracy_topk(logits: torch.Tensor, targets: torch.Tensor, ks=(1, 3, 5)) -> Dict[int, float]:\n    \"\"\"\n    targets can be:\n      - int64 class indices [B]\n      - soft targets [B, num_classes] (we'll argmax for accuracy reporting)\n    \"\"\"\n    if targets.ndim == 2:\n        targets = targets.argmax(dim=1)\n\n    max_k = max(ks)\n    B = targets.size(0)\n    _, pred = torch.topk(logits, k=max_k, dim=1)\n    correct = pred.eq(targets.view(-1, 1).expand_as(pred))\n    out = {}\n    for k in ks:\n        out[k] = 100.0 * correct[:, :k].any(dim=1).float().sum().item() / B\n    return out","metadata":{"id":"toJSWec19P2s","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T23:00:13.284961Z","iopub.execute_input":"2026-01-06T23:00:13.285706Z","iopub.status.idle":"2026-01-06T23:00:13.290618Z","shell.execute_reply.started":"2026-01-06T23:00:13.285682Z","shell.execute_reply":"2026-01-06T23:00:13.290019Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def _one_hot(targets: torch.Tensor, num_classes: int) -> torch.Tensor:\n    return F.one_hot(targets, num_classes=num_classes).float()\n\n\ndef soft_target_cross_entropy(logits: torch.Tensor, targets_soft: torch.Tensor) -> torch.Tensor:\n    logp = F.log_softmax(logits, dim=1)\n    return -(targets_soft * logp).sum(dim=1).mean()\n\n\ndef apply_mixup_cutmix(\n    images: torch.Tensor,\n    targets: torch.Tensor,\n    num_classes: int,\n    mixup_alpha: float = 0.0,\n    cutmix_alpha: float = 0.0,\n    prob: float = 1.0,):\n    \"\"\"\n    Returns:\n      images_aug: [B,3,H,W]\n      targets_soft: [B,K]\n    \"\"\"\n    if prob <= 0.0 or (mixup_alpha <= 0.0 and cutmix_alpha <= 0.0):\n        return images, _one_hot(targets, num_classes)\n\n    if random.random() > prob:\n        return images, _one_hot(targets, num_classes)\n\n    use_cutmix = (cutmix_alpha > 0.0) and (mixup_alpha <= 0.0 or random.random() < 0.5)\n    B, _, H, W = images.shape\n    perm = torch.randperm(B, device=images.device)\n\n    y1 = _one_hot(targets, num_classes)\n    y2 = _one_hot(targets[perm], num_classes)\n\n    if use_cutmix:\n        lam = torch.distributions.Beta(cutmix_alpha, cutmix_alpha).sample().item()\n        cut_w = int(W * math.sqrt(1.0 - lam))\n        cut_h = int(H * math.sqrt(1.0 - lam))\n        cx = random.randint(0, W - 1)\n        cy = random.randint(0, H - 1)\n\n        x1 = max(cx - cut_w // 2, 0)\n        x2 = min(cx + cut_w // 2, W)\n        y1b = max(cy - cut_h // 2, 0)\n        y2b = min(cy + cut_h // 2, H)\n\n        images_aug = images.clone()\n        images_aug[:, :, y1b:y2b, x1:x2] = images[perm, :, y1b:y2b, x1:x2]\n\n        # adjust lambda based on actual area swapped\n        area = (x2 - x1) * (y2b - y1b)\n        lam = 1.0 - area / float(W * H)\n    else:\n        lam = torch.distributions.Beta(mixup_alpha, mixup_alpha).sample().item()\n        images_aug = images * lam + images[perm] * (1.0 - lam)\n\n    targets_soft = y1 * lam + y2 * (1.0 - lam)\n    return images_aug, targets_soft","metadata":{"id":"zvJc7YKo9UdD","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T23:00:14.649586Z","iopub.execute_input":"2026-01-06T23:00:14.649840Z","iopub.status.idle":"2026-01-06T23:00:14.658204Z","shell.execute_reply.started":"2026-01-06T23:00:14.649821Z","shell.execute_reply":"2026-01-06T23:00:14.657430Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"def build_param_groups_no_wd(model: nn.Module, weight_decay: float):\n    decay, no_decay = [], []\n    for name, p in model.named_parameters():\n        if not p.requires_grad:\n            continue\n\n        name_l = name.lower()\n        # no decay for biases + norms + positional/class tokens\n        if (\n            name.endswith(\".bias\")\n            or (\"norm\" in name_l)\n            or (\"bn\" in name_l)\n            or (\"ln\" in name_l)\n            or (\"pos\" in name_l)         # pos_embed / pos\n            or (\"cls_token\" in name_l)\n        ):\n            no_decay.append(p)\n        else:\n            decay.append(p)\n\n    return [\n        {\"params\": decay, \"weight_decay\": weight_decay},\n        {\"params\": no_decay, \"weight_decay\": 0.0}]\n\n\nclass WarmupCosineLR:\n    \"\"\"Warmup linear for warmup_steps, then cosine to min_lr. Step-based.\"\"\"\n    def __init__(self, optimizer, total_steps: int, warmup_steps: int, min_lr: float = 0.0):\n        self.optimizer = optimizer\n        self.total_steps = int(total_steps)\n        self.warmup_steps = int(warmup_steps)\n        self.min_lr = float(min_lr)\n        self.base_lrs = [g[\"lr\"] for g in optimizer.param_groups]\n        self.step_num = 0\n\n    def step(self):\n        self.step_num += 1\n        t = self.step_num\n\n        for i, group in enumerate(self.optimizer.param_groups):\n            base = self.base_lrs[i]\n            if t <= self.warmup_steps and self.warmup_steps > 0:\n                lr = base * (t / self.warmup_steps)\n            else:\n                tt = min(t, self.total_steps)\n                denom = max(1, self.total_steps - self.warmup_steps)\n                progress = (tt - self.warmup_steps) / denom\n                cosine = 0.5 * (1.0 + math.cos(math.pi * progress))\n                lr = self.min_lr + (base - self.min_lr) * cosine\n            group[\"lr\"] = lr\n\n    def state_dict(self):\n        return {\"step_num\": self.step_num}\n\n    def load_state_dict(self, d):\n        self.step_num = int(d.get(\"step_num\", 0))","metadata":{"id":"qO-QWNsY9XU7","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T23:00:16.284332Z","iopub.execute_input":"2026-01-06T23:00:16.284966Z","iopub.status.idle":"2026-01-06T23:00:16.293216Z","shell.execute_reply.started":"2026-01-06T23:00:16.284943Z","shell.execute_reply":"2026-01-06T23:00:16.292477Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def train_one_epoch(\n    model: nn.Module,\n    dataloader,\n    optimizer: torch.optim.Optimizer,\n    scheduler,\n    device: str = \"cuda\",\n    scaler=None,\n    autocast_dtype: str = \"bf16\",\n    use_amp: bool = True,\n    grad_clip_norm: Optional[float] = 1.0,\n    label_smoothing: float = 0.1,\n    mixup_alpha: float = 0.0,\n    cutmix_alpha: float = 0.0,\n    mix_prob: float = 1.0,\n    num_classes: int = 100,\n    channels_last: bool = False,\n    print_every: int = 100,) -> Tuple[float, Dict[str, float]]:\n    \"\"\"\n    Single-process train loop (no DDP, no EMA).\n\n    Expects helpers already defined in your file:\n      - autocast_ctx\n      - apply_mixup_cutmix\n      - soft_target_cross_entropy\n      - accuracy_topk\n    \"\"\"\n    model.train()\n\n    use_scaler = (scaler is not None) and use_amp and autocast_dtype.lower() in (\"fp16\", \"float16\")\n\n    running_loss = 0.0\n    total = 0\n    c1 = c3 = c5 = 0.0\n\n    t0 = time.time()\n    for step, (images, targets) in enumerate(dataloader, start=1):\n        images = images.to(device, non_blocking=True)\n        targets = targets.to(device, non_blocking=True)\n\n        if channels_last:\n            images = images.contiguous(memory_format=torch.channels_last)\n\n        B = targets.size(0)\n\n        # mixup/cutmix => soft targets\n        images_aug, targets_soft = apply_mixup_cutmix(\n            images, targets,\n            num_classes=num_classes,\n            mixup_alpha=mixup_alpha,\n            cutmix_alpha=cutmix_alpha,\n            prob=mix_prob,)\n\n        optimizer.zero_grad(set_to_none=True)\n\n        with autocast_ctx(device=device, enabled=use_amp, dtype=autocast_dtype, cache_enabled=True):\n            logits = model(images_aug)  # [B, K]\n\n        # loss in fp32\n        if (mixup_alpha > 0.0) or (cutmix_alpha > 0.0):\n            # With mixup/cutmix, label smoothing is usually redundant.\n            loss = soft_target_cross_entropy(logits.float(), targets_soft)\n        else:\n            loss = F.cross_entropy(logits.float(), targets, label_smoothing=label_smoothing)\n\n        if use_scaler:\n            scaler.scale(loss).backward()\n            if grad_clip_norm is not None:\n                scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_norm)\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            loss.backward()\n            if grad_clip_norm is not None:\n                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_norm)\n            optimizer.step()\n\n        if scheduler is not None:\n            scheduler.step()\n\n        # metrics\n        running_loss += loss.item() * B\n        total += B\n        accs = accuracy_topk(\n            logits.detach(),\n            targets_soft if targets_soft.ndim == 2 else targets,\n            ks=(1, 3, 5),)\n\n        c1 += accs[1] * B / 100.0\n        c3 += accs[3] * B / 100.0\n        c5 += accs[5] * B / 100.0\n\n        if print_every and (step % print_every == 0):\n            dt = time.time() - t0\n            imgs_sec = total / max(dt, 1e-9)\n            print(\n                f\"[train step {step}/{len(dataloader)}] \"\n                f\"loss {running_loss/total:.4f} | \"\n                f\"top1 {100*c1/total:.2f}% | top3 {100*c3/total:.2f}% | top5 {100*c5/total:.2f}% | \"\n                f\"{imgs_sec:.1f} img/s | lr {optimizer.param_groups[0]['lr']:.2e}\")\n\n    avg_loss = running_loss / max(1, total)\n    metrics = {\n        \"top1\": 100.0 * c1 / max(1, total),\n        \"top3\": 100.0 * c3 / max(1, total),\n        \"top5\": 100.0 * c5 / max(1, total),}\n\n    return avg_loss, metrics","metadata":{"id":"vW315s-J9axB","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T23:00:17.835126Z","iopub.execute_input":"2026-01-06T23:00:17.835398Z","iopub.status.idle":"2026-01-06T23:00:17.846861Z","shell.execute_reply.started":"2026-01-06T23:00:17.835377Z","shell.execute_reply":"2026-01-06T23:00:17.846177Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"\n@torch.no_grad()\ndef evaluate_one_epoch(\n    model: nn.Module,\n    dataloader,\n    device: str = \"cuda\",\n    autocast_dtype: str = \"bf16\",\n    use_amp: bool = True,\n    label_smoothing: float = 0.0,\n    channels_last: bool = False) -> Tuple[float, Dict[str, float]]:\n    \"\"\"\n    Single-process evaluation loop (no DDP, no EMA).\n\n    Expects helpers already defined in your file:\n      - autocast_ctx\n      - accuracy_topk\n    \"\"\"\n    model.eval().to(device)\n\n    running_loss = 0.0\n    total = 0\n    c1 = c3 = c5 = 0.0\n\n    for images, targets in dataloader:\n        images = images.to(device, non_blocking=True)\n        targets = targets.to(device, non_blocking=True)\n\n        if channels_last:\n            images = images.contiguous(memory_format=torch.channels_last)\n\n        B = targets.size(0)\n\n        with autocast_ctx(device=device, enabled=use_amp, dtype=autocast_dtype, cache_enabled=True):\n            logits = model(images)\n\n        loss = F.cross_entropy(logits.float(), targets, label_smoothing=label_smoothing)\n\n        running_loss += loss.item() * B\n        total += B\n\n        accs = accuracy_topk(logits, targets, ks=(1, 3, 5))\n        c1 += accs[1] * B / 100.0\n        c3 += accs[3] * B / 100.0\n        c5 += accs[5] * B / 100.0\n\n    avg_loss = running_loss / max(1, total)\n    metrics = {\n        \"top1\": 100.0 * c1 / max(1, total),\n        \"top3\": 100.0 * c3 / max(1, total),\n        \"top5\": 100.0 * c5 / max(1, total),}\n\n    return avg_loss, metrics","metadata":{"id":"O7MaseFT_Rqd","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T23:00:20.374731Z","iopub.execute_input":"2026-01-06T23:00:20.375251Z","iopub.status.idle":"2026-01-06T23:00:20.381995Z","shell.execute_reply.started":"2026-01-06T23:00:20.375227Z","shell.execute_reply":"2026-01-06T23:00:20.381183Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"def train_model(\n    model: nn.Module,\n    train_loader,\n    epochs: int,\n    val_loader=None,\n    device: str = \"cuda\",\n    lr: float = 5e-4,\n    weight_decay: float = 0.05,\n    autocast_dtype: str = \"fp16\",\n    use_amp: bool = True,\n    grad_clip_norm: float | None = 1.0,\n    warmup_ratio: float = 0.05,\n    min_lr: float = 0.0,\n    label_smoothing: float = 0.1,\n    print_every: int = 100,\n    save_path: str = \"best_model.pt\",\n    last_path: str = \"last_model.pt\",\n    resume_path: str | None = None,\n    mixup_alpha: float = 0.0,\n    cutmix_alpha: float = 0.0,\n    mix_prob: float = 1.0,\n    num_classes: int = 100,\n    channels_last: bool = False,\n    early_stop: bool = True,\n    early_stop_metric: str = \"top1\",          # \"top1\" or \"loss\"\n    early_stop_patience: int = 10,\n    early_stop_min_delta: float = 0.0,\n    early_stop_require_monotonic: bool = False,) -> Tuple[Dict[str, list], nn.Module]:\n\n    \"\"\"\n    Single-process trainer (no DDP, no EMA).\n\n    Expects helpers already defined in your file:\n      - build_param_groups_no_wd\n      - WarmupCosineLR\n      - make_grad_scaler\n      - save_checkpoint / load_checkpoint\n      - train_one_epoch (the one above)\n      - evaluate_one_epoch\n    \"\"\"\n    model.to(device)\n\n    # Optimizer\n    param_groups = build_param_groups_no_wd(model, weight_decay=weight_decay)\n    optimizer = torch.optim.AdamW(param_groups, lr=lr, betas=(0.9, 0.999), eps=1e-8)\n\n    # Scheduler warmup + cosine (step-based)\n    total_steps = epochs * len(train_loader)\n    warmup_steps = int(total_steps * warmup_ratio)\n    scheduler = WarmupCosineLR(\n        optimizer,\n        total_steps=total_steps,\n        warmup_steps=warmup_steps,\n        min_lr=min_lr)\n\n    # AMP scaler\n    scaler = None\n    if use_amp and autocast_dtype.lower() in (\"fp16\", \"float16\"):\n        scaler = make_grad_scaler(device=device, enabled=True)\n\n    # Resume\n    start_epoch = 0\n    best_val_top1 = -float(\"inf\")\n    best_val_loss = float(\"inf\")\n    best_epoch = 0\n\n    if resume_path is not None:\n        ckpt = load_checkpoint(\n            resume_path, model,\n            optimizer=optimizer, scheduler=scheduler, scaler=scaler,\n            map_location=device,\n            strict=True,)\n\n        start_epoch = int(ckpt.get(\"epoch\", 0))\n        best_val_top1 = float(ckpt.get(\"best_top1\", best_val_top1))\n        extra = ckpt.get(\"extra\", {}) or {}\n        best_val_loss = float(extra.get(\"best_val_loss\", best_val_loss))\n        best_epoch = int(extra.get(\"best_epoch\", best_epoch))\n        print(f\"Resumed from {resume_path} at epoch {start_epoch} | best_top1 {best_val_top1:.2f}% | best_loss {best_val_loss:.4f}\")\n\n    history = {\n        \"train_loss\": [], \"train_top1\": [], \"train_top3\": [], \"train_top5\": [],\n        \"val_loss\": [], \"val_top1\": [], \"val_top3\": [], \"val_top5\": [],\n        \"lr\": [],}\n\n    metric = early_stop_metric.lower()\n    assert metric in (\"top1\", \"loss\")\n    mode = \"max\" if metric == \"top1\" else \"min\"\n    best_metric = best_val_top1 if metric == \"top1\" else best_val_loss\n    patience = int(early_stop_patience)\n    bad_epochs = 0\n    last_vals: list[float] = []\n\n    def _is_improvement(curr: float, best: float) -> bool:\n        d = float(early_stop_min_delta)\n        return (curr > (best + d)) if mode == \"max\" else (curr < (best - d))\n\n    def _degradation_monotonic(vals: list[float]) -> bool:\n        if not early_stop_require_monotonic or len(vals) < 2:\n            return True\n        if mode == \"max\":\n            return all(vals[i] >= vals[i + 1] for i in range(len(vals) - 1))\n        else:\n            return all(vals[i] <= vals[i + 1] for i in range(len(vals) - 1))\n\n    for epoch in range(start_epoch + 1, epochs + 1):\n        print(f\"\\n=== Epoch {epoch}/{epochs} ===\")\n        t_epoch = time.time()\n\n        # If a sampler supports set_epoch, reshuffle deterministically per epoch (works even without DDP)\n        if hasattr(train_loader, \"sampler\") and hasattr(train_loader.sampler, \"set_epoch\"):\n            train_loader.sampler.set_epoch(epoch)\n        if val_loader is not None and hasattr(val_loader, \"sampler\") and hasattr(val_loader.sampler, \"set_epoch\"):\n            val_loader.sampler.set_epoch(epoch)\n\n        # --- Train ---\n        tr_loss, tr_m = train_one_epoch(\n            model=model,\n            dataloader=train_loader,\n            optimizer=optimizer,\n            scheduler=scheduler,\n            device=device,\n            scaler=scaler,\n            autocast_dtype=autocast_dtype,\n            use_amp=use_amp,\n            grad_clip_norm=grad_clip_norm,\n            label_smoothing=label_smoothing,\n            mixup_alpha=mixup_alpha,\n            cutmix_alpha=cutmix_alpha,\n            mix_prob=mix_prob,\n            num_classes=num_classes,\n            channels_last=channels_last,\n            print_every=print_every,)\n\n        history[\"train_loss\"].append(tr_loss)\n        history[\"train_top1\"].append(tr_m[\"top1\"])\n        history[\"train_top3\"].append(tr_m[\"top3\"])\n        history[\"train_top5\"].append(tr_m[\"top5\"])\n        history[\"lr\"].append(float(optimizer.param_groups[0][\"lr\"]))\n\n        print(\n            f\"[Train] loss {tr_loss:.4f} | top1 {tr_m['top1']:.2f}% | top3 {tr_m['top3']:.2f}% | \"\n            f\"top5 {tr_m['top5']:.2f}% | lr {optimizer.param_groups[0]['lr']:.2e}\")\n\n        # Save \"last\" checkpoint every epoch\n        save_checkpoint(\n            last_path, model, optimizer, scheduler, scaler,\n            epoch=epoch, best_top1=best_val_top1,\n            extra={\n                \"autocast_dtype\": autocast_dtype,\n                \"use_amp\": use_amp,\n                \"best_val_loss\": best_val_loss,\n                \"best_epoch\": best_epoch,\n                \"early_stop_metric\": metric,\n                \"early_stop_patience\": patience,\n                \"early_stop_min_delta\": float(early_stop_min_delta),},)\n\n        stop_now = False\n\n        # --- Val ---\n        if val_loader is not None:\n            va_loss, va_m = evaluate_one_epoch(\n                model=model,\n                dataloader=val_loader,\n                device=device,\n                autocast_dtype=autocast_dtype,\n                use_amp=use_amp,\n                label_smoothing=0.0,\n                channels_last=channels_last,)\n\n            history[\"val_loss\"].append(va_loss)\n            history[\"val_top1\"].append(va_m[\"top1\"])\n            history[\"val_top3\"].append(va_m[\"top3\"])\n            history[\"val_top5\"].append(va_m[\"top5\"])\n\n            print(\n                f\"[Val]   loss {va_loss:.4f} | top1 {va_m['top1']:.2f}% | top3 {va_m['top3']:.2f}% | top5 {va_m['top5']:.2f}%\")\n\n            # Best checkpoint by val_top1\n            if va_m[\"top1\"] > best_val_top1:\n                best_val_top1 = float(va_m[\"top1\"])\n                if va_loss < best_val_loss:\n                    best_val_loss = float(va_loss)\n                    best_epoch = int(epoch)\n\n                save_checkpoint(\n                    save_path, model, optimizer, scheduler, scaler,\n                    epoch=epoch, best_top1=best_val_top1,\n                    extra={\n                        \"autocast_dtype\": autocast_dtype,\n                        \"use_amp\": use_amp,\n                        \"best_val_loss\": best_val_loss,\n                        \"best_epoch\": best_epoch,},)\n\n                print(f\"Best saved to {save_path} (val top1 {best_val_top1:.2f}%)\")\n\n            # Early stop on chosen metric\n            if early_stop:\n                curr_metric = float(va_m[\"top1\"]) if metric == \"top1\" else float(va_loss)\n\n                last_vals.append(curr_metric)\n                if len(last_vals) > patience:\n                    last_vals = last_vals[-patience:]\n\n                if _is_improvement(curr_metric, best_metric):\n                    best_metric = curr_metric\n                    bad_epochs = 0\n                else:\n                    bad_epochs += 1\n\n                if bad_epochs >= patience and _degradation_monotonic(last_vals):\n                    print(f\"Early-stop: no improvement on val_{metric} for {patience} epochs.\")\n                    stop_now = True\n\n        if stop_now:\n            break\n\n        dt = time.time() - t_epoch\n        print(f\"Epoch time: {dt/60:.2f} min\")\n\n    return history, model","metadata":{"id":"pWPxUzjx_Ehy","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T23:00:21.715856Z","iopub.execute_input":"2026-01-06T23:00:21.716383Z","iopub.status.idle":"2026-01-06T23:00:21.735112Z","shell.execute_reply.started":"2026-01-06T23:00:21.716361Z","shell.execute_reply":"2026-01-06T23:00:21.734385Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"import gc\n\ndef free_all_cuda(*names, verbose=True, globals_dict=None, locals_dict=None):\n    \"\"\"\n    Borra variables por nombre (strings) de globals/locals para evitar referencias colgadas en notebooks.\n    \"\"\"\n    if globals_dict is None: globals_dict = globals()\n    if locals_dict is None:  locals_dict  = locals()\n\n    for n in names:\n        if n in locals_dict:\n            del locals_dict[n]\n        if n in globals_dict:\n            del globals_dict[n]\n\n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.synchronize()\n        torch.cuda.empty_cache()\n        torch.cuda.ipc_collect()\n\n    if verbose and torch.cuda.is_available():\n        alloc = torch.cuda.memory_allocated() / 1024**2\n        res   = torch.cuda.memory_reserved() / 1024**2\n        print(f\"[CUDA] allocated={alloc:.1f} MB | reserved(cache)={res:.1f} MB\")\n\nfree_all_cuda(\"model\", \"optimizer\", \"scaler\", \"scheduler\", \"batch\", \"loss\", \"outputs\", \"logits\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cIv5mdnqAX74","outputId":"8f6a3f63-463b-488f-b090-492d75d0d27e","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T23:01:32.745245Z","iopub.execute_input":"2026-01-06T23:01:32.745625Z","iopub.status.idle":"2026-01-06T23:01:33.043882Z","shell.execute_reply.started":"2026-01-06T23:01:32.745596Z","shell.execute_reply":"2026-01-06T23:01:33.043160Z"}},"outputs":[{"name":"stdout","text":"[CUDA] allocated=252.3 MB | reserved(cache)=1050.0 MB\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"def cifar64_stages_t4_tinyplus(drop_path=0.08):\n    # resoluciones: 64 -> 32 -> 16 -> 8\n    return [\n        StageCfg(dim=64,  depth=2, num_heads=2,  grid_size=8, outlook_heads=2,  drop_path=drop_path),\n        StageCfg(dim=128, depth=2, num_heads=4,  grid_size=8, outlook_heads=4,  drop_path=drop_path),\n        StageCfg(dim=256, depth=3, num_heads=8,  grid_size=4, outlook_heads=8,  drop_path=drop_path),\n        StageCfg(dim=384, depth=1, num_heads=6,  grid_size=2, outlook_heads=6,  drop_path=drop_path),]\n\nstages = cifar64_stages_t4_tinyplus()\nmodel = OutlookerFrontGridNet(num_classes=100, stages=stages, stem_dim=64, outlooker_front_depth=1, dpr_max=0.1)\n\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nhistory, model = train_model(\n    model=model,\n    train_loader=train_loader,\n    epochs=50,\n    val_loader=val_loader,\n    device=device,\n\n    lr=5e-4,\n    weight_decay=0.05,\n\n    autocast_dtype=\"fp16\" if device == \"cuda\" else \"fp32\",\n    use_amp=(device == \"cuda\"),\n    grad_clip_norm=1.0,\n\n    warmup_ratio=0.05,\n    min_lr=1e-6,\n\n    label_smoothing=0.0,\n\n    print_every=100,\n    save_path=\"best_maxout_medium.pt\",\n    last_path=\"last_maxout_medium.pt\",\n    resume_path=None,\n\n    # Augmentations\n    mix_prob=0.5,\n    mixup_alpha=0.0,\n    cutmix_alpha=1.0,\n\n    num_classes=100,\n    channels_last=True)\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MWflG0_8_doZ","outputId":"b7a07792-aa32-4217-8654-76ee2299a580","collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Epoch 1/50 ===\n","[train step 100/352] loss 4.4824 | top1 3.52% | top3 8.54% | top5 12.80% | 116.3 img/s | lr 5.68e-05\n","[train step 200/352] loss 4.3496 | top1 5.12% | top3 12.41% | top5 18.10% | 120.4 img/s | lr 1.14e-04\n","[train step 300/352] loss 4.2459 | top1 6.55% | top3 15.18% | top5 21.68% | 121.8 img/s | lr 1.70e-04\n","[Train] loss 4.2034 | top1 7.19% | top3 16.40% | top5 23.26% | lr 2.00e-04\n","[Val]   loss 3.7152 | top1 13.10% | top3 27.08% | top5 36.98%\n","Best saved to best_maxout_medium.pt (val top1 13.10%)\n","Epoch time: 6.52 min\n","\n","=== Epoch 2/50 ===\n","[train step 100/352] loss 3.7666 | top1 13.28% | top3 28.25% | top5 37.82% | 124.1 img/s | lr 2.57e-04\n","[train step 200/352] loss 3.6872 | top1 14.67% | top3 30.08% | top5 39.87% | 124.3 img/s | lr 3.14e-04\n","[train step 300/352] loss 3.6362 | top1 15.90% | top3 32.04% | top5 41.82% | 124.5 img/s | lr 3.70e-04\n","[Train] loss 3.5984 | top1 16.66% | top3 33.18% | top5 43.03% | lr 4.00e-04\n","[Val]   loss 3.1387 | top1 22.26% | top3 41.72% | top5 51.90%\n","Best saved to best_maxout_medium.pt (val top1 22.26%)\n","Epoch time: 6.28 min\n","\n","=== Epoch 3/50 ===\n","[train step 100/352] loss 3.3235 | top1 22.07% | top3 40.70% | top5 51.19% | 124.2 img/s | lr 4.57e-04\n","[train step 200/352] loss 3.3131 | top1 22.66% | top3 41.90% | top5 52.16% | 124.2 img/s | lr 5.00e-04\n","[train step 300/352] loss 3.2181 | top1 24.46% | top3 44.23% | top5 54.47% | 124.2 img/s | lr 5.00e-04\n","[Train] loss 3.1865 | top1 25.34% | top3 45.32% | top5 55.53% | lr 5.00e-04\n","[Val]   loss 2.5816 | top1 33.74% | top3 56.80% | top5 67.38%\n","Best saved to best_maxout_medium.pt (val top1 33.74%)\n","Epoch time: 6.29 min\n","\n","=== Epoch 4/50 ===\n","[train step 100/352] loss 2.8811 | top1 31.88% | top3 52.71% | top5 62.73% | 124.0 img/s | lr 5.00e-04\n","[train step 200/352] loss 2.8754 | top1 32.56% | top3 53.46% | top5 63.39% | 124.2 img/s | lr 4.99e-04\n","[train step 300/352] loss 2.8531 | top1 33.13% | top3 54.12% | top5 63.94% | 124.2 img/s | lr 4.99e-04\n","[Train] loss 2.8413 | top1 33.42% | top3 54.47% | top5 64.25% | lr 4.99e-04\n","[Val]   loss 2.2664 | top1 41.64% | top3 63.34% | top5 73.00%\n","Best saved to best_maxout_medium.pt (val top1 41.64%)\n","Epoch time: 6.29 min\n","\n","=== Epoch 5/50 ===\n","[train step 100/352] loss 2.7554 | top1 36.68% | top3 57.63% | top5 67.02% | 124.2 img/s | lr 4.98e-04\n","[train step 200/352] loss 2.6385 | top1 38.87% | top3 60.48% | top5 69.99% | 124.3 img/s | lr 4.98e-04\n","[train step 300/352] loss 2.6300 | top1 39.17% | top3 60.99% | top5 70.30% | 124.3 img/s | lr 4.97e-04\n","[Train] loss 2.6306 | top1 39.17% | top3 60.76% | top5 69.97% | lr 4.97e-04\n","[Val]   loss 2.0569 | top1 46.62% | top3 68.92% | top5 77.44%\n","Best saved to best_maxout_medium.pt (val top1 46.62%)\n","Epoch time: 6.29 min\n","\n","=== Epoch 6/50 ===\n","[train step 100/352] loss 2.5570 | top1 41.14% | top3 62.41% | top5 71.21% | 124.3 img/s | lr 4.96e-04\n","[train step 200/352] loss 2.4851 | top1 42.60% | top3 63.87% | top5 72.66% | 124.4 img/s | lr 4.95e-04\n","[train step 300/352] loss 2.4134 | top1 44.18% | top3 65.59% | top5 74.33% | 124.4 img/s | lr 4.94e-04\n","[Train] loss 2.3705 | top1 45.01% | top3 66.49% | top5 75.15% | lr 4.93e-04\n","[Val]   loss 1.8467 | top1 49.38% | top3 72.60% | top5 81.04%\n","Best saved to best_maxout_medium.pt (val top1 49.38%)\n","Epoch time: 6.28 min\n","\n","=== Epoch 7/50 ===\n","[train step 100/352] loss 2.2133 | top1 48.03% | top3 68.20% | top5 76.55% | 124.4 img/s | lr 4.92e-04\n","[train step 200/352] loss 2.2511 | top1 47.77% | top3 68.21% | top5 76.45% | 124.4 img/s | lr 4.91e-04\n","[train step 300/352] loss 2.2122 | top1 48.56% | top3 69.24% | top5 77.38% | 124.4 img/s | lr 4.90e-04\n","[Train] loss 2.2026 | top1 48.93% | top3 69.58% | top5 77.64% | lr 4.89e-04\n","[Val]   loss 1.6619 | top1 54.58% | top3 75.72% | top5 83.36%\n","Best saved to best_maxout_medium.pt (val top1 54.58%)\n","Epoch time: 6.29 min\n","\n","=== Epoch 8/50 ===\n","[train step 100/352] loss 2.1667 | top1 50.24% | top3 70.57% | top5 78.34% | 124.2 img/s | lr 4.88e-04\n","[train step 200/352] loss 2.2344 | top1 49.14% | top3 69.39% | top5 77.31% | 124.3 img/s | lr 4.86e-04\n","[train step 300/352] loss 2.2027 | top1 49.58% | top3 69.84% | top5 77.74% | 124.3 img/s | lr 4.85e-04\n","[Train] loss 2.1837 | top1 49.96% | top3 70.37% | top5 78.17% | lr 4.84e-04\n","[Val]   loss 1.6012 | top1 55.48% | top3 77.80% | top5 85.08%\n","Best saved to best_maxout_medium.pt (val top1 55.48%)\n","Epoch time: 6.29 min\n","\n","=== Epoch 9/50 ===\n","[train step 100/352] loss 2.1034 | top1 52.78% | top3 73.38% | top5 80.63% | 124.0 img/s | lr 4.82e-04\n","[train step 200/352] loss 2.1069 | top1 52.96% | top3 73.37% | top5 80.89% | 124.3 img/s | lr 4.80e-04\n","[train step 300/352] loss 2.1078 | top1 52.71% | top3 73.01% | top5 80.49% | 124.4 img/s | lr 4.78e-04\n","[Train] loss 2.0979 | top1 52.86% | top3 73.10% | top5 80.61% | lr 4.77e-04\n","[Val]   loss 1.5034 | top1 59.00% | top3 79.38% | top5 86.46%\n","Best saved to best_maxout_medium.pt (val top1 59.00%)\n","Epoch time: 6.28 min\n","\n","=== Epoch 10/50 ===\n","[train step 100/352] loss 1.8581 | top1 57.03% | top3 77.27% | top5 83.52% | 124.1 img/s | lr 4.75e-04\n","[train step 200/352] loss 1.9676 | top1 55.17% | top3 74.93% | top5 81.55% | 124.1 img/s | lr 4.73e-04\n","[train step 300/352] loss 1.9823 | top1 55.11% | top3 74.75% | top5 81.53% | 124.2 img/s | lr 4.71e-04\n","[Train] loss 1.9929 | top1 54.99% | top3 74.55% | top5 81.42% | lr 4.70e-04\n","[Val]   loss 1.4354 | top1 61.54% | top3 80.80% | top5 87.46%\n","Best saved to best_maxout_medium.pt (val top1 61.54%)\n","Epoch time: 6.29 min\n","\n","=== Epoch 11/50 ===\n","[train step 100/352] loss 1.9344 | top1 57.34% | top3 77.02% | top5 83.65% | 124.1 img/s | lr 4.68e-04\n","[train step 200/352] loss 1.8634 | top1 58.38% | top3 77.76% | top5 84.16% | 124.3 img/s | lr 4.65e-04\n","[train step 300/352] loss 1.9139 | top1 57.36% | top3 76.61% | top5 83.23% | 124.3 img/s | lr 4.63e-04\n","[Train] loss 1.9122 | top1 57.27% | top3 76.63% | top5 83.13% | lr 4.62e-04\n","[Val]   loss 1.3606 | top1 63.28% | top3 82.72% | top5 88.94%\n","Best saved to best_maxout_medium.pt (val top1 63.28%)\n","Epoch time: 6.29 min\n","\n","=== Epoch 12/50 ===\n","[train step 100/352] loss 1.7725 | top1 61.30% | top3 79.74% | top5 85.98% | 124.1 img/s | lr 4.59e-04\n","[train step 200/352] loss 1.8422 | top1 59.66% | top3 78.14% | top5 84.52% | 124.3 img/s | lr 4.56e-04\n","[train step 300/352] loss 1.8640 | top1 59.47% | top3 78.38% | top5 84.65% | 124.3 img/s | lr 4.54e-04\n","[Train] loss 1.8735 | top1 59.20% | top3 78.15% | top5 84.44% | lr 4.52e-04\n","[Val]   loss 1.3538 | top1 63.10% | top3 82.78% | top5 88.92%\n","Epoch time: 6.28 min\n","\n","=== Epoch 13/50 ===\n","[train step 100/352] loss 1.6372 | top1 62.61% | top3 81.23% | top5 87.07% | 124.3 img/s | lr 4.50e-04\n","[train step 200/352] loss 1.7869 | top1 59.89% | top3 78.52% | top5 84.88% | 124.3 img/s | lr 4.47e-04\n","[train step 300/352] loss 1.8104 | top1 59.94% | top3 78.59% | top5 84.92% | 124.3 img/s | lr 4.44e-04\n","[Train] loss 1.8093 | top1 60.15% | top3 78.78% | top5 85.15% | lr 4.42e-04\n","[Val]   loss 1.2943 | top1 64.20% | top3 83.90% | top5 89.48%\n","Best saved to best_maxout_medium.pt (val top1 64.20%)\n","Epoch time: 6.29 min\n","\n","=== Epoch 14/50 ===\n","[train step 100/352] loss 1.8028 | top1 61.98% | top3 80.66% | top5 86.74% | 124.0 img/s | lr 4.39e-04\n","[train step 200/352] loss 1.7823 | top1 62.16% | top3 80.48% | top5 86.50% | 124.1 img/s | lr 4.36e-04\n","[train step 300/352] loss 1.7811 | top1 61.92% | top3 80.32% | top5 86.38% | 124.2 img/s | lr 4.33e-04\n","[Train] loss 1.7537 | top1 62.16% | top3 80.38% | top5 86.39% | lr 4.31e-04\n","[Val]   loss 1.2579 | top1 65.70% | top3 84.02% | top5 89.70%\n","Best saved to best_maxout_medium.pt (val top1 65.70%)\n","Epoch time: 6.29 min\n","\n","=== Epoch 15/50 ===\n","[train step 100/352] loss 1.5372 | top1 66.00% | top3 82.76% | top5 88.27% | 124.2 img/s | lr 4.28e-04\n","[train step 200/352] loss 1.5850 | top1 65.61% | top3 82.88% | top5 88.23% | 124.6 img/s | lr 4.25e-04\n","[train step 300/352] loss 1.6055 | top1 65.19% | top3 82.56% | top5 87.94% | 124.6 img/s | lr 4.21e-04\n","[Train] loss 1.6077 | top1 65.16% | top3 82.58% | top5 87.87% | lr 4.19e-04\n","[Val]   loss 1.2226 | top1 65.78% | top3 84.84% | top5 90.36%\n","Best saved to best_maxout_medium.pt (val top1 65.78%)\n","Epoch time: 6.28 min\n","\n","=== Epoch 16/50 ===\n","[train step 100/352] loss 1.6648 | top1 63.43% | top3 81.03% | top5 86.47% | 124.2 img/s | lr 4.16e-04\n","[train step 200/352] loss 1.6859 | top1 63.93% | top3 81.59% | top5 86.95% | 124.4 img/s | lr 4.12e-04\n","[train step 300/352] loss 1.6816 | top1 64.15% | top3 81.93% | top5 87.23% | 124.6 img/s | lr 4.09e-04\n","[Train] loss 1.6802 | top1 63.98% | top3 81.70% | top5 87.12% | lr 4.07e-04\n","[Val]   loss 1.1720 | top1 67.86% | top3 85.88% | top5 91.18%\n","Best saved to best_maxout_medium.pt (val top1 67.86%)\n","Epoch time: 6.27 min\n","\n","=== Epoch 17/50 ===\n","[train step 100/352] loss 1.6380 | top1 64.52% | top3 81.57% | top5 86.95% | 124.3 img/s | lr 4.03e-04\n","[train step 200/352] loss 1.6800 | top1 64.12% | top3 81.31% | top5 86.81% | 124.4 img/s | lr 4.00e-04\n","[train step 300/352] loss 1.6059 | top1 65.50% | top3 82.45% | top5 87.69% | 124.5 img/s | lr 3.96e-04\n","[Train] loss 1.6026 | top1 65.51% | top3 82.32% | top5 87.61% | lr 3.94e-04\n","[Val]   loss 1.1343 | top1 68.84% | top3 86.06% | top5 91.66%\n","Best saved to best_maxout_medium.pt (val top1 68.84%)\n","Epoch time: 6.28 min\n","\n","=== Epoch 18/50 ===\n","[train step 100/352] loss 1.5897 | top1 67.96% | top3 83.98% | top5 88.92% | 124.2 img/s | lr 3.90e-04\n","[train step 200/352] loss 1.6115 | top1 67.04% | top3 83.49% | top5 88.61% | 124.4 img/s | lr 3.86e-04\n","[train step 300/352] loss 1.5818 | top1 67.35% | top3 84.00% | top5 88.99% | 124.5 img/s | lr 3.82e-04\n","[Train] loss 1.5868 | top1 66.94% | top3 83.66% | top5 88.66% | lr 3.80e-04\n","[Val]   loss 1.0996 | top1 69.46% | top3 87.06% | top5 92.12%\n","Best saved to best_maxout_medium.pt (val top1 69.46%)\n","Epoch time: 6.28 min\n","\n","=== Epoch 19/50 ===\n","[train step 100/352] loss 1.4447 | top1 71.78% | top3 87.24% | top5 91.46% | 124.6 img/s | lr 3.76e-04\n","[train step 200/352] loss 1.5354 | top1 68.95% | top3 85.09% | top5 89.68% | 124.7 img/s | lr 3.72e-04\n","[train step 300/352] loss 1.5625 | top1 68.02% | top3 84.28% | top5 89.11% | 124.8 img/s | lr 3.68e-04\n","[Train] loss 1.5531 | top1 68.30% | top3 84.59% | top5 89.35% | lr 3.66e-04\n","[Val]   loss 1.0790 | top1 70.46% | top3 87.12% | top5 91.86%\n","Best saved to best_maxout_medium.pt (val top1 70.46%)\n","Epoch time: 6.26 min\n","\n","=== Epoch 20/50 ===\n","[train step 100/352] loss 1.3439 | top1 70.69% | top3 85.73% | top5 90.02% | 124.1 img/s | lr 3.61e-04\n","[train step 200/352] loss 1.4315 | top1 70.48% | top3 85.94% | top5 90.29% | 124.4 img/s | lr 3.57e-04\n","[train step 300/352] loss 1.3837 | top1 71.07% | top3 86.35% | top5 90.62% | 124.4 img/s | lr 3.53e-04\n","[Train] loss 1.4216 | top1 70.36% | top3 85.79% | top5 90.18% | lr 3.51e-04\n","[Val]   loss 1.0720 | top1 70.24% | top3 87.06% | top5 92.14%\n","Epoch time: 6.27 min\n","\n","=== Epoch 21/50 ===\n","[train step 100/352] loss 1.4903 | top1 69.37% | top3 84.76% | top5 89.58% | 124.3 img/s | lr 3.46e-04\n","[train step 200/352] loss 1.4560 | top1 70.06% | top3 85.38% | top5 90.04% | 124.5 img/s | lr 3.42e-04\n","[train step 300/352] loss 1.4663 | top1 70.02% | top3 85.44% | top5 90.08% | 124.5 img/s | lr 3.38e-04\n","[Train] loss 1.4493 | top1 69.98% | top3 85.37% | top5 90.01% | lr 3.35e-04\n","[Val]   loss 1.0318 | top1 70.94% | top3 88.38% | top5 92.40%\n","Best saved to best_maxout_medium.pt (val top1 70.94%)\n","Epoch time: 6.28 min\n","\n","=== Epoch 22/50 ===\n","[train step 100/352] loss 1.4238 | top1 71.01% | top3 85.85% | top5 90.24% | 124.2 img/s | lr 3.31e-04\n","[train step 200/352] loss 1.4374 | top1 70.25% | top3 85.29% | top5 89.91% | 124.5 img/s | lr 3.27e-04\n","[train step 300/352] loss 1.4240 | top1 70.76% | top3 85.65% | top5 90.13% | 124.6 img/s | lr 3.22e-04\n","[Train] loss 1.4323 | top1 70.70% | top3 85.65% | top5 90.18% | lr 3.20e-04\n","[Val]   loss 1.0553 | top1 71.14% | top3 87.56% | top5 92.26%\n","Best saved to best_maxout_medium.pt (val top1 71.14%)\n","Epoch time: 6.27 min\n","\n","=== Epoch 23/50 ===\n","[train step 100/352] loss 1.2418 | top1 74.09% | top3 88.05% | top5 91.87% | 124.0 img/s | lr 3.15e-04\n","[train step 200/352] loss 1.3144 | top1 72.97% | top3 87.30% | top5 91.36% | 124.3 img/s | lr 3.11e-04\n","[train step 300/352] loss 1.2780 | top1 74.12% | top3 88.16% | top5 92.05% | 124.3 img/s | lr 3.06e-04\n","[Train] loss 1.3024 | top1 73.51% | top3 87.75% | top5 91.72% | lr 3.04e-04\n","[Val]   loss 1.0641 | top1 71.90% | top3 87.64% | top5 92.10%\n","Best saved to best_maxout_medium.pt (val top1 71.90%)\n","Epoch time: 6.29 min\n","\n","=== Epoch 24/50 ===\n","[train step 100/352] loss 1.2293 | top1 76.10% | top3 89.88% | top5 93.32% | 123.9 img/s | lr 2.99e-04\n","[train step 200/352] loss 1.2360 | top1 75.21% | top3 89.18% | top5 92.77% | 124.2 img/s | lr 2.95e-04\n","[train step 300/352] loss 1.2532 | top1 74.86% | top3 88.95% | top5 92.61% | 124.4 img/s | lr 2.90e-04\n","[Train] loss 1.2577 | top1 74.67% | top3 88.72% | top5 92.42% | lr 2.87e-04\n","[Val]   loss 0.9797 | top1 72.44% | top3 88.66% | top5 93.24%\n","Best saved to best_maxout_medium.pt (val top1 72.44%)\n","Epoch time: 6.28 min\n","\n","=== Epoch 25/50 ===\n","[train step 100/352] loss 1.3451 | top1 74.61% | top3 87.83% | top5 91.61% | 124.2 img/s | lr 2.83e-04\n","[train step 200/352] loss 1.2477 | top1 76.68% | top3 89.64% | top5 93.00% | 124.3 img/s | lr 2.78e-04\n","[train step 300/352] loss 1.2304 | top1 76.65% | top3 89.80% | top5 93.12% | 124.4 img/s | lr 2.74e-04\n","[Train] loss 1.2666 | top1 75.66% | top3 89.07% | top5 92.64% | lr 2.71e-04\n","[Val]   loss 1.0109 | top1 72.40% | top3 89.08% | top5 93.38%\n","Epoch time: 6.27 min\n","\n","=== Epoch 26/50 ===\n","[train step 100/352] loss 1.1214 | top1 77.27% | top3 89.31% | top5 92.75% | 124.0 img/s | lr 2.66e-04\n","[train step 200/352] loss 1.1939 | top1 75.91% | top3 88.72% | top5 92.40% | 124.4 img/s | lr 2.62e-04\n","[train step 300/352] loss 1.2553 | top1 74.86% | top3 88.18% | top5 91.97% | 124.5 img/s | lr 2.57e-04\n","[Train] loss 1.2955 | top1 74.40% | top3 87.88% | top5 91.79% | lr 2.55e-04\n","[Val]   loss 0.9700 | top1 73.10% | top3 89.00% | top5 93.40%\n","Best saved to best_maxout_medium.pt (val top1 73.10%)\n","Epoch time: 6.27 min\n","\n","=== Epoch 27/50 ===\n","[train step 100/352] loss 1.2731 | top1 77.83% | top3 90.51% | top5 94.03% | 124.2 img/s | lr 2.50e-04\n","[train step 200/352] loss 1.2973 | top1 76.22% | top3 89.25% | top5 93.00% | 124.2 img/s | lr 2.45e-04\n","[train step 300/352] loss 1.2550 | top1 76.01% | top3 88.94% | top5 92.66% | 124.4 img/s | lr 2.41e-04\n","[Train] loss 1.2712 | top1 75.55% | top3 88.62% | top5 92.40% | lr 2.38e-04\n","[Val]   loss 0.9285 | top1 73.50% | top3 89.40% | top5 93.76%\n","Best saved to best_maxout_medium.pt (val top1 73.50%)\n","Epoch time: 6.28 min\n","\n","=== Epoch 28/50 ===\n","[train step 100/352] loss 0.9674 | top1 80.22% | top3 91.04% | top5 93.98% | 124.2 img/s | lr 2.33e-04\n","[train step 200/352] loss 1.0958 | top1 78.81% | top3 90.63% | top5 93.68% | 124.2 img/s | lr 2.29e-04\n","[train step 300/352] loss 1.1269 | top1 78.37% | top3 90.26% | top5 93.44% | 124.4 img/s | lr 2.24e-04\n","[Train] loss 1.1593 | top1 77.67% | top3 89.82% | top5 93.10% | lr 2.22e-04\n","[Val]   loss 0.9325 | top1 73.64% | top3 89.58% | top5 93.68%\n","Best saved to best_maxout_medium.pt (val top1 73.64%)\n","Epoch time: 6.28 min\n","\n","=== Epoch 29/50 ===\n","[train step 100/352] loss 1.2889 | top1 75.85% | top3 88.86% | top5 92.51% | 124.7 img/s | lr 2.17e-04\n","[train step 200/352] loss 1.2546 | top1 76.38% | top3 89.18% | top5 92.80% | 124.8 img/s | lr 2.12e-04\n","[train step 300/352] loss 1.2349 | top1 76.81% | top3 89.45% | top5 93.01% | 124.8 img/s | lr 2.08e-04\n","[Train] loss 1.2314 | top1 77.06% | top3 89.52% | top5 93.02% | lr 2.05e-04\n","[Val]   loss 0.9168 | top1 74.78% | top3 90.08% | top5 93.72%\n","Best saved to best_maxout_medium.pt (val top1 74.78%)\n","Epoch time: 6.26 min\n","\n","=== Epoch 30/50 ===\n"]}],"execution_count":null},{"cell_type":"code","source":"def cifar64_stages_t4_tinyplus(drop_path=0.08):\n    # resoluciones: 64 -> 32 -> 16 -> 8\n    return [\n        StageCfg(dim=64,  depth=2, num_heads=2,  grid_size=8, outlook_heads=2,  drop_path=drop_path),\n        StageCfg(dim=128, depth=2, num_heads=4,  grid_size=8, outlook_heads=4,  drop_path=drop_path),\n        StageCfg(dim=256, depth=3, num_heads=8,  grid_size=4, outlook_heads=8,  drop_path=drop_path),\n        StageCfg(dim=384, depth=1, num_heads=6,  grid_size=2, outlook_heads=6,  drop_path=drop_path),]\n\n\nstages = cifar64_stages_t4_tinyplus()\n\nmodel = MaxOutNet(num_classes=100, stages=stages, stem_dim=64, dpr_max=0.1)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nhistory, model = train_model(\n    model=model,\n    train_loader=train_loader,\n    epochs=50,\n    val_loader=val_loader,\n    device=device,\n\n    lr=5e-4,\n    weight_decay=0.05,\n\n    autocast_dtype=\"fp16\" if device == \"cuda\" else \"fp32\",\n    use_amp=(device == \"cuda\"),\n    grad_clip_norm=1.0,\n\n    warmup_ratio=0.05,\n    min_lr=1e-6,\n\n    label_smoothing=0.0,\n\n    print_every=100,\n    save_path=\"best_maxout_medium.pt\",\n    last_path=\"last_maxout_medium.pt\",\n    resume_path=None,\n\n    # Augmentations\n    mix_prob=0.5,\n    mixup_alpha=0.0,\n    cutmix_alpha=1.0,\n\n    num_classes=100,\n    channels_last=True)\n\n#10.5 GB","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T23:04:09.596577Z","iopub.execute_input":"2026-01-06T23:04:09.597256Z","iopub.status.idle":"2026-01-07T07:32:22.778401Z","shell.execute_reply.started":"2026-01-06T23:04:09.597232Z","shell.execute_reply":"2026-01-07T07:32:22.777588Z"}},"outputs":[{"name":"stdout","text":"\n=== Epoch 1/50 ===\n[train step 100/704] loss 4.5330 | top1 3.03% | top3 7.48% | top5 11.03% | 80.5 img/s | lr 2.84e-05\n[train step 200/704] loss 4.4217 | top1 4.42% | top3 10.75% | top5 15.47% | 78.5 img/s | lr 5.68e-05\n[train step 300/704] loss 4.3576 | top1 4.95% | top3 12.22% | top5 17.66% | 78.0 img/s | lr 8.52e-05\n[train step 400/704] loss 4.3060 | top1 5.63% | top3 13.75% | top5 19.63% | 77.8 img/s | lr 1.14e-04\n[train step 500/704] loss 4.2664 | top1 6.24% | top3 14.78% | top5 21.04% | 77.6 img/s | lr 1.42e-04\n[train step 600/704] loss 4.2211 | top1 6.77% | top3 15.98% | top5 22.59% | 77.5 img/s | lr 1.70e-04\n[train step 700/704] loss 4.1717 | top1 7.41% | top3 17.22% | top5 24.22% | 77.4 img/s | lr 1.99e-04\n[Train] loss 4.1698 | top1 7.42% | top3 17.24% | top5 24.27% | lr 2.00e-04\n[Val]   loss 3.6764 | top1 13.70% | top3 29.00% | top5 37.76%\nBest saved to best_maxout_medium.pt (val top1 13.70%)\nEpoch time: 10.12 min\n\n=== Epoch 2/50 ===\n[train step 100/704] loss 3.7765 | top1 13.48% | top3 26.75% | top5 36.34% | 77.0 img/s | lr 2.28e-04\n[train step 200/704] loss 3.7698 | top1 13.43% | top3 27.49% | top5 37.23% | 77.0 img/s | lr 2.57e-04\n[train step 300/704] loss 3.7180 | top1 14.62% | top3 29.49% | top5 39.18% | 77.1 img/s | lr 2.85e-04\n[train step 400/704] loss 3.7045 | top1 14.84% | top3 30.02% | top5 39.79% | 77.1 img/s | lr 3.14e-04\n[train step 500/704] loss 3.6760 | top1 15.10% | top3 30.77% | top5 40.56% | 77.1 img/s | lr 3.42e-04\n[train step 600/704] loss 3.6540 | top1 15.65% | top3 31.62% | top5 41.51% | 77.1 img/s | lr 3.70e-04\n[train step 700/704] loss 3.6188 | top1 16.40% | top3 32.73% | top5 42.68% | 77.1 img/s | lr 3.99e-04\n[Train] loss 3.6178 | top1 16.41% | top3 32.75% | top5 42.70% | lr 4.00e-04\n[Val]   loss 3.0274 | top1 24.14% | top3 44.46% | top5 57.02%\nBest saved to best_maxout_medium.pt (val top1 24.14%)\nEpoch time: 10.15 min\n\n=== Epoch 3/50 ===\n[train step 100/704] loss 3.4145 | top1 21.59% | top3 40.36% | top5 51.45% | 76.8 img/s | lr 4.28e-04\n[train step 200/704] loss 3.4299 | top1 21.05% | top3 39.92% | top5 50.44% | 76.8 img/s | lr 4.57e-04\n[train step 300/704] loss 3.4038 | top1 21.41% | top3 40.16% | top5 50.82% | 76.9 img/s | lr 4.85e-04\n[train step 400/704] loss 3.3750 | top1 22.01% | top3 40.86% | top5 51.45% | 76.9 img/s | lr 5.00e-04\n[train step 500/704] loss 3.3461 | top1 22.60% | top3 41.49% | top5 51.87% | 76.9 img/s | lr 5.00e-04\n[train step 600/704] loss 3.3016 | top1 23.29% | top3 42.41% | top5 52.72% | 76.8 img/s | lr 5.00e-04\n[train step 700/704] loss 3.2823 | top1 23.73% | top3 42.99% | top5 53.28% | 76.9 img/s | lr 5.00e-04\n[Train] loss 3.2788 | top1 23.77% | top3 43.08% | top5 53.36% | lr 5.00e-04\n[Val]   loss 2.6492 | top1 31.10% | top3 53.64% | top5 64.46%\nBest saved to best_maxout_medium.pt (val top1 31.10%)\nEpoch time: 10.18 min\n\n=== Epoch 4/50 ===\n[train step 100/704] loss 2.9117 | top1 30.52% | top3 52.89% | top5 62.86% | 76.9 img/s | lr 5.00e-04\n[train step 200/704] loss 2.9108 | top1 30.97% | top3 52.21% | top5 62.38% | 76.9 img/s | lr 5.00e-04\n[train step 300/704] loss 2.8966 | top1 31.48% | top3 52.75% | top5 62.70% | 77.0 img/s | lr 5.00e-04\n[train step 400/704] loss 2.8684 | top1 31.97% | top3 53.27% | top5 63.20% | 77.0 img/s | lr 4.99e-04\n[train step 500/704] loss 2.8688 | top1 32.27% | top3 53.16% | top5 63.33% | 77.0 img/s | lr 4.99e-04\n[train step 600/704] loss 2.8571 | top1 32.66% | top3 53.62% | top5 63.67% | 77.0 img/s | lr 4.99e-04\n[train step 700/704] loss 2.8503 | top1 32.89% | top3 53.83% | top5 63.91% | 77.0 img/s | lr 4.99e-04\n[Train] loss 2.8500 | top1 32.90% | top3 53.84% | top5 63.93% | lr 4.99e-04\n[Val]   loss 2.3212 | top1 39.18% | top3 61.76% | top5 70.96%\nBest saved to best_maxout_medium.pt (val top1 39.18%)\nEpoch time: 10.17 min\n\n=== Epoch 5/50 ===\n[train step 100/704] loss 2.8184 | top1 35.53% | top3 56.77% | top5 65.00% | 77.0 img/s | lr 4.99e-04\n[train step 200/704] loss 2.7399 | top1 36.09% | top3 57.67% | top5 66.55% | 77.1 img/s | lr 4.98e-04\n[train step 300/704] loss 2.7359 | top1 36.39% | top3 57.93% | top5 67.01% | 77.1 img/s | lr 4.98e-04\n[train step 400/704] loss 2.7463 | top1 36.28% | top3 57.76% | top5 66.80% | 77.1 img/s | lr 4.98e-04\n[train step 500/704] loss 2.7067 | top1 36.91% | top3 58.44% | top5 67.54% | 77.1 img/s | lr 4.97e-04\n[train step 600/704] loss 2.7147 | top1 37.08% | top3 58.56% | top5 67.56% | 77.1 img/s | lr 4.97e-04\n[train step 700/704] loss 2.6971 | top1 37.56% | top3 58.89% | top5 67.91% | 77.1 img/s | lr 4.97e-04\n[Train] loss 2.6952 | top1 37.59% | top3 58.95% | top5 67.95% | lr 4.97e-04\n[Val]   loss 1.9644 | top1 48.18% | top3 70.34% | top5 79.02%\nBest saved to best_maxout_medium.pt (val top1 48.18%)\nEpoch time: 10.15 min\n\n=== Epoch 6/50 ===\n[train step 100/704] loss 2.5496 | top1 40.83% | top3 62.17% | top5 71.44% | 76.8 img/s | lr 4.96e-04\n[train step 200/704] loss 2.5315 | top1 40.91% | top3 62.29% | top5 71.45% | 76.8 img/s | lr 4.96e-04\n[train step 300/704] loss 2.5347 | top1 41.54% | top3 62.67% | top5 71.69% | 76.9 img/s | lr 4.95e-04\n[train step 400/704] loss 2.5350 | top1 41.50% | top3 62.45% | top5 71.37% | 77.0 img/s | lr 4.95e-04\n[train step 500/704] loss 2.5076 | top1 41.98% | top3 63.08% | top5 71.94% | 77.0 img/s | lr 4.94e-04\n[train step 600/704] loss 2.4861 | top1 42.41% | top3 63.45% | top5 72.28% | 77.0 img/s | lr 4.94e-04\n[train step 700/704] loss 2.4849 | top1 42.50% | top3 63.49% | top5 72.37% | 77.0 img/s | lr 4.93e-04\n[Train] loss 2.4843 | top1 42.52% | top3 63.52% | top5 72.39% | lr 4.93e-04\n[Val]   loss 1.8230 | top1 50.22% | top3 72.80% | top5 81.46%\nBest saved to best_maxout_medium.pt (val top1 50.22%)\nEpoch time: 10.16 min\n\n=== Epoch 7/50 ===\n[train step 100/704] loss 2.3873 | top1 44.89% | top3 66.25% | top5 74.59% | 76.8 img/s | lr 4.93e-04\n[train step 200/704] loss 2.4365 | top1 45.00% | top3 65.91% | top5 74.23% | 76.9 img/s | lr 4.92e-04\n[train step 300/704] loss 2.4106 | top1 45.20% | top3 65.94% | top5 74.58% | 76.9 img/s | lr 4.92e-04\n[train step 400/704] loss 2.3893 | top1 45.28% | top3 66.25% | top5 74.91% | 77.0 img/s | lr 4.91e-04\n[train step 500/704] loss 2.3893 | top1 45.36% | top3 66.08% | top5 74.81% | 77.0 img/s | lr 4.90e-04\n[train step 600/704] loss 2.3866 | top1 45.19% | top3 65.94% | top5 74.65% | 77.0 img/s | lr 4.90e-04\n[train step 700/704] loss 2.4011 | top1 45.12% | top3 65.88% | top5 74.59% | 77.0 img/s | lr 4.89e-04\n[Train] loss 2.4048 | top1 45.04% | top3 65.79% | top5 74.50% | lr 4.89e-04\n[Val]   loss 1.7558 | top1 53.68% | top3 74.78% | top5 82.48%\nBest saved to best_maxout_medium.pt (val top1 53.68%)\nEpoch time: 10.16 min\n\n=== Epoch 8/50 ===\n[train step 100/704] loss 2.3240 | top1 47.09% | top3 67.47% | top5 75.50% | 76.9 img/s | lr 4.88e-04\n[train step 200/704] loss 2.3112 | top1 47.48% | top3 68.08% | top5 76.29% | 76.9 img/s | lr 4.88e-04\n[train step 300/704] loss 2.2910 | top1 48.02% | top3 68.61% | top5 76.62% | 77.0 img/s | lr 4.87e-04\n[train step 400/704] loss 2.2597 | top1 48.48% | top3 69.05% | top5 77.01% | 77.0 img/s | lr 4.86e-04\n[train step 500/704] loss 2.2612 | top1 48.31% | top3 68.95% | top5 76.95% | 77.0 img/s | lr 4.85e-04\n[train step 600/704] loss 2.2477 | top1 48.66% | top3 69.19% | top5 77.17% | 77.0 img/s | lr 4.85e-04\n[train step 700/704] loss 2.2173 | top1 49.19% | top3 69.71% | top5 77.63% | 77.0 img/s | lr 4.84e-04\n[Train] loss 2.2179 | top1 49.18% | top3 69.71% | top5 77.63% | lr 4.84e-04\n[Val]   loss 1.6265 | top1 56.20% | top3 76.18% | top5 84.16%\nBest saved to best_maxout_medium.pt (val top1 56.20%)\nEpoch time: 10.16 min\n\n=== Epoch 9/50 ===\n[train step 100/704] loss 2.0203 | top1 53.94% | top3 73.83% | top5 81.17% | 76.8 img/s | lr 4.83e-04\n[train step 200/704] loss 2.1441 | top1 51.83% | top3 71.42% | top5 79.14% | 76.7 img/s | lr 4.82e-04\n[train step 300/704] loss 2.1404 | top1 51.61% | top3 71.42% | top5 79.18% | 76.8 img/s | lr 4.81e-04\n[train step 400/704] loss 2.1506 | top1 51.28% | top3 71.51% | top5 79.30% | 76.9 img/s | lr 4.80e-04\n[train step 500/704] loss 2.1733 | top1 50.68% | top3 71.06% | top5 78.88% | 76.9 img/s | lr 4.79e-04\n[train step 600/704] loss 2.1597 | top1 51.08% | top3 71.39% | top5 79.16% | 76.9 img/s | lr 4.78e-04\n[train step 700/704] loss 2.1598 | top1 50.95% | top3 71.28% | top5 79.02% | 77.0 img/s | lr 4.77e-04\n[Train] loss 2.1610 | top1 50.96% | top3 71.28% | top5 79.02% | lr 4.77e-04\n[Val]   loss 1.5421 | top1 58.70% | top3 79.40% | top5 86.20%\nBest saved to best_maxout_medium.pt (val top1 58.70%)\nEpoch time: 10.17 min\n\n=== Epoch 10/50 ===\n[train step 100/704] loss 2.0319 | top1 53.03% | top3 73.41% | top5 80.84% | 76.8 img/s | lr 4.76e-04\n[train step 200/704] loss 2.0105 | top1 53.80% | top3 74.01% | top5 81.28% | 76.8 img/s | lr 4.75e-04\n[train step 300/704] loss 2.0008 | top1 53.69% | top3 73.78% | top5 81.03% | 76.9 img/s | lr 4.74e-04\n[train step 400/704] loss 2.0321 | top1 53.49% | top3 73.50% | top5 80.73% | 77.0 img/s | lr 4.73e-04\n[train step 500/704] loss 2.0259 | top1 53.75% | top3 73.69% | top5 80.89% | 77.0 img/s | lr 4.72e-04\n[train step 600/704] loss 2.0423 | top1 53.55% | top3 73.56% | top5 80.75% | 77.0 img/s | lr 4.71e-04\n[train step 700/704] loss 2.0567 | top1 53.37% | top3 73.45% | top5 80.62% | 77.0 img/s | lr 4.70e-04\n[Train] loss 2.0592 | top1 53.30% | top3 73.40% | top5 80.56% | lr 4.70e-04\n[Val]   loss 1.4738 | top1 60.46% | top3 80.04% | top5 87.04%\nBest saved to best_maxout_medium.pt (val top1 60.46%)\nEpoch time: 10.17 min\n\n=== Epoch 11/50 ===\n[train step 100/704] loss 2.0097 | top1 55.19% | top3 75.03% | top5 81.89% | 77.0 img/s | lr 4.69e-04\n[train step 200/704] loss 2.0782 | top1 54.35% | top3 74.33% | top5 81.27% | 76.9 img/s | lr 4.68e-04\n[train step 300/704] loss 2.0201 | top1 55.03% | top3 75.02% | top5 81.69% | 76.8 img/s | lr 4.66e-04\n[train step 400/704] loss 2.0218 | top1 54.93% | top3 74.89% | top5 81.75% | 76.8 img/s | lr 4.65e-04\n[train step 500/704] loss 2.0145 | top1 55.26% | top3 75.33% | top5 82.21% | 76.9 img/s | lr 4.64e-04\n[train step 600/704] loss 2.0438 | top1 54.64% | top3 74.66% | top5 81.58% | 76.9 img/s | lr 4.63e-04\n[train step 700/704] loss 2.0233 | top1 54.88% | top3 74.91% | top5 81.81% | 76.9 img/s | lr 4.62e-04\n[Train] loss 2.0204 | top1 54.91% | top3 74.92% | top5 81.84% | lr 4.62e-04\n[Val]   loss 1.4136 | top1 61.00% | top3 81.16% | top5 87.78%\nBest saved to best_maxout_medium.pt (val top1 61.00%)\nEpoch time: 10.18 min\n\n=== Epoch 12/50 ===\n[train step 100/704] loss 1.9514 | top1 56.09% | top3 75.27% | top5 82.44% | 76.6 img/s | lr 4.60e-04\n[train step 200/704] loss 2.0105 | top1 55.50% | top3 74.19% | top5 81.26% | 76.7 img/s | lr 4.59e-04\n[train step 300/704] loss 1.9166 | top1 56.96% | top3 75.91% | top5 82.59% | 76.8 img/s | lr 4.58e-04\n[train step 400/704] loss 1.9334 | top1 57.32% | top3 76.25% | top5 82.89% | 76.8 img/s | lr 4.56e-04\n[train step 500/704] loss 1.9577 | top1 56.49% | top3 75.56% | top5 82.25% | 76.8 img/s | lr 4.55e-04\n[train step 600/704] loss 1.9720 | top1 56.32% | top3 75.52% | top5 82.21% | 76.8 img/s | lr 4.54e-04\n[train step 700/704] loss 1.9660 | top1 56.30% | top3 75.63% | top5 82.31% | 76.8 img/s | lr 4.52e-04\n[Train] loss 1.9670 | top1 56.30% | top3 75.64% | top5 82.30% | lr 4.52e-04\n[Val]   loss 1.3454 | top1 63.14% | top3 82.64% | top5 88.60%\nBest saved to best_maxout_medium.pt (val top1 63.14%)\nEpoch time: 10.19 min\n\n=== Epoch 13/50 ===\n[train step 100/704] loss 1.8210 | top1 58.30% | top3 76.78% | top5 83.14% | 77.0 img/s | lr 4.51e-04\n[train step 200/704] loss 1.8147 | top1 58.78% | top3 77.15% | top5 83.46% | 77.0 img/s | lr 4.50e-04\n[train step 300/704] loss 1.8509 | top1 58.59% | top3 77.03% | top5 83.37% | 76.9 img/s | lr 4.48e-04\n[train step 400/704] loss 1.8624 | top1 58.78% | top3 77.39% | top5 83.75% | 76.9 img/s | lr 4.47e-04\n[train step 500/704] loss 1.8220 | top1 59.42% | top3 78.13% | top5 84.35% | 77.0 img/s | lr 4.45e-04\n[train step 600/704] loss 1.8287 | top1 59.15% | top3 77.94% | top5 84.27% | 76.9 img/s | lr 4.44e-04\n[train step 700/704] loss 1.8435 | top1 58.89% | top3 77.82% | top5 84.21% | 76.9 img/s | lr 4.42e-04\n[Train] loss 1.8476 | top1 58.86% | top3 77.79% | top5 84.16% | lr 4.42e-04\n[Val]   loss 1.3644 | top1 63.10% | top3 82.56% | top5 88.64%\nEpoch time: 10.16 min\n\n=== Epoch 14/50 ===\n[train step 100/704] loss 1.6360 | top1 63.00% | top3 81.45% | top5 87.39% | 77.0 img/s | lr 4.41e-04\n[train step 200/704] loss 1.7254 | top1 61.00% | top3 79.60% | top5 85.62% | 76.8 img/s | lr 4.39e-04\n[train step 300/704] loss 1.7094 | top1 61.33% | top3 79.85% | top5 85.89% | 76.9 img/s | lr 4.38e-04\n[train step 400/704] loss 1.7545 | top1 60.88% | top3 79.37% | top5 85.34% | 77.0 img/s | lr 4.36e-04\n[train step 500/704] loss 1.7783 | top1 60.60% | top3 79.12% | top5 85.14% | 77.0 img/s | lr 4.35e-04\n[train step 600/704] loss 1.7759 | top1 60.83% | top3 79.28% | top5 85.30% | 77.0 img/s | lr 4.33e-04\n[train step 700/704] loss 1.7621 | top1 61.12% | top3 79.50% | top5 85.52% | 77.0 img/s | lr 4.31e-04\n[Train] loss 1.7627 | top1 61.12% | top3 79.50% | top5 85.52% | lr 4.31e-04\n[Val]   loss 1.2509 | top1 65.64% | top3 83.92% | top5 89.78%\nBest saved to best_maxout_medium.pt (val top1 65.64%)\nEpoch time: 10.16 min\n\n=== Epoch 15/50 ===\n[train step 100/704] loss 1.8504 | top1 60.72% | top3 78.73% | top5 85.19% | 76.8 img/s | lr 4.30e-04\n[train step 200/704] loss 1.8210 | top1 60.66% | top3 78.62% | top5 84.94% | 77.0 img/s | lr 4.28e-04\n[train step 300/704] loss 1.7833 | top1 61.01% | top3 79.19% | top5 85.43% | 77.0 img/s | lr 4.26e-04\n[train step 400/704] loss 1.7688 | top1 61.22% | top3 79.32% | top5 85.43% | 77.0 img/s | lr 4.25e-04\n[train step 500/704] loss 1.7681 | top1 61.29% | top3 79.46% | top5 85.50% | 77.1 img/s | lr 4.23e-04\n[train step 600/704] loss 1.7551 | top1 61.56% | top3 79.79% | top5 85.76% | 77.1 img/s | lr 4.21e-04\n[train step 700/704] loss 1.7566 | top1 61.45% | top3 79.69% | top5 85.68% | 77.1 img/s | lr 4.20e-04\n[Train] loss 1.7571 | top1 61.44% | top3 79.66% | top5 85.65% | lr 4.19e-04\n[Val]   loss 1.2298 | top1 65.94% | top3 84.54% | top5 90.20%\nBest saved to best_maxout_medium.pt (val top1 65.94%)\nEpoch time: 10.16 min\n\n=== Epoch 16/50 ===\n[train step 100/704] loss 1.6351 | top1 65.20% | top3 82.06% | top5 87.84% | 77.0 img/s | lr 4.18e-04\n[train step 200/704] loss 1.6365 | top1 65.17% | top3 82.52% | top5 88.09% | 76.9 img/s | lr 4.16e-04\n[train step 300/704] loss 1.6959 | top1 63.92% | top3 81.61% | top5 87.21% | 76.9 img/s | lr 4.14e-04\n[train step 400/704] loss 1.6775 | top1 64.18% | top3 81.81% | top5 87.39% | 77.0 img/s | lr 4.12e-04\n[train step 500/704] loss 1.6842 | top1 63.82% | top3 81.61% | top5 87.29% | 76.9 img/s | lr 4.11e-04\n[train step 600/704] loss 1.6629 | top1 64.16% | top3 81.89% | top5 87.53% | 77.0 img/s | lr 4.09e-04\n[train step 700/704] loss 1.6644 | top1 64.05% | top3 81.78% | top5 87.43% | 77.0 img/s | lr 4.07e-04\n[Train] loss 1.6665 | top1 64.05% | top3 81.78% | top5 87.42% | lr 4.07e-04\n[Val]   loss 1.1354 | top1 68.12% | top3 85.86% | top5 91.34%\nBest saved to best_maxout_medium.pt (val top1 68.12%)\nEpoch time: 10.17 min\n\n=== Epoch 17/50 ===\n[train step 100/704] loss 1.6050 | top1 65.39% | top3 82.56% | top5 87.58% | 76.7 img/s | lr 4.05e-04\n[train step 200/704] loss 1.6327 | top1 65.17% | top3 82.59% | top5 87.63% | 76.9 img/s | lr 4.03e-04\n[train step 300/704] loss 1.6473 | top1 64.84% | top3 82.07% | top5 87.43% | 76.9 img/s | lr 4.01e-04\n[train step 400/704] loss 1.6165 | top1 64.94% | top3 82.20% | top5 87.44% | 76.9 img/s | lr 4.00e-04\n[train step 500/704] loss 1.6105 | top1 64.94% | top3 82.18% | top5 87.40% | 77.0 img/s | lr 3.98e-04\n[train step 600/704] loss 1.6252 | top1 64.65% | top3 81.85% | top5 87.20% | 77.0 img/s | lr 3.96e-04\n[train step 700/704] loss 1.6218 | top1 64.79% | top3 81.91% | top5 87.32% | 77.0 img/s | lr 3.94e-04\n[Train] loss 1.6237 | top1 64.77% | top3 81.89% | top5 87.31% | lr 3.94e-04\n[Val]   loss 1.1631 | top1 68.94% | top3 86.40% | top5 91.48%\nBest saved to best_maxout_medium.pt (val top1 68.94%)\nEpoch time: 10.16 min\n\n=== Epoch 18/50 ===\n[train step 100/704] loss 1.5301 | top1 67.94% | top3 84.23% | top5 88.84% | 77.0 img/s | lr 3.92e-04\n[train step 200/704] loss 1.5516 | top1 67.06% | top3 83.88% | top5 88.45% | 76.9 img/s | lr 3.90e-04\n[train step 300/704] loss 1.5968 | top1 66.78% | top3 83.67% | top5 88.39% | 77.0 img/s | lr 3.88e-04\n[train step 400/704] loss 1.6142 | top1 66.50% | top3 83.55% | top5 88.48% | 77.0 img/s | lr 3.86e-04\n[train step 500/704] loss 1.5940 | top1 66.81% | top3 83.81% | top5 88.78% | 77.0 img/s | lr 3.84e-04\n[train step 600/704] loss 1.6040 | top1 66.55% | top3 83.54% | top5 88.61% | 77.0 img/s | lr 3.82e-04\n[train step 700/704] loss 1.6251 | top1 65.96% | top3 83.12% | top5 88.31% | 77.0 img/s | lr 3.80e-04\n[Train] loss 1.6310 | top1 65.84% | top3 83.01% | top5 88.22% | lr 3.80e-04\n[Val]   loss 1.1524 | top1 69.62% | top3 86.38% | top5 91.54%\nBest saved to best_maxout_medium.pt (val top1 69.62%)\nEpoch time: 10.17 min\n\n=== Epoch 19/50 ===\n[train step 100/704] loss 1.4966 | top1 66.80% | top3 83.62% | top5 88.47% | 76.9 img/s | lr 3.78e-04\n[train step 200/704] loss 1.5656 | top1 66.24% | top3 82.73% | top5 87.64% | 77.0 img/s | lr 3.76e-04\n[train step 300/704] loss 1.5619 | top1 66.69% | top3 83.27% | top5 88.07% | 77.1 img/s | lr 3.74e-04\n[train step 400/704] loss 1.5369 | top1 67.35% | top3 83.79% | top5 88.52% | 77.1 img/s | lr 3.72e-04\n[train step 500/704] loss 1.5696 | top1 66.71% | top3 83.20% | top5 88.15% | 77.1 img/s | lr 3.70e-04\n[train step 600/704] loss 1.5781 | top1 66.51% | top3 83.24% | top5 88.20% | 77.1 img/s | lr 3.68e-04\n[train step 700/704] loss 1.5690 | top1 66.90% | top3 83.59% | top5 88.55% | 77.1 img/s | lr 3.66e-04\n[Train] loss 1.5679 | top1 66.93% | top3 83.62% | top5 88.57% | lr 3.66e-04\n[Val]   loss 1.0392 | top1 71.46% | top3 88.34% | top5 92.56%\nBest saved to best_maxout_medium.pt (val top1 71.46%)\nEpoch time: 10.15 min\n\n=== Epoch 20/50 ===\n[train step 100/704] loss 1.4718 | top1 69.86% | top3 86.27% | top5 90.44% | 76.9 img/s | lr 3.64e-04\n[train step 200/704] loss 1.5222 | top1 68.72% | top3 85.21% | top5 89.91% | 77.0 img/s | lr 3.61e-04\n[train step 300/704] loss 1.5078 | top1 68.69% | top3 85.17% | top5 89.91% | 77.0 img/s | lr 3.59e-04\n[train step 400/704] loss 1.5482 | top1 67.62% | top3 84.18% | top5 89.09% | 77.0 img/s | lr 3.57e-04\n[train step 500/704] loss 1.5707 | top1 67.19% | top3 83.82% | top5 88.80% | 77.0 img/s | lr 3.55e-04\n[train step 600/704] loss 1.5615 | top1 67.42% | top3 83.94% | top5 88.87% | 77.0 img/s | lr 3.53e-04\n[train step 700/704] loss 1.5727 | top1 67.18% | top3 83.81% | top5 88.81% | 77.0 img/s | lr 3.51e-04\n[Train] loss 1.5751 | top1 67.11% | top3 83.76% | top5 88.77% | lr 3.51e-04\n[Val]   loss 1.1105 | top1 69.74% | top3 86.96% | top5 91.98%\nEpoch time: 10.16 min\n\n=== Epoch 21/50 ===\n[train step 100/704] loss 1.5354 | top1 67.89% | top3 84.06% | top5 89.64% | 77.0 img/s | lr 3.49e-04\n[train step 200/704] loss 1.4909 | top1 69.25% | top3 84.94% | top5 89.98% | 76.9 img/s | lr 3.46e-04\n[train step 300/704] loss 1.5536 | top1 67.95% | top3 83.82% | top5 88.93% | 76.9 img/s | lr 3.44e-04\n[train step 400/704] loss 1.5204 | top1 68.48% | top3 84.20% | top5 89.19% | 77.0 img/s | lr 3.42e-04\n[train step 500/704] loss 1.5004 | top1 68.95% | top3 84.66% | top5 89.56% | 77.0 img/s | lr 3.40e-04\n[train step 600/704] loss 1.4975 | top1 69.14% | top3 84.94% | top5 89.81% | 77.0 img/s | lr 3.38e-04\n[train step 700/704] loss 1.4915 | top1 69.12% | top3 84.99% | top5 89.83% | 77.0 img/s | lr 3.35e-04\n[Train] loss 1.4953 | top1 69.06% | top3 84.96% | top5 89.81% | lr 3.35e-04\n[Val]   loss 1.0094 | top1 71.72% | top3 88.10% | top5 92.94%\nBest saved to best_maxout_medium.pt (val top1 71.72%)\nEpoch time: 10.16 min\n\n=== Epoch 22/50 ===\n[train step 100/704] loss 1.4150 | top1 70.66% | top3 85.98% | top5 90.33% | 76.7 img/s | lr 3.33e-04\n[train step 200/704] loss 1.4533 | top1 71.17% | top3 86.47% | top5 90.57% | 76.9 img/s | lr 3.31e-04\n[train step 300/704] loss 1.4086 | top1 71.22% | top3 86.58% | top5 90.52% | 76.9 img/s | lr 3.29e-04\n[train step 400/704] loss 1.4007 | top1 71.31% | top3 86.81% | top5 90.82% | 76.9 img/s | lr 3.27e-04\n[train step 500/704] loss 1.4222 | top1 70.59% | top3 86.28% | top5 90.45% | 76.9 img/s | lr 3.24e-04\n[train step 600/704] loss 1.4118 | top1 70.79% | top3 86.41% | top5 90.62% | 76.9 img/s | lr 3.22e-04\n[train step 700/704] loss 1.3951 | top1 71.04% | top3 86.53% | top5 90.67% | 76.9 img/s | lr 3.20e-04\n[Train] loss 1.3950 | top1 71.05% | top3 86.54% | top5 90.69% | lr 3.20e-04\n[Val]   loss 1.0307 | top1 71.56% | top3 88.44% | top5 92.72%\nEpoch time: 10.17 min\n\n=== Epoch 23/50 ===\n[train step 100/704] loss 1.5410 | top1 68.55% | top3 83.91% | top5 88.86% | 76.9 img/s | lr 3.17e-04\n[train step 200/704] loss 1.5023 | top1 69.82% | top3 84.84% | top5 89.48% | 77.0 img/s | lr 3.15e-04\n[train step 300/704] loss 1.4814 | top1 70.39% | top3 85.40% | top5 89.87% | 77.0 img/s | lr 3.13e-04\n[train step 400/704] loss 1.4553 | top1 70.44% | top3 85.46% | top5 89.97% | 77.0 img/s | lr 3.11e-04\n[train step 500/704] loss 1.4552 | top1 70.65% | top3 85.68% | top5 90.17% | 77.1 img/s | lr 3.08e-04\n[train step 600/704] loss 1.4619 | top1 70.60% | top3 85.61% | top5 90.19% | 77.1 img/s | lr 3.06e-04\n[train step 700/704] loss 1.4535 | top1 70.44% | top3 85.50% | top5 90.13% | 77.1 img/s | lr 3.04e-04\n[Train] loss 1.4553 | top1 70.42% | top3 85.48% | top5 90.11% | lr 3.04e-04\n[Val]   loss 1.0040 | top1 71.94% | top3 88.44% | top5 93.02%\nBest saved to best_maxout_medium.pt (val top1 71.94%)\nEpoch time: 10.16 min\n\n=== Epoch 24/50 ===\n[train step 100/704] loss 1.4635 | top1 72.16% | top3 86.83% | top5 91.52% | 77.0 img/s | lr 3.01e-04\n[train step 200/704] loss 1.4872 | top1 70.91% | top3 86.36% | top5 90.66% | 76.9 img/s | lr 2.99e-04\n[train step 300/704] loss 1.4700 | top1 71.22% | top3 86.15% | top5 90.57% | 76.9 img/s | lr 2.97e-04\n[train step 400/704] loss 1.4192 | top1 72.12% | top3 86.84% | top5 91.06% | 76.9 img/s | lr 2.95e-04\n[train step 500/704] loss 1.3833 | top1 72.18% | top3 86.83% | top5 91.03% | 77.0 img/s | lr 2.92e-04\n[train step 600/704] loss 1.4064 | top1 71.62% | top3 86.52% | top5 90.80% | 77.0 img/s | lr 2.90e-04\n[train step 700/704] loss 1.3844 | top1 72.11% | top3 87.00% | top5 91.17% | 77.0 img/s | lr 2.88e-04\n[Train] loss 1.3872 | top1 72.10% | top3 86.99% | top5 91.17% | lr 2.87e-04\n[Val]   loss 0.9793 | top1 72.48% | top3 88.92% | top5 92.70%\nBest saved to best_maxout_medium.pt (val top1 72.48%)\nEpoch time: 10.17 min\n\n=== Epoch 25/50 ===\n[train step 100/704] loss 1.2344 | top1 73.66% | top3 87.62% | top5 91.97% | 77.0 img/s | lr 2.85e-04\n[train step 200/704] loss 1.2807 | top1 74.21% | top3 88.01% | top5 91.99% | 76.9 img/s | lr 2.83e-04\n[train step 300/704] loss 1.3188 | top1 73.60% | top3 87.63% | top5 91.59% | 77.0 img/s | lr 2.81e-04\n[train step 400/704] loss 1.3144 | top1 73.41% | top3 87.29% | top5 91.44% | 77.0 img/s | lr 2.78e-04\n[train step 500/704] loss 1.3113 | top1 73.42% | top3 87.36% | top5 91.53% | 77.0 img/s | lr 2.76e-04\n[train step 600/704] loss 1.3220 | top1 73.25% | top3 87.33% | top5 91.48% | 77.0 img/s | lr 2.74e-04\n[train step 700/704] loss 1.3141 | top1 73.37% | top3 87.46% | top5 91.51% | 77.0 img/s | lr 2.71e-04\n[Train] loss 1.3193 | top1 73.31% | top3 87.44% | top5 91.50% | lr 2.71e-04\n[Val]   loss 0.9490 | top1 73.74% | top3 89.54% | top5 93.44%\nBest saved to best_maxout_medium.pt (val top1 73.74%)\nEpoch time: 10.16 min\n\n=== Epoch 26/50 ===\n[train step 100/704] loss 1.2502 | top1 76.73% | top3 90.42% | top5 93.72% | 77.0 img/s | lr 2.69e-04\n[train step 200/704] loss 1.2842 | top1 75.80% | top3 89.37% | top5 92.97% | 77.1 img/s | lr 2.66e-04\n[train step 300/704] loss 1.2472 | top1 75.95% | top3 89.36% | top5 92.94% | 77.1 img/s | lr 2.64e-04\n[train step 400/704] loss 1.2282 | top1 76.05% | top3 89.39% | top5 92.90% | 77.0 img/s | lr 2.62e-04\n[train step 500/704] loss 1.2299 | top1 75.89% | top3 89.27% | top5 92.86% | 77.0 img/s | lr 2.59e-04\n[train step 600/704] loss 1.2503 | top1 75.47% | top3 88.94% | top5 92.61% | 77.0 img/s | lr 2.57e-04\n[train step 700/704] loss 1.2547 | top1 75.25% | top3 88.87% | top5 92.50% | 77.0 img/s | lr 2.55e-04\n[Train] loss 1.2539 | top1 75.27% | top3 88.85% | top5 92.50% | lr 2.55e-04\n[Val]   loss 0.9450 | top1 73.22% | top3 89.50% | top5 93.60%\nEpoch time: 10.16 min\n\n=== Epoch 27/50 ===\n[train step 100/704] loss 1.0612 | top1 79.91% | top3 92.14% | top5 94.88% | 77.0 img/s | lr 2.52e-04\n[train step 200/704] loss 1.1928 | top1 77.08% | top3 90.18% | top5 93.38% | 77.1 img/s | lr 2.50e-04\n[train step 300/704] loss 1.1911 | top1 77.02% | top3 89.99% | top5 93.24% | 77.1 img/s | lr 2.48e-04\n[train step 400/704] loss 1.1591 | top1 77.24% | top3 90.20% | top5 93.32% | 77.1 img/s | lr 2.45e-04\n[train step 500/704] loss 1.1616 | top1 77.35% | top3 90.29% | top5 93.38% | 77.1 img/s | lr 2.43e-04\n[train step 600/704] loss 1.1861 | top1 76.80% | top3 89.90% | top5 93.09% | 77.1 img/s | lr 2.41e-04\n[train step 700/704] loss 1.2201 | top1 76.25% | top3 89.52% | top5 92.81% | 77.0 img/s | lr 2.38e-04\n[Train] loss 1.2228 | top1 76.20% | top3 89.46% | top5 92.78% | lr 2.38e-04\n[Val]   loss 0.9546 | top1 74.10% | top3 89.54% | top5 93.32%\nBest saved to best_maxout_medium.pt (val top1 74.10%)\nEpoch time: 10.16 min\n\n=== Epoch 28/50 ===\n[train step 100/704] loss 1.2170 | top1 76.92% | top3 89.00% | top5 92.84% | 77.1 img/s | lr 2.36e-04\n[train step 200/704] loss 1.1407 | top1 78.79% | top3 90.49% | top5 93.80% | 77.0 img/s | lr 2.33e-04\n[train step 300/704] loss 1.1795 | top1 77.59% | top3 89.70% | top5 93.09% | 76.9 img/s | lr 2.31e-04\n[train step 400/704] loss 1.1948 | top1 77.67% | top3 89.79% | top5 93.22% | 77.0 img/s | lr 2.29e-04\n[train step 500/704] loss 1.1853 | top1 77.60% | top3 89.84% | top5 93.29% | 77.0 img/s | lr 2.26e-04\n[train step 600/704] loss 1.1725 | top1 77.76% | top3 90.09% | top5 93.42% | 77.0 img/s | lr 2.24e-04\n[train step 700/704] loss 1.1746 | top1 77.55% | top3 89.95% | top5 93.33% | 77.0 img/s | lr 2.22e-04\n[Train] loss 1.1769 | top1 77.52% | top3 89.91% | top5 93.30% | lr 2.22e-04\n[Val]   loss 0.8838 | top1 75.18% | top3 90.22% | top5 94.06%\nBest saved to best_maxout_medium.pt (val top1 75.18%)\nEpoch time: 10.17 min\n\n=== Epoch 29/50 ===\n[train step 100/704] loss 1.1408 | top1 78.73% | top3 90.50% | top5 93.92% | 77.0 img/s | lr 2.19e-04\n[train step 200/704] loss 1.1632 | top1 78.27% | top3 90.19% | top5 93.69% | 77.0 img/s | lr 2.17e-04\n[train step 300/704] loss 1.1775 | top1 78.14% | top3 90.30% | top5 93.81% | 77.0 img/s | lr 2.15e-04\n[train step 400/704] loss 1.2341 | top1 76.84% | top3 89.48% | top5 93.15% | 77.0 img/s | lr 2.12e-04\n[train step 500/704] loss 1.2388 | top1 77.03% | top3 89.56% | top5 93.17% | 77.0 img/s | lr 2.10e-04\n[train step 600/704] loss 1.2383 | top1 76.72% | top3 89.36% | top5 93.01% | 77.0 img/s | lr 2.08e-04\n[train step 700/704] loss 1.2214 | top1 76.87% | top3 89.43% | top5 93.07% | 77.0 img/s | lr 2.05e-04\n[Train] loss 1.2257 | top1 76.84% | top3 89.43% | top5 93.07% | lr 2.05e-04\n[Val]   loss 0.9181 | top1 74.84% | top3 89.84% | top5 93.84%\nEpoch time: 10.16 min\n\n=== Epoch 30/50 ===\n[train step 100/704] loss 1.0065 | top1 80.53% | top3 91.09% | top5 93.73% | 77.0 img/s | lr 2.03e-04\n[train step 200/704] loss 1.1307 | top1 78.60% | top3 89.96% | top5 92.98% | 77.0 img/s | lr 2.01e-04\n[train step 300/704] loss 1.1408 | top1 79.01% | top3 90.47% | top5 93.42% | 77.1 img/s | lr 1.98e-04\n[train step 400/704] loss 1.1204 | top1 79.29% | top3 90.63% | top5 93.56% | 77.0 img/s | lr 1.96e-04\n[train step 500/704] loss 1.1415 | top1 78.91% | top3 90.44% | top5 93.51% | 77.0 img/s | lr 1.94e-04\n[train step 600/704] loss 1.1308 | top1 79.19% | top3 90.64% | top5 93.67% | 77.0 img/s | lr 1.92e-04\n[train step 700/704] loss 1.1310 | top1 78.99% | top3 90.60% | top5 93.66% | 77.0 img/s | lr 1.89e-04\n[Train] loss 1.1325 | top1 78.99% | top3 90.60% | top5 93.67% | lr 1.89e-04\n[Val]   loss 0.8973 | top1 75.08% | top3 89.84% | top5 93.74%\nEpoch time: 10.16 min\n\n=== Epoch 31/50 ===\n[train step 100/704] loss 0.9659 | top1 82.17% | top3 92.47% | top5 94.95% | 77.0 img/s | lr 1.87e-04\n[train step 200/704] loss 1.0205 | top1 81.95% | top3 92.57% | top5 95.12% | 76.9 img/s | lr 1.85e-04\n[train step 300/704] loss 1.1238 | top1 79.84% | top3 91.01% | top5 94.07% | 76.9 img/s | lr 1.82e-04\n[train step 400/704] loss 1.1476 | top1 79.38% | top3 90.84% | top5 93.91% | 77.0 img/s | lr 1.80e-04\n[train step 500/704] loss 1.1561 | top1 79.47% | top3 91.00% | top5 93.97% | 77.0 img/s | lr 1.78e-04\n[train step 600/704] loss 1.1617 | top1 79.27% | top3 90.91% | top5 93.91% | 77.0 img/s | lr 1.76e-04\n[train step 700/704] loss 1.1611 | top1 79.27% | top3 90.90% | top5 93.91% | 77.0 img/s | lr 1.73e-04\n[Train] loss 1.1586 | top1 79.31% | top3 90.93% | top5 93.94% | lr 1.73e-04\n[Val]   loss 0.8683 | top1 76.04% | top3 90.52% | top5 94.38%\nBest saved to best_maxout_medium.pt (val top1 76.04%)\nEpoch time: 10.17 min\n\n=== Epoch 32/50 ===\n[train step 100/704] loss 1.0815 | top1 81.25% | top3 91.39% | top5 94.33% | 77.1 img/s | lr 1.71e-04\n[train step 200/704] loss 1.1281 | top1 80.32% | top3 90.90% | top5 93.88% | 77.1 img/s | lr 1.69e-04\n[train step 300/704] loss 1.1079 | top1 80.24% | top3 90.98% | top5 93.99% | 77.1 img/s | lr 1.67e-04\n[train step 400/704] loss 1.0863 | top1 80.78% | top3 91.42% | top5 94.21% | 77.0 img/s | lr 1.65e-04\n[train step 500/704] loss 1.1058 | top1 80.47% | top3 91.36% | top5 94.21% | 77.0 img/s | lr 1.62e-04\n[train step 600/704] loss 1.0815 | top1 80.92% | top3 91.62% | top5 94.37% | 77.0 img/s | lr 1.60e-04\n[train step 700/704] loss 1.0682 | top1 80.88% | top3 91.59% | top5 94.31% | 77.0 img/s | lr 1.58e-04\n[Train] loss 1.0704 | top1 80.84% | top3 91.56% | top5 94.28% | lr 1.58e-04\n[Val]   loss 0.8496 | top1 76.32% | top3 91.22% | top5 94.74%\nBest saved to best_maxout_medium.pt (val top1 76.32%)\nEpoch time: 10.16 min\n\n=== Epoch 33/50 ===\n[train step 100/704] loss 1.2375 | top1 77.16% | top3 88.98% | top5 92.33% | 76.7 img/s | lr 1.56e-04\n[train step 200/704] loss 1.3006 | top1 76.88% | top3 89.13% | top5 92.60% | 76.9 img/s | lr 1.54e-04\n[train step 300/704] loss 1.2181 | top1 78.42% | top3 90.02% | top5 93.28% | 77.0 img/s | lr 1.51e-04\n[train step 400/704] loss 1.1849 | top1 78.57% | top3 90.03% | top5 93.25% | 76.9 img/s | lr 1.49e-04\n[train step 500/704] loss 1.1478 | top1 79.35% | top3 90.45% | top5 93.55% | 76.9 img/s | lr 1.47e-04\n[train step 600/704] loss 1.1708 | top1 78.76% | top3 90.03% | top5 93.23% | 77.0 img/s | lr 1.45e-04\n[train step 700/704] loss 1.2033 | top1 78.12% | top3 89.71% | top5 92.96% | 77.0 img/s | lr 1.43e-04\n[Train] loss 1.2043 | top1 78.07% | top3 89.67% | top5 92.93% | lr 1.43e-04\n[Val]   loss 0.8625 | top1 76.58% | top3 90.56% | top5 94.42%\nBest saved to best_maxout_medium.pt (val top1 76.58%)\nEpoch time: 10.17 min\n\n=== Epoch 34/50 ===\n[train step 100/704] loss 0.8655 | top1 85.22% | top3 93.58% | top5 95.56% | 77.1 img/s | lr 1.41e-04\n[train step 200/704] loss 0.9731 | top1 82.83% | top3 92.54% | top5 95.00% | 77.0 img/s | lr 1.39e-04\n[train step 300/704] loss 1.0339 | top1 81.80% | top3 91.98% | top5 94.55% | 77.0 img/s | lr 1.36e-04\n[train step 400/704] loss 1.0663 | top1 80.91% | top3 91.29% | top5 94.09% | 77.0 img/s | lr 1.34e-04\n[train step 500/704] loss 1.0676 | top1 80.70% | top3 91.28% | top5 94.09% | 77.0 img/s | lr 1.32e-04\n[train step 600/704] loss 1.0913 | top1 80.02% | top3 90.91% | top5 93.86% | 77.0 img/s | lr 1.30e-04\n[train step 700/704] loss 1.0949 | top1 80.04% | top3 90.90% | top5 93.83% | 77.0 img/s | lr 1.28e-04\n[Train] loss 1.1011 | top1 79.83% | top3 90.76% | top5 93.74% | lr 1.28e-04\n[Val]   loss 0.8458 | top1 76.70% | top3 91.00% | top5 94.24%\nBest saved to best_maxout_medium.pt (val top1 76.70%)\nEpoch time: 10.17 min\n\n=== Epoch 35/50 ===\n[train step 100/704] loss 1.1157 | top1 81.06% | top3 91.19% | top5 93.95% | 76.7 img/s | lr 1.26e-04\n[train step 200/704] loss 1.1717 | top1 79.93% | top3 90.69% | top5 93.57% | 76.9 img/s | lr 1.24e-04\n[train step 300/704] loss 1.1029 | top1 80.97% | top3 91.39% | top5 94.15% | 76.9 img/s | lr 1.22e-04\n[train step 400/704] loss 1.1154 | top1 81.03% | top3 91.48% | top5 94.22% | 77.0 img/s | lr 1.20e-04\n[train step 500/704] loss 1.0906 | top1 81.41% | top3 91.64% | top5 94.35% | 77.0 img/s | lr 1.18e-04\n[train step 600/704] loss 1.0560 | top1 81.81% | top3 91.85% | top5 94.50% | 77.0 img/s | lr 1.16e-04\n[train step 700/704] loss 1.0437 | top1 81.92% | top3 91.91% | top5 94.53% | 76.9 img/s | lr 1.14e-04\n[Train] loss 1.0397 | top1 81.98% | top3 91.95% | top5 94.56% | lr 1.14e-04\n[Val]   loss 0.8222 | top1 77.06% | top3 91.76% | top5 95.00%\nBest saved to best_maxout_medium.pt (val top1 77.06%)\nEpoch time: 10.17 min\n\n=== Epoch 36/50 ===\n[train step 100/704] loss 1.1084 | top1 80.19% | top3 90.78% | top5 93.62% | 77.0 img/s | lr 1.12e-04\n[train step 200/704] loss 1.0701 | top1 81.66% | top3 91.84% | top5 94.46% | 76.9 img/s | lr 1.10e-04\n[train step 300/704] loss 1.1016 | top1 80.73% | top3 91.36% | top5 94.09% | 76.9 img/s | lr 1.08e-04\n[train step 400/704] loss 1.0724 | top1 81.35% | top3 91.76% | top5 94.39% | 77.0 img/s | lr 1.06e-04\n[train step 500/704] loss 1.0839 | top1 81.45% | top3 91.89% | top5 94.52% | 76.9 img/s | lr 1.04e-04\n[train step 600/704] loss 1.1040 | top1 81.10% | top3 91.64% | top5 94.35% | 76.9 img/s | lr 1.02e-04\n[train step 700/704] loss 1.0983 | top1 81.22% | top3 91.67% | top5 94.38% | 76.9 img/s | lr 1.01e-04\n[Train] loss 1.0993 | top1 81.24% | top3 91.69% | top5 94.40% | lr 1.01e-04\n[Val]   loss 0.8373 | top1 77.14% | top3 91.36% | top5 94.80%\nBest saved to best_maxout_medium.pt (val top1 77.14%)\nEpoch time: 10.18 min\n\n=== Epoch 37/50 ===\n[train step 100/704] loss 1.0280 | top1 82.59% | top3 92.67% | top5 95.42% | 77.0 img/s | lr 9.87e-05\n[train step 200/704] loss 1.0904 | top1 81.30% | top3 91.73% | top5 94.52% | 76.9 img/s | lr 9.68e-05\n[train step 300/704] loss 1.0441 | top1 82.08% | top3 91.89% | top5 94.60% | 77.0 img/s | lr 9.50e-05\n[train step 400/704] loss 1.0493 | top1 81.95% | top3 91.91% | top5 94.62% | 77.0 img/s | lr 9.31e-05\n[train step 500/704] loss 1.0476 | top1 82.10% | top3 92.09% | top5 94.74% | 77.0 img/s | lr 9.13e-05\n[train step 600/704] loss 1.0410 | top1 82.51% | top3 92.33% | top5 94.90% | 77.0 img/s | lr 8.95e-05\n[train step 700/704] loss 1.0486 | top1 82.23% | top3 92.19% | top5 94.81% | 77.0 img/s | lr 8.78e-05\n[Train] loss 1.0503 | top1 82.20% | top3 92.16% | top5 94.79% | lr 8.77e-05\n[Val]   loss 0.8235 | top1 77.70% | top3 91.32% | top5 94.76%\nBest saved to best_maxout_medium.pt (val top1 77.70%)\nEpoch time: 10.17 min\n\n=== Epoch 38/50 ===\n[train step 100/704] loss 0.9251 | top1 84.20% | top3 93.47% | top5 95.64% | 76.8 img/s | lr 8.59e-05\n[train step 200/704] loss 1.0304 | top1 81.77% | top3 92.13% | top5 94.60% | 76.8 img/s | lr 8.42e-05\n[train step 300/704] loss 1.0143 | top1 82.15% | top3 92.17% | top5 94.66% | 76.9 img/s | lr 8.24e-05\n[train step 400/704] loss 0.9983 | top1 82.61% | top3 92.29% | top5 94.78% | 76.9 img/s | lr 8.07e-05\n[train step 500/704] loss 0.9873 | top1 82.63% | top3 92.33% | top5 94.84% | 76.9 img/s | lr 7.90e-05\n[train step 600/704] loss 0.9843 | top1 82.92% | top3 92.58% | top5 95.02% | 76.9 img/s | lr 7.73e-05\n[train step 700/704] loss 0.9687 | top1 83.15% | top3 92.64% | top5 95.04% | 76.9 img/s | lr 7.56e-05\n[Train] loss 0.9679 | top1 83.16% | top3 92.64% | top5 95.05% | lr 7.55e-05\n[Val]   loss 0.7808 | top1 77.76% | top3 91.86% | top5 95.04%\nBest saved to best_maxout_medium.pt (val top1 77.76%)\nEpoch time: 10.17 min\n\n=== Epoch 39/50 ===\n[train step 100/704] loss 0.9233 | top1 85.38% | top3 93.73% | top5 95.72% | 76.9 img/s | lr 7.39e-05\n[train step 200/704] loss 0.9867 | top1 83.38% | top3 92.47% | top5 94.76% | 77.0 img/s | lr 7.22e-05\n[train step 300/704] loss 1.0004 | top1 83.17% | top3 92.40% | top5 94.84% | 77.0 img/s | lr 7.06e-05\n[train step 400/704] loss 1.0395 | top1 82.55% | top3 92.13% | top5 94.77% | 77.0 img/s | lr 6.90e-05\n[train step 500/704] loss 1.0323 | top1 82.53% | top3 92.11% | top5 94.73% | 77.0 img/s | lr 6.74e-05\n[train step 600/704] loss 1.0335 | top1 82.65% | top3 92.20% | top5 94.79% | 77.0 img/s | lr 6.58e-05\n[train step 700/704] loss 1.0159 | top1 83.22% | top3 92.49% | top5 94.96% | 77.0 img/s | lr 6.42e-05\n[Train] loss 1.0138 | top1 83.27% | top3 92.52% | top5 94.98% | lr 6.42e-05\n[Val]   loss 0.7748 | top1 78.06% | top3 92.10% | top5 95.26%\nBest saved to best_maxout_medium.pt (val top1 78.06%)\nEpoch time: 10.17 min\n\n=== Epoch 40/50 ===\n[train step 100/704] loss 1.0749 | top1 81.98% | top3 91.95% | top5 94.83% | 77.0 img/s | lr 6.26e-05\n[train step 200/704] loss 1.0111 | top1 83.16% | top3 92.56% | top5 95.20% | 77.0 img/s | lr 6.11e-05\n[train step 300/704] loss 0.9585 | top1 83.82% | top3 92.76% | top5 95.34% | 77.1 img/s | lr 5.96e-05\n[train step 400/704] loss 0.9935 | top1 83.29% | top3 92.50% | top5 95.13% | 77.1 img/s | lr 5.81e-05\n[train step 500/704] loss 0.9953 | top1 83.44% | top3 92.62% | top5 95.18% | 77.0 img/s | lr 5.66e-05\n[train step 600/704] loss 0.9980 | top1 83.48% | top3 92.60% | top5 95.16% | 77.0 img/s | lr 5.51e-05\n[train step 700/704] loss 0.9840 | top1 83.65% | top3 92.62% | top5 95.15% | 77.0 img/s | lr 5.37e-05\n[Train] loss 0.9845 | top1 83.65% | top3 92.63% | top5 95.16% | lr 5.36e-05\n[Val]   loss 0.7734 | top1 78.82% | top3 92.06% | top5 95.12%\nBest saved to best_maxout_medium.pt (val top1 78.82%)\nEpoch time: 10.17 min\n\n=== Epoch 41/50 ===\n[train step 100/704] loss 0.9385 | top1 83.88% | top3 93.03% | top5 95.47% | 77.0 img/s | lr 5.22e-05\n[train step 200/704] loss 1.0099 | top1 83.48% | top3 92.82% | top5 95.33% | 76.8 img/s | lr 5.08e-05\n[train step 300/704] loss 0.9446 | top1 83.97% | top3 93.10% | top5 95.49% | 76.9 img/s | lr 4.94e-05\n[train step 400/704] loss 0.9524 | top1 83.98% | top3 93.25% | top5 95.56% | 76.9 img/s | lr 4.80e-05\n[train step 500/704] loss 0.9694 | top1 84.03% | top3 93.19% | top5 95.57% | 76.9 img/s | lr 4.66e-05\n[train step 600/704] loss 0.9745 | top1 84.15% | top3 93.22% | top5 95.59% | 76.9 img/s | lr 4.53e-05\n[train step 700/704] loss 0.9727 | top1 84.31% | top3 93.33% | top5 95.70% | 76.9 img/s | lr 4.40e-05\n[Train] loss 0.9722 | top1 84.28% | top3 93.30% | top5 95.68% | lr 4.39e-05\n[Val]   loss 0.7637 | top1 79.14% | top3 92.60% | top5 95.34%\nBest saved to best_maxout_medium.pt (val top1 79.14%)\nEpoch time: 10.18 min\n\n=== Epoch 42/50 ===\n[train step 100/704] loss 0.8424 | top1 85.81% | top3 93.56% | top5 95.55% | 76.9 img/s | lr 4.26e-05\n[train step 200/704] loss 0.7990 | top1 86.73% | top3 94.18% | top5 96.07% | 76.9 img/s | lr 4.13e-05\n[train step 300/704] loss 0.8328 | top1 86.03% | top3 93.92% | top5 95.92% | 77.0 img/s | lr 4.01e-05\n[train step 400/704] loss 0.8346 | top1 86.06% | top3 93.83% | top5 95.84% | 77.0 img/s | lr 3.88e-05\n[train step 500/704] loss 0.8709 | top1 85.51% | top3 93.50% | top5 95.64% | 77.0 img/s | lr 3.76e-05\n[train step 600/704] loss 0.8987 | top1 84.76% | top3 93.16% | top5 95.36% | 77.0 img/s | lr 3.64e-05\n[train step 700/704] loss 0.9109 | top1 84.83% | top3 93.19% | top5 95.37% | 77.0 img/s | lr 3.52e-05\n[Train] loss 0.9076 | top1 84.88% | top3 93.22% | top5 95.39% | lr 3.51e-05\n[Val]   loss 0.7924 | top1 78.08% | top3 91.78% | top5 94.84%\nEpoch time: 10.17 min\n\n=== Epoch 43/50 ===\n[train step 100/704] loss 0.9785 | top1 82.11% | top3 92.12% | top5 94.45% | 77.0 img/s | lr 3.39e-05\n[train step 200/704] loss 0.9248 | top1 83.15% | top3 92.27% | top5 94.59% | 77.0 img/s | lr 3.28e-05\n[train step 300/704] loss 0.9586 | top1 83.59% | top3 92.47% | top5 94.79% | 76.9 img/s | lr 3.17e-05\n[train step 400/704] loss 0.9526 | top1 83.95% | top3 92.79% | top5 95.05% | 77.0 img/s | lr 3.05e-05\n[train step 500/704] loss 0.9804 | top1 83.35% | top3 92.57% | top5 94.94% | 77.0 img/s | lr 2.94e-05\n[train step 600/704] loss 0.9924 | top1 83.46% | top3 92.69% | top5 95.09% | 77.0 img/s | lr 2.84e-05\n[train step 700/704] loss 0.9847 | top1 83.57% | top3 92.75% | top5 95.13% | 77.0 img/s | lr 2.73e-05\n[Train] loss 0.9877 | top1 83.49% | top3 92.69% | top5 95.09% | lr 2.73e-05\n[Val]   loss 0.7887 | top1 78.82% | top3 91.86% | top5 94.82%\nEpoch time: 10.16 min\n\n=== Epoch 44/50 ===\n[train step 100/704] loss 1.0213 | top1 83.58% | top3 92.64% | top5 95.19% | 77.0 img/s | lr 2.62e-05\n[train step 200/704] loss 0.9649 | top1 84.21% | top3 93.12% | top5 95.45% | 77.0 img/s | lr 2.52e-05\n[train step 300/704] loss 0.9289 | top1 84.43% | top3 93.18% | top5 95.46% | 76.9 img/s | lr 2.42e-05\n[train step 400/704] loss 0.9335 | top1 84.05% | top3 92.95% | top5 95.27% | 76.9 img/s | lr 2.32e-05\n[train step 500/704] loss 0.9257 | top1 84.00% | top3 92.85% | top5 95.18% | 77.0 img/s | lr 2.23e-05\n[train step 600/704] loss 0.9708 | top1 83.38% | top3 92.54% | top5 95.04% | 77.0 img/s | lr 2.13e-05\n[train step 700/704] loss 0.9902 | top1 83.34% | top3 92.63% | top5 95.12% | 77.0 img/s | lr 2.04e-05\n[Train] loss 0.9898 | top1 83.34% | top3 92.64% | top5 95.12% | lr 2.04e-05\n[Val]   loss 0.7878 | top1 78.88% | top3 91.72% | top5 94.66%\nEpoch time: 10.16 min\n\n=== Epoch 45/50 ===\n[train step 100/704] loss 0.8558 | top1 87.83% | top3 95.16% | top5 96.81% | 76.9 img/s | lr 1.95e-05\n[train step 200/704] loss 0.8989 | top1 86.33% | top3 94.23% | top5 96.35% | 77.0 img/s | lr 1.86e-05\n[train step 300/704] loss 0.9048 | top1 86.17% | top3 94.22% | top5 96.29% | 77.0 img/s | lr 1.78e-05\n[train step 400/704] loss 0.8935 | top1 86.10% | top3 94.29% | top5 96.30% | 77.0 img/s | lr 1.69e-05\n[train step 500/704] loss 0.8930 | top1 86.13% | top3 94.35% | top5 96.37% | 77.0 img/s | lr 1.61e-05\n[train step 600/704] loss 0.9193 | top1 85.70% | top3 94.05% | top5 96.12% | 77.0 img/s | lr 1.53e-05\n[train step 700/704] loss 0.9123 | top1 85.89% | top3 94.10% | top5 96.17% | 77.0 img/s | lr 1.45e-05\n[Train] loss 0.9123 | top1 85.83% | top3 94.04% | top5 96.12% | lr 1.45e-05\n[Val]   loss 0.7553 | top1 79.02% | top3 92.38% | top5 95.38%\nEpoch time: 10.16 min\n\n=== Epoch 46/50 ===\n[train step 100/704] loss 0.8388 | top1 85.22% | top3 93.69% | top5 96.05% | 77.0 img/s | lr 1.38e-05\n[train step 200/704] loss 0.8762 | top1 85.69% | top3 93.88% | top5 96.27% | 77.0 img/s | lr 1.30e-05\n[train step 300/704] loss 0.8477 | top1 86.39% | top3 94.12% | top5 96.29% | 76.9 img/s | lr 1.23e-05\n[train step 400/704] loss 0.8632 | top1 86.18% | top3 94.00% | top5 96.19% | 76.9 img/s | lr 1.16e-05\n[train step 500/704] loss 0.8728 | top1 85.92% | top3 93.86% | top5 96.15% | 76.9 img/s | lr 1.10e-05\n[train step 600/704] loss 0.8770 | top1 85.94% | top3 93.97% | top5 96.21% | 76.9 img/s | lr 1.03e-05\n[train step 700/704] loss 0.8858 | top1 85.93% | top3 93.98% | top5 96.20% | 76.9 img/s | lr 9.70e-06\n[Train] loss 0.8908 | top1 85.88% | top3 93.95% | top5 96.18% | lr 9.68e-06\n[Val]   loss 0.7772 | top1 78.78% | top3 92.18% | top5 95.02%\nEpoch time: 10.17 min\n\n=== Epoch 47/50 ===\n[train step 100/704] loss 0.9462 | top1 85.16% | top3 93.16% | top5 95.19% | 77.0 img/s | lr 9.08e-06\n[train step 200/704] loss 1.0261 | top1 83.14% | top3 92.67% | top5 95.25% | 77.0 img/s | lr 8.50e-06\n[train step 300/704] loss 1.0220 | top1 83.61% | top3 92.87% | top5 95.35% | 77.0 img/s | lr 7.94e-06\n[train step 400/704] loss 0.9682 | top1 84.62% | top3 93.42% | top5 95.65% | 77.0 img/s | lr 7.40e-06\n[train step 500/704] loss 0.9545 | top1 84.72% | top3 93.45% | top5 95.66% | 77.0 img/s | lr 6.88e-06\n[train step 600/704] loss 0.9283 | top1 85.20% | top3 93.64% | top5 95.79% | 77.0 img/s | lr 6.39e-06\n[train step 700/704] loss 0.9418 | top1 84.68% | top3 93.26% | top5 95.53% | 77.0 img/s | lr 5.91e-06\n[Train] loss 0.9439 | top1 84.68% | top3 93.26% | top5 95.54% | lr 5.90e-06\n[Val]   loss 0.7613 | top1 79.50% | top3 92.10% | top5 95.30%\nBest saved to best_maxout_medium.pt (val top1 79.50%)\nEpoch time: 10.16 min\n\n=== Epoch 48/50 ===\n[train step 100/704] loss 0.9322 | top1 83.41% | top3 92.41% | top5 94.59% | 76.9 img/s | lr 5.44e-06\n[train step 200/704] loss 0.8863 | top1 84.81% | top3 92.95% | top5 95.12% | 76.9 img/s | lr 5.01e-06\n[train step 300/704] loss 0.8676 | top1 85.33% | top3 93.22% | top5 95.29% | 76.9 img/s | lr 4.61e-06\n[train step 400/704] loss 0.9004 | top1 85.16% | top3 93.19% | top5 95.35% | 76.9 img/s | lr 4.22e-06\n[train step 500/704] loss 0.8791 | top1 85.90% | top3 93.64% | top5 95.72% | 77.0 img/s | lr 3.86e-06\n[train step 600/704] loss 0.8725 | top1 85.86% | top3 93.60% | top5 95.69% | 76.9 img/s | lr 3.51e-06\n[train step 700/704] loss 0.8689 | top1 85.94% | top3 93.73% | top5 95.82% | 77.0 img/s | lr 3.19e-06\n[Train] loss 0.8687 | top1 85.92% | top3 93.73% | top5 95.82% | lr 3.18e-06\n[Val]   loss 0.7661 | top1 78.68% | top3 92.34% | top5 95.06%\nEpoch time: 10.16 min\n\n=== Epoch 49/50 ===\n[train step 100/704] loss 1.0532 | top1 82.02% | top3 91.62% | top5 94.48% | 77.0 img/s | lr 2.88e-06\n[train step 200/704] loss 0.9882 | top1 83.11% | top3 92.35% | top5 95.01% | 77.0 img/s | lr 2.61e-06\n[train step 300/704] loss 0.9575 | top1 83.70% | top3 92.72% | top5 95.25% | 77.0 img/s | lr 2.35e-06\n[train step 400/704] loss 0.9481 | top1 84.47% | top3 93.27% | top5 95.59% | 77.0 img/s | lr 2.12e-06\n[train step 500/704] loss 0.9527 | top1 84.28% | top3 93.11% | top5 95.55% | 77.0 img/s | lr 1.91e-06\n[train step 600/704] loss 0.9464 | top1 84.72% | top3 93.39% | top5 95.72% | 77.0 img/s | lr 1.72e-06\n[train step 700/704] loss 0.9437 | top1 84.91% | top3 93.43% | top5 95.74% | 77.0 img/s | lr 1.55e-06\n[Train] loss 0.9402 | top1 84.96% | top3 93.46% | top5 95.76% | lr 1.55e-06\n[Val]   loss 0.7660 | top1 78.70% | top3 92.26% | top5 95.06%\nEpoch time: 10.16 min\n\n=== Epoch 50/50 ===\n[train step 100/704] loss 1.0846 | top1 83.00% | top3 92.70% | top5 95.44% | 77.0 img/s | lr 1.40e-06\n[train step 200/704] loss 0.9776 | top1 84.20% | top3 92.96% | top5 95.40% | 77.0 img/s | lr 1.28e-06\n[train step 300/704] loss 0.9793 | top1 83.84% | top3 92.67% | top5 95.21% | 76.9 img/s | lr 1.18e-06\n[train step 400/704] loss 0.9584 | top1 84.34% | top3 93.02% | top5 95.38% | 77.0 img/s | lr 1.10e-06\n[train step 500/704] loss 0.9608 | top1 84.49% | top3 93.28% | top5 95.59% | 77.0 img/s | lr 1.05e-06\n[train step 600/704] loss 0.9567 | top1 84.69% | top3 93.38% | top5 95.64% | 77.0 img/s | lr 1.01e-06\n[train step 700/704] loss 0.9624 | top1 84.50% | top3 93.29% | top5 95.57% | 76.9 img/s | lr 1.00e-06\n[Train] loss 0.9642 | top1 84.47% | top3 93.28% | top5 95.57% | lr 1.00e-06\n[Val]   loss 0.7696 | top1 78.26% | top3 92.10% | top5 95.34%\nEpoch time: 10.17 min\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"def count_trainable_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nn_params = count_trainable_parameters(model)\nprint(f\"Trainable parameters: {n_params:,}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T07:32:56.966314Z","iopub.execute_input":"2026-01-07T07:32:56.967020Z","iopub.status.idle":"2026-01-07T07:32:56.973186Z","shell.execute_reply.started":"2026-01-07T07:32:56.966980Z","shell.execute_reply":"2026-01-07T07:32:56.972406Z"}},"outputs":[{"name":"stdout","text":"Trainable parameters: 14,599,198\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"def count_trainable_parameters_by_module(model):\n    total = 0\n    for name, p in model.named_parameters():\n        if p.requires_grad:\n            n = p.numel()\n            total += n\n            print(f\"{name:40s} | {n:10,d}\")\n    print(\"-\" * 60)\n    print(f\"{'TOTAL':40s} | {total:10,d}\")\n    return total\n\ncount_trainable_parameters_by_module(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T07:33:00.942383Z","iopub.execute_input":"2026-01-07T07:33:00.942967Z","iopub.status.idle":"2026-01-07T07:33:00.953046Z","shell.execute_reply.started":"2026-01-07T07:33:00.942939Z","shell.execute_reply":"2026-01-07T07:33:00.952489Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"stem.stem.0.weight                       |      1,728\nstem.stem.1.weight                       |         64\nstem.stem.1.bias                         |         64\nstages.0.0.outlook.norm1.ln.weight       |         64\nstages.0.0.outlook.norm1.ln.bias         |         64\nstages.0.0.outlook.attn.attn.weight      |      1,152\nstages.0.0.outlook.attn.attn.bias        |         18\nstages.0.0.outlook.attn.v.weight         |      4,096\nstages.0.0.outlook.attn.v.bias           |         64\nstages.0.0.outlook.attn.proj.weight      |      4,096\nstages.0.0.outlook.attn.proj.bias        |         64\nstages.0.0.outlook.norm2.ln.weight       |         64\nstages.0.0.outlook.norm2.ln.bias         |         64\nstages.0.0.outlook.mlp.fc1.weight        |      8,192\nstages.0.0.outlook.mlp.fc1.bias          |        128\nstages.0.0.outlook.mlp.fc2.weight        |      8,192\nstages.0.0.outlook.mlp.fc2.bias          |         64\nstages.0.0.mbconv.expand.0.weight        |     16,384\nstages.0.0.mbconv.expand.1.weight        |        256\nstages.0.0.mbconv.expand.1.bias          |        256\nstages.0.0.mbconv.depthwise.0.weight     |      2,304\nstages.0.0.mbconv.depthwise.1.weight     |        256\nstages.0.0.mbconv.depthwise.1.bias       |        256\nstages.0.0.mbconv.se.fc1.weight          |     16,384\nstages.0.0.mbconv.se.fc1.bias            |         64\nstages.0.0.mbconv.se.fc2.weight          |     16,384\nstages.0.0.mbconv.se.fc2.bias            |        256\nstages.0.0.mbconv.project.0.weight       |     16,384\nstages.0.0.mbconv.project.1.weight       |         64\nstages.0.0.mbconv.project.1.bias         |         64\nstages.0.0.norm2.weight                  |         64\nstages.0.0.norm2.bias                    |         64\nstages.0.0.grid_attn.mhsa.qkv.weight     |     12,288\nstages.0.0.grid_attn.mhsa.qkv.bias       |        192\nstages.0.0.grid_attn.mhsa.proj.weight    |      4,096\nstages.0.0.grid_attn.mhsa.proj.bias      |         64\nstages.0.0.norm3.weight                  |         64\nstages.0.0.norm3.bias                    |         64\nstages.0.0.mlp.fc1.weight                |     16,384\nstages.0.0.mlp.fc1.bias                  |        256\nstages.0.0.mlp.fc2.weight                |     16,384\nstages.0.0.mlp.fc2.bias                  |         64\nstages.0.1.outlook.norm1.ln.weight       |         64\nstages.0.1.outlook.norm1.ln.bias         |         64\nstages.0.1.outlook.attn.attn.weight      |      1,152\nstages.0.1.outlook.attn.attn.bias        |         18\nstages.0.1.outlook.attn.v.weight         |      4,096\nstages.0.1.outlook.attn.v.bias           |         64\nstages.0.1.outlook.attn.proj.weight      |      4,096\nstages.0.1.outlook.attn.proj.bias        |         64\nstages.0.1.outlook.norm2.ln.weight       |         64\nstages.0.1.outlook.norm2.ln.bias         |         64\nstages.0.1.outlook.mlp.fc1.weight        |      8,192\nstages.0.1.outlook.mlp.fc1.bias          |        128\nstages.0.1.outlook.mlp.fc2.weight        |      8,192\nstages.0.1.outlook.mlp.fc2.bias          |         64\nstages.0.1.mbconv.expand.0.weight        |     16,384\nstages.0.1.mbconv.expand.1.weight        |        256\nstages.0.1.mbconv.expand.1.bias          |        256\nstages.0.1.mbconv.depthwise.0.weight     |      2,304\nstages.0.1.mbconv.depthwise.1.weight     |        256\nstages.0.1.mbconv.depthwise.1.bias       |        256\nstages.0.1.mbconv.se.fc1.weight          |     16,384\nstages.0.1.mbconv.se.fc1.bias            |         64\nstages.0.1.mbconv.se.fc2.weight          |     16,384\nstages.0.1.mbconv.se.fc2.bias            |        256\nstages.0.1.mbconv.project.0.weight       |     16,384\nstages.0.1.mbconv.project.1.weight       |         64\nstages.0.1.mbconv.project.1.bias         |         64\nstages.0.1.norm2.weight                  |         64\nstages.0.1.norm2.bias                    |         64\nstages.0.1.grid_attn.mhsa.qkv.weight     |     12,288\nstages.0.1.grid_attn.mhsa.qkv.bias       |        192\nstages.0.1.grid_attn.mhsa.proj.weight    |      4,096\nstages.0.1.grid_attn.mhsa.proj.bias      |         64\nstages.0.1.norm3.weight                  |         64\nstages.0.1.norm3.bias                    |         64\nstages.0.1.mlp.fc1.weight                |     16,384\nstages.0.1.mlp.fc1.bias                  |        256\nstages.0.1.mlp.fc2.weight                |     16,384\nstages.0.1.mlp.fc2.bias                  |         64\nstages.1.0.outlook.norm1.ln.weight       |        128\nstages.1.0.outlook.norm1.ln.bias         |        128\nstages.1.0.outlook.attn.attn.weight      |      4,608\nstages.1.0.outlook.attn.attn.bias        |         36\nstages.1.0.outlook.attn.v.weight         |     16,384\nstages.1.0.outlook.attn.v.bias           |        128\nstages.1.0.outlook.attn.proj.weight      |     16,384\nstages.1.0.outlook.attn.proj.bias        |        128\nstages.1.0.outlook.norm2.ln.weight       |        128\nstages.1.0.outlook.norm2.ln.bias         |        128\nstages.1.0.outlook.mlp.fc1.weight        |     32,768\nstages.1.0.outlook.mlp.fc1.bias          |        256\nstages.1.0.outlook.mlp.fc2.weight        |     32,768\nstages.1.0.outlook.mlp.fc2.bias          |        128\nstages.1.0.mbconv.expand.0.weight        |     65,536\nstages.1.0.mbconv.expand.1.weight        |        512\nstages.1.0.mbconv.expand.1.bias          |        512\nstages.1.0.mbconv.depthwise.0.weight     |      4,608\nstages.1.0.mbconv.depthwise.1.weight     |        512\nstages.1.0.mbconv.depthwise.1.bias       |        512\nstages.1.0.mbconv.se.fc1.weight          |     65,536\nstages.1.0.mbconv.se.fc1.bias            |        128\nstages.1.0.mbconv.se.fc2.weight          |     65,536\nstages.1.0.mbconv.se.fc2.bias            |        512\nstages.1.0.mbconv.project.0.weight       |     65,536\nstages.1.0.mbconv.project.1.weight       |        128\nstages.1.0.mbconv.project.1.bias         |        128\nstages.1.0.norm2.weight                  |        128\nstages.1.0.norm2.bias                    |        128\nstages.1.0.grid_attn.mhsa.qkv.weight     |     49,152\nstages.1.0.grid_attn.mhsa.qkv.bias       |        384\nstages.1.0.grid_attn.mhsa.proj.weight    |     16,384\nstages.1.0.grid_attn.mhsa.proj.bias      |        128\nstages.1.0.norm3.weight                  |        128\nstages.1.0.norm3.bias                    |        128\nstages.1.0.mlp.fc1.weight                |     65,536\nstages.1.0.mlp.fc1.bias                  |        512\nstages.1.0.mlp.fc2.weight                |     65,536\nstages.1.0.mlp.fc2.bias                  |        128\nstages.1.1.outlook.norm1.ln.weight       |        128\nstages.1.1.outlook.norm1.ln.bias         |        128\nstages.1.1.outlook.attn.attn.weight      |      4,608\nstages.1.1.outlook.attn.attn.bias        |         36\nstages.1.1.outlook.attn.v.weight         |     16,384\nstages.1.1.outlook.attn.v.bias           |        128\nstages.1.1.outlook.attn.proj.weight      |     16,384\nstages.1.1.outlook.attn.proj.bias        |        128\nstages.1.1.outlook.norm2.ln.weight       |        128\nstages.1.1.outlook.norm2.ln.bias         |        128\nstages.1.1.outlook.mlp.fc1.weight        |     32,768\nstages.1.1.outlook.mlp.fc1.bias          |        256\nstages.1.1.outlook.mlp.fc2.weight        |     32,768\nstages.1.1.outlook.mlp.fc2.bias          |        128\nstages.1.1.mbconv.expand.0.weight        |     65,536\nstages.1.1.mbconv.expand.1.weight        |        512\nstages.1.1.mbconv.expand.1.bias          |        512\nstages.1.1.mbconv.depthwise.0.weight     |      4,608\nstages.1.1.mbconv.depthwise.1.weight     |        512\nstages.1.1.mbconv.depthwise.1.bias       |        512\nstages.1.1.mbconv.se.fc1.weight          |     65,536\nstages.1.1.mbconv.se.fc1.bias            |        128\nstages.1.1.mbconv.se.fc2.weight          |     65,536\nstages.1.1.mbconv.se.fc2.bias            |        512\nstages.1.1.mbconv.project.0.weight       |     65,536\nstages.1.1.mbconv.project.1.weight       |        128\nstages.1.1.mbconv.project.1.bias         |        128\nstages.1.1.norm2.weight                  |        128\nstages.1.1.norm2.bias                    |        128\nstages.1.1.grid_attn.mhsa.qkv.weight     |     49,152\nstages.1.1.grid_attn.mhsa.qkv.bias       |        384\nstages.1.1.grid_attn.mhsa.proj.weight    |     16,384\nstages.1.1.grid_attn.mhsa.proj.bias      |        128\nstages.1.1.norm3.weight                  |        128\nstages.1.1.norm3.bias                    |        128\nstages.1.1.mlp.fc1.weight                |     65,536\nstages.1.1.mlp.fc1.bias                  |        512\nstages.1.1.mlp.fc2.weight                |     65,536\nstages.1.1.mlp.fc2.bias                  |        128\nstages.2.0.outlook.norm1.ln.weight       |        256\nstages.2.0.outlook.norm1.ln.bias         |        256\nstages.2.0.outlook.attn.attn.weight      |     18,432\nstages.2.0.outlook.attn.attn.bias        |         72\nstages.2.0.outlook.attn.v.weight         |     65,536\nstages.2.0.outlook.attn.v.bias           |        256\nstages.2.0.outlook.attn.proj.weight      |     65,536\nstages.2.0.outlook.attn.proj.bias        |        256\nstages.2.0.outlook.norm2.ln.weight       |        256\nstages.2.0.outlook.norm2.ln.bias         |        256\nstages.2.0.outlook.mlp.fc1.weight        |    131,072\nstages.2.0.outlook.mlp.fc1.bias          |        512\nstages.2.0.outlook.mlp.fc2.weight        |    131,072\nstages.2.0.outlook.mlp.fc2.bias          |        256\nstages.2.0.mbconv.expand.0.weight        |    262,144\nstages.2.0.mbconv.expand.1.weight        |      1,024\nstages.2.0.mbconv.expand.1.bias          |      1,024\nstages.2.0.mbconv.depthwise.0.weight     |      9,216\nstages.2.0.mbconv.depthwise.1.weight     |      1,024\nstages.2.0.mbconv.depthwise.1.bias       |      1,024\nstages.2.0.mbconv.se.fc1.weight          |    262,144\nstages.2.0.mbconv.se.fc1.bias            |        256\nstages.2.0.mbconv.se.fc2.weight          |    262,144\nstages.2.0.mbconv.se.fc2.bias            |      1,024\nstages.2.0.mbconv.project.0.weight       |    262,144\nstages.2.0.mbconv.project.1.weight       |        256\nstages.2.0.mbconv.project.1.bias         |        256\nstages.2.0.norm2.weight                  |        256\nstages.2.0.norm2.bias                    |        256\nstages.2.0.grid_attn.mhsa.qkv.weight     |    196,608\nstages.2.0.grid_attn.mhsa.qkv.bias       |        768\nstages.2.0.grid_attn.mhsa.proj.weight    |     65,536\nstages.2.0.grid_attn.mhsa.proj.bias      |        256\nstages.2.0.norm3.weight                  |        256\nstages.2.0.norm3.bias                    |        256\nstages.2.0.mlp.fc1.weight                |    262,144\nstages.2.0.mlp.fc1.bias                  |      1,024\nstages.2.0.mlp.fc2.weight                |    262,144\nstages.2.0.mlp.fc2.bias                  |        256\nstages.2.1.outlook.norm1.ln.weight       |        256\nstages.2.1.outlook.norm1.ln.bias         |        256\nstages.2.1.outlook.attn.attn.weight      |     18,432\nstages.2.1.outlook.attn.attn.bias        |         72\nstages.2.1.outlook.attn.v.weight         |     65,536\nstages.2.1.outlook.attn.v.bias           |        256\nstages.2.1.outlook.attn.proj.weight      |     65,536\nstages.2.1.outlook.attn.proj.bias        |        256\nstages.2.1.outlook.norm2.ln.weight       |        256\nstages.2.1.outlook.norm2.ln.bias         |        256\nstages.2.1.outlook.mlp.fc1.weight        |    131,072\nstages.2.1.outlook.mlp.fc1.bias          |        512\nstages.2.1.outlook.mlp.fc2.weight        |    131,072\nstages.2.1.outlook.mlp.fc2.bias          |        256\nstages.2.1.mbconv.expand.0.weight        |    262,144\nstages.2.1.mbconv.expand.1.weight        |      1,024\nstages.2.1.mbconv.expand.1.bias          |      1,024\nstages.2.1.mbconv.depthwise.0.weight     |      9,216\nstages.2.1.mbconv.depthwise.1.weight     |      1,024\nstages.2.1.mbconv.depthwise.1.bias       |      1,024\nstages.2.1.mbconv.se.fc1.weight          |    262,144\nstages.2.1.mbconv.se.fc1.bias            |        256\nstages.2.1.mbconv.se.fc2.weight          |    262,144\nstages.2.1.mbconv.se.fc2.bias            |      1,024\nstages.2.1.mbconv.project.0.weight       |    262,144\nstages.2.1.mbconv.project.1.weight       |        256\nstages.2.1.mbconv.project.1.bias         |        256\nstages.2.1.norm2.weight                  |        256\nstages.2.1.norm2.bias                    |        256\nstages.2.1.grid_attn.mhsa.qkv.weight     |    196,608\nstages.2.1.grid_attn.mhsa.qkv.bias       |        768\nstages.2.1.grid_attn.mhsa.proj.weight    |     65,536\nstages.2.1.grid_attn.mhsa.proj.bias      |        256\nstages.2.1.norm3.weight                  |        256\nstages.2.1.norm3.bias                    |        256\nstages.2.1.mlp.fc1.weight                |    262,144\nstages.2.1.mlp.fc1.bias                  |      1,024\nstages.2.1.mlp.fc2.weight                |    262,144\nstages.2.1.mlp.fc2.bias                  |        256\nstages.2.2.outlook.norm1.ln.weight       |        256\nstages.2.2.outlook.norm1.ln.bias         |        256\nstages.2.2.outlook.attn.attn.weight      |     18,432\nstages.2.2.outlook.attn.attn.bias        |         72\nstages.2.2.outlook.attn.v.weight         |     65,536\nstages.2.2.outlook.attn.v.bias           |        256\nstages.2.2.outlook.attn.proj.weight      |     65,536\nstages.2.2.outlook.attn.proj.bias        |        256\nstages.2.2.outlook.norm2.ln.weight       |        256\nstages.2.2.outlook.norm2.ln.bias         |        256\nstages.2.2.outlook.mlp.fc1.weight        |    131,072\nstages.2.2.outlook.mlp.fc1.bias          |        512\nstages.2.2.outlook.mlp.fc2.weight        |    131,072\nstages.2.2.outlook.mlp.fc2.bias          |        256\nstages.2.2.mbconv.expand.0.weight        |    262,144\nstages.2.2.mbconv.expand.1.weight        |      1,024\nstages.2.2.mbconv.expand.1.bias          |      1,024\nstages.2.2.mbconv.depthwise.0.weight     |      9,216\nstages.2.2.mbconv.depthwise.1.weight     |      1,024\nstages.2.2.mbconv.depthwise.1.bias       |      1,024\nstages.2.2.mbconv.se.fc1.weight          |    262,144\nstages.2.2.mbconv.se.fc1.bias            |        256\nstages.2.2.mbconv.se.fc2.weight          |    262,144\nstages.2.2.mbconv.se.fc2.bias            |      1,024\nstages.2.2.mbconv.project.0.weight       |    262,144\nstages.2.2.mbconv.project.1.weight       |        256\nstages.2.2.mbconv.project.1.bias         |        256\nstages.2.2.norm2.weight                  |        256\nstages.2.2.norm2.bias                    |        256\nstages.2.2.grid_attn.mhsa.qkv.weight     |    196,608\nstages.2.2.grid_attn.mhsa.qkv.bias       |        768\nstages.2.2.grid_attn.mhsa.proj.weight    |     65,536\nstages.2.2.grid_attn.mhsa.proj.bias      |        256\nstages.2.2.norm3.weight                  |        256\nstages.2.2.norm3.bias                    |        256\nstages.2.2.mlp.fc1.weight                |    262,144\nstages.2.2.mlp.fc1.bias                  |      1,024\nstages.2.2.mlp.fc2.weight                |    262,144\nstages.2.2.mlp.fc2.bias                  |        256\nstages.3.0.outlook.norm1.ln.weight       |        384\nstages.3.0.outlook.norm1.ln.bias         |        384\nstages.3.0.outlook.attn.attn.weight      |     20,736\nstages.3.0.outlook.attn.attn.bias        |         54\nstages.3.0.outlook.attn.v.weight         |    147,456\nstages.3.0.outlook.attn.v.bias           |        384\nstages.3.0.outlook.attn.proj.weight      |    147,456\nstages.3.0.outlook.attn.proj.bias        |        384\nstages.3.0.outlook.norm2.ln.weight       |        384\nstages.3.0.outlook.norm2.ln.bias         |        384\nstages.3.0.outlook.mlp.fc1.weight        |    294,912\nstages.3.0.outlook.mlp.fc1.bias          |        768\nstages.3.0.outlook.mlp.fc2.weight        |    294,912\nstages.3.0.outlook.mlp.fc2.bias          |        384\nstages.3.0.mbconv.expand.0.weight        |    589,824\nstages.3.0.mbconv.expand.1.weight        |      1,536\nstages.3.0.mbconv.expand.1.bias          |      1,536\nstages.3.0.mbconv.depthwise.0.weight     |     13,824\nstages.3.0.mbconv.depthwise.1.weight     |      1,536\nstages.3.0.mbconv.depthwise.1.bias       |      1,536\nstages.3.0.mbconv.se.fc1.weight          |    589,824\nstages.3.0.mbconv.se.fc1.bias            |        384\nstages.3.0.mbconv.se.fc2.weight          |    589,824\nstages.3.0.mbconv.se.fc2.bias            |      1,536\nstages.3.0.mbconv.project.0.weight       |    589,824\nstages.3.0.mbconv.project.1.weight       |        384\nstages.3.0.mbconv.project.1.bias         |        384\nstages.3.0.norm2.weight                  |        384\nstages.3.0.norm2.bias                    |        384\nstages.3.0.grid_attn.mhsa.qkv.weight     |    442,368\nstages.3.0.grid_attn.mhsa.qkv.bias       |      1,152\nstages.3.0.grid_attn.mhsa.proj.weight    |    147,456\nstages.3.0.grid_attn.mhsa.proj.bias      |        384\nstages.3.0.norm3.weight                  |        384\nstages.3.0.norm3.bias                    |        384\nstages.3.0.mlp.fc1.weight                |    589,824\nstages.3.0.mlp.fc1.bias                  |      1,536\nstages.3.0.mlp.fc2.weight                |    589,824\nstages.3.0.mlp.fc2.bias                  |        384\ndowns.0.op.0.weight                      |     73,728\ndowns.0.op.1.weight                      |        128\ndowns.0.op.1.bias                        |        128\ndowns.1.op.0.weight                      |    294,912\ndowns.1.op.1.weight                      |        256\ndowns.1.op.1.bias                        |        256\ndowns.2.op.0.weight                      |    884,736\ndowns.2.op.1.weight                      |        384\ndowns.2.op.1.bias                        |        384\nhead_norm.weight                         |        384\nhead_norm.bias                           |        384\nclassifier.weight                        |     38,400\nclassifier.bias                          |        100\n------------------------------------------------------------\nTOTAL                                    | 14,599,198\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"14599198"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"evaluate_one_epoch(model=model,dataloader=test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T07:33:09.862276Z","iopub.execute_input":"2026-01-07T07:33:09.862772Z","iopub.status.idle":"2026-01-07T07:34:48.369695Z","shell.execute_reply.started":"2026-01-07T07:33:09.862748Z","shell.execute_reply":"2026-01-07T07:34:48.368880Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"(0.6719321002960205, {'top1': 81.15, 'top3': 93.29, 'top5': 95.8})"},"metadata":{}}],"execution_count":36}]}