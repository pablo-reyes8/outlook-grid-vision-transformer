{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Szc_5HDk-up"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import RandAugment\n",
        "\n",
        "def get_cifar100_datasets(\n",
        "    data_dir: str = \"./data\",\n",
        "    val_split: float = 0.0,\n",
        "    ra_num_ops: int = 2,\n",
        "    ra_magnitude: int = 7,\n",
        "    random_erasing_p: float = 0.25,\n",
        "    erasing_scale=(0.02, 0.20),\n",
        "    erasing_ratio=(0.3, 3.3),\n",
        "    img_size: int = 32,):\n",
        "\n",
        "    \"\"\"\n",
        "    CIFAR-100 datasets con augmentations \"mix-friendly\":\n",
        "    diseñadas para complementar Mixup/CutMix (en el loop) sin pasarse.\n",
        "\n",
        "    img_size:\n",
        "      - 32 (default): CIFAR nativo.\n",
        "      - >32: upsample (p.ej. 64) para experimentos (más tokens/compute).\n",
        "    \"\"\"\n",
        "    if img_size < 32:\n",
        "        raise ValueError(f\"img_size must be >= 32 for CIFAR-100. Got {img_size}.\")\n",
        "\n",
        "    cifar100_mean = (0.5071, 0.4867, 0.4408)\n",
        "    cifar100_std  = (0.2675, 0.2565, 0.2761)\n",
        "\n",
        "    # Si subimos resolución, primero hacemos resize y adaptamos crop/padding.\n",
        "    # Padding recomendado proporcional: 32->4, 64->8, etc.\n",
        "\n",
        "    crop_padding = max(4, img_size // 8)\n",
        "\n",
        "    train_ops = []\n",
        "    if img_size != 32:\n",
        "        train_ops.append(transforms.Resize(img_size, interpolation=transforms.InterpolationMode.BICUBIC))\n",
        "\n",
        "    train_ops += [\n",
        "        transforms.RandomCrop(img_size, padding=crop_padding),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        RandAugment(num_ops=ra_num_ops, magnitude=ra_magnitude),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(cifar100_mean, cifar100_std),\n",
        "        transforms.RandomErasing(\n",
        "            p=random_erasing_p,\n",
        "            scale=erasing_scale,\n",
        "            ratio=erasing_ratio,\n",
        "            value=\"random\",),]\n",
        "\n",
        "    train_transform = transforms.Compose(train_ops)\n",
        "\n",
        "    test_ops = []\n",
        "    if img_size != 32:\n",
        "        test_ops.append(transforms.Resize(img_size, interpolation=transforms.InterpolationMode.BICUBIC))\n",
        "\n",
        "    test_ops += [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(cifar100_mean, cifar100_std),]\n",
        "\n",
        "    test_transform = transforms.Compose(test_ops)\n",
        "\n",
        "    full_train_dataset = datasets.CIFAR100(\n",
        "        root=data_dir, train=True, download=True, transform=train_transform)\n",
        "\n",
        "    test_dataset = datasets.CIFAR100(\n",
        "        root=data_dir, train=False, download=True, transform=test_transform)\n",
        "\n",
        "    if val_split > 0.0:\n",
        "        n_total = len(full_train_dataset)\n",
        "        n_val = int(n_total * val_split)\n",
        "        n_train = n_total - n_val\n",
        "        train_dataset, val_dataset = random_split(\n",
        "            full_train_dataset,\n",
        "            [n_train, n_val],\n",
        "            generator=torch.Generator().manual_seed(7),)\n",
        "\n",
        "    else:\n",
        "        train_dataset = full_train_dataset\n",
        "        val_dataset = None\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "\n",
        "def get_cifar100_dataloaders(\n",
        "    batch_size: int = 128,\n",
        "    data_dir: str = \"./data\",\n",
        "    num_workers: int = 2,\n",
        "    val_split: float = 0.0,\n",
        "    pin_memory: bool = True,\n",
        "    ra_num_ops: int = 2,\n",
        "    ra_magnitude: int = 7,\n",
        "    random_erasing_p: float = 0.25,\n",
        "    img_size: int = 32,):\n",
        "    \"\"\"\n",
        "    Dataloaders CIFAR-100 listos para entrenar con Mixup/CutMix en el loop.\n",
        "    Augmentations no tan agresivas.\n",
        "\n",
        "    img_size:\n",
        "      - 32 (default): CIFAR nativo.\n",
        "      - 64: experimento de upsample (ojo: más compute).\n",
        "    \"\"\"\n",
        "    train_ds, val_ds, test_ds = get_cifar100_datasets(\n",
        "        data_dir=data_dir,\n",
        "        val_split=val_split,\n",
        "        ra_num_ops=ra_num_ops,\n",
        "        ra_magnitude=ra_magnitude,\n",
        "        random_erasing_p=random_erasing_p,\n",
        "        img_size=img_size,)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=pin_memory,\n",
        "        persistent_workers=(num_workers > 0),)\n",
        "\n",
        "    val_loader = None\n",
        "    if val_ds is not None:\n",
        "        val_loader = DataLoader(\n",
        "            val_ds,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=num_workers,\n",
        "            pin_memory=pin_memory,\n",
        "            persistent_workers=(num_workers > 0),)\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=pin_memory,\n",
        "        persistent_workers=(num_workers > 0),)\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcvYzk_fX9zK",
        "outputId": "3df751a9-f620-4a55-93fc-b9d47df374f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 169M/169M [00:04<00:00, 35.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "train_loader, val_loader, test_loader = get_cifar100_dataloaders(\n",
        "    batch_size=128,\n",
        "    data_dir=\"./data/cifar100\",\n",
        "    num_workers=2,\n",
        "    val_split=0.1,\n",
        "    img_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUbtacnUYMKF",
        "outputId": "ddf22534-e60c-4c8d-bcd1-5a623b1a8545"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==========================================================================================\n",
            "TRAIN_LOADER SUMMARY\n",
            "==========================================================================================\n",
            "Dataset type        : Subset\n",
            "  ↳ Wrapped dataset  : CIFAR100 (Subset-like)\n",
            "  ↳ Subset size      : 45000\n",
            "Num samples         : 45000\n",
            "Batch size          : 128\n",
            "Num workers         : 2\n",
            "Pin memory          : True\n",
            "Drop last           : False\n",
            "Sampler             : RandomSampler\n",
            "len(loader) (#batches): 352 (≈ ceil(45000/128) = 352)\n",
            "\n",
            "First batch:\n",
            "  x.shape           : (128, 3, 64, 64)\n",
            "  y.shape           : (128,)\n",
            "  x.dtype           : torch.float32\n",
            "  y.dtype           : torch.int64\n",
            "  x.min/max         : -4.3048 / 4.0542\n",
            "  y.min/max         : 0 / 99\n",
            "  unique labels (batch): 74\n",
            "\n",
            "Quick stats over up to 50 batches:\n",
            "  Approx mean        : -0.287313\n",
            "  Approx std         : 1.113161\n",
            "  Seen label counts  : 100 classes (in sampled batches)\n",
            "  Top-5 labels       : [(2, 82), (18, 81), (58, 79), (22, 79), (99, 79)]\n",
            "\n",
            "Full dataset label distribution:\n",
            "  #classes detected  : 100\n",
            "  min/max per class  : 436 / 463\n",
            "  first 10 classes   : [(0, 457), (1, 439), (2, 448), (3, 455), (4, 446), (5, 447), (6, 451), (7, 457), (8, 448), (9, 453)]\n",
            "  balance check      : not perfectly balanced\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision import datasets\n",
        "from collections import Counter, defaultdict\n",
        "import math\n",
        "\n",
        "CIFAR100_MEAN = (0.5071, 0.4867, 0.4408)\n",
        "CIFAR100_STD  = (0.2675, 0.2565, 0.2761)\n",
        "\n",
        "\n",
        "\n",
        "def describe_loader(loader, name=\"loader\", max_batches_for_stats=50):\n",
        "    ds = loader.dataset\n",
        "    n = len(ds)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(f\"{name.upper()} SUMMARY\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    print(f\"Dataset type        : {type(ds).__name__}\")\n",
        "    if hasattr(ds, \"dataset\") and hasattr(ds, \"indices\"):\n",
        "        print(f\"  ↳ Wrapped dataset  : {type(ds.dataset).__name__} (Subset-like)\")\n",
        "        print(f\"  ↳ Subset size      : {len(ds.indices)}\")\n",
        "\n",
        "    print(f\"Num samples         : {n}\")\n",
        "    print(f\"Batch size          : {getattr(loader, 'batch_size', None)}\")\n",
        "    print(f\"Num workers         : {getattr(loader, 'num_workers', None)}\")\n",
        "    print(f\"Pin memory          : {getattr(loader, 'pin_memory', None)}\")\n",
        "    print(f\"Drop last           : {getattr(loader, 'drop_last', None)}\")\n",
        "\n",
        "    sampler = getattr(loader, \"sampler\", None)\n",
        "    sampler_name = type(sampler).__name__ if sampler is not None else None\n",
        "    print(f\"Sampler             : {sampler_name}\")\n",
        "\n",
        "    num_batches = len(loader)\n",
        "    bs = loader.batch_size if loader.batch_size is not None else \"?\"\n",
        "    approx_batches = math.ceil(n / loader.batch_size) if loader.batch_size else \"?\"\n",
        "    print(f\"len(loader) (#batches): {num_batches} (≈ ceil({n}/{bs}) = {approx_batches})\")\n",
        "\n",
        "    x, y = next(iter(loader))\n",
        "    print(\"\\nFirst batch:\")\n",
        "    print(f\"  x.shape           : {tuple(x.shape)}\")\n",
        "    print(f\"  y.shape           : {tuple(y.shape)}\")\n",
        "    print(f\"  x.dtype           : {x.dtype}\")\n",
        "    print(f\"  y.dtype           : {y.dtype}\")\n",
        "    print(f\"  x.min/max         : {float(x.min()):.4f} / {float(x.max()):.4f}\")\n",
        "    print(f\"  y.min/max         : {int(y.min())} / {int(y.max())}\")\n",
        "    print(f\"  unique labels (batch): {len(torch.unique(y))}\")\n",
        "    print(f\"\\nQuick stats over up to {max_batches_for_stats} batches:\")\n",
        "\n",
        "    n_seen = 0\n",
        "    sum_ = 0.0\n",
        "    sumsq_ = 0.0\n",
        "    class_counts = Counter()\n",
        "\n",
        "    for bi, (xb, yb) in enumerate(loader):\n",
        "        if bi >= max_batches_for_stats:\n",
        "            break\n",
        "        xb = xb.float()\n",
        "        n_pix = xb.numel()\n",
        "        sum_ += xb.sum().item()\n",
        "        sumsq_ += (xb * xb).sum().item()\n",
        "        n_seen += n_pix\n",
        "\n",
        "        class_counts.update(yb.tolist())\n",
        "\n",
        "    mean = sum_ / max(1, n_seen)\n",
        "    var = (sumsq_ / max(1, n_seen)) - mean**2\n",
        "    std = math.sqrt(max(0.0, var))\n",
        "\n",
        "    print(f\"  Approx mean        : {mean:.6f}\")\n",
        "    print(f\"  Approx std         : {std:.6f}\")\n",
        "    top5 = class_counts.most_common(5)\n",
        "    print(f\"  Seen label counts  : {len(class_counts)} classes (in sampled batches)\")\n",
        "    print(f\"  Top-5 labels       : {top5}\")\n",
        "\n",
        "    targets = None\n",
        "    if hasattr(ds, \"targets\"):\n",
        "        targets = ds.targets\n",
        "    elif hasattr(ds, \"labels\"):\n",
        "        targets = ds.labels\n",
        "    elif hasattr(ds, \"dataset\") and hasattr(ds.dataset, \"targets\") and hasattr(ds, \"indices\"):\n",
        "        base_targets = ds.dataset.targets\n",
        "        targets = [base_targets[i] for i in ds.indices]\n",
        "\n",
        "    if targets is not None:\n",
        "        full_counts = Counter(list(map(int, targets)))\n",
        "        k = len(full_counts)\n",
        "        print(f\"\\nFull dataset label distribution:\")\n",
        "        print(f\"  #classes detected  : {k}\")\n",
        "        if k > 0:\n",
        "            mn = min(full_counts.values())\n",
        "            mx = max(full_counts.values())\n",
        "            print(f\"  min/max per class  : {mn} / {mx}\")\n",
        "            first10 = sorted(full_counts.items(), key=lambda t: t[0])[:10]\n",
        "            print(f\"  first 10 classes   : {first10}\")\n",
        "            if mn == mx:\n",
        "                print(\"  balance check      : perfectly balanced\")\n",
        "            else:\n",
        "                print(\"  balance check      : not perfectly balanced\")\n",
        "    else:\n",
        "        print(\"\\nFull dataset label distribution: (couldn't find targets/labels attribute)\")\n",
        "\n",
        "    print(\"=\"*90)\n",
        "\n",
        "\n",
        "describe_loader(train_loader, \"train_loader\", max_batches_for_stats=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u08t_5gzYXoN"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def unnormalize(images: torch.Tensor,\n",
        "                mean=CIFAR100_MEAN,\n",
        "                std=CIFAR100_STD):\n",
        "    \"\"\"\n",
        "    Des-normaliza un batch de imágenes.\n",
        "    images: tensor [B, C, H, W] normalizado.\n",
        "    \"\"\"\n",
        "    mean = torch.tensor(mean, device=images.device).view(1, -1, 1, 1)\n",
        "    std = torch.tensor(std, device=images.device).view(1, -1, 1, 1)\n",
        "    return images * std + mean\n",
        "\n",
        "\n",
        "def show_batch(images: torch.Tensor,\n",
        "               labels: torch.Tensor,\n",
        "               class_names=None,\n",
        "               n: int = 8):\n",
        "    \"\"\"\n",
        "    Muestra las primeras n imágenes de un batch con sus labels.\n",
        "\n",
        "    Args:\n",
        "        images: tensor [B, C, H, W] (normalizado).\n",
        "        labels: tensor [B].\n",
        "        class_names: lista de nombres de clases (len = 100).\n",
        "        n: cuántas imágenes mostrar (en una fila).\n",
        "    \"\"\"\n",
        "    images = images[:n].cpu()\n",
        "    labels = labels[:n].cpu()\n",
        "    images_unnorm = unnormalize(images)\n",
        "\n",
        "    grid = make_grid(images_unnorm, nrow=n, padding=2)\n",
        "    npimg = grid.permute(1, 2, 0).numpy()\n",
        "\n",
        "    plt.figure(figsize=(2 * n, 2.5))\n",
        "    plt.imshow(npimg)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    if class_names is not None:\n",
        "        title = \" | \".join(class_names[int(lbl)] for lbl in labels)\n",
        "        plt.title(title, fontsize=10)\n",
        "    plt.show()\n",
        "\n",
        "cifar100_train = datasets.CIFAR100(\n",
        "    root=\"./data/cifar100\",\n",
        "    train=True,\n",
        "    download=False)\n",
        "\n",
        "class_names = cifar100_train.classes\n",
        "images, labels = next(iter(train_loader))\n",
        "show_batch(images, labels, class_names=class_names, n=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnzAvcYaY_rK"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ll76DN0Hx6FR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class LayerNorm2d(nn.Module):\n",
        "    def __init__(self, C, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.ln = nn.LayerNorm(C, eps=eps)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # [B,C,H,W] -> [B,H,W,C] -> LN -> [B,C,H,W]\n",
        "        return self.ln(x.permute(0,2,3,1)).permute(0,3,1,2).contiguous()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def _make_activation(act: str) -> nn.Module:\n",
        "    act = act.lower()\n",
        "    if act == \"silu\":\n",
        "        return nn.SiLU(inplace=True)\n",
        "    if act == \"relu\":\n",
        "        return nn.ReLU(inplace=True)\n",
        "    if act == \"gelu\":\n",
        "        return nn.GELU()\n",
        "    raise ValueError(f\"Unknown activation '{act}'. Use one of: silu|gelu|relu\")\n",
        "\n",
        "\n",
        "class MLP2d(nn.Module):\n",
        "    def __init__(self, dim, mlp_ratio=4.0, drop=0.0, act=\"gelu\"):\n",
        "        super().__init__()\n",
        "        hidden = max(1, int(dim * mlp_ratio))\n",
        "        self.fc1 = nn.Conv2d(dim, hidden, 1)\n",
        "        self.act = _make_activation(act)\n",
        "        self.drop1 = nn.Dropout(drop)\n",
        "        self.fc2 = nn.Conv2d(hidden, dim, 1)\n",
        "        self.drop2 = nn.Dropout(drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class OutlookAttention2d(nn.Module):\n",
        "    \"\"\"\n",
        "    OutlookAttention on [B,C,H,W] (NCHW) with dynamic local aggregation.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim: int,\n",
        "        num_heads: int = 6,\n",
        "        kernel_size: int = 3,\n",
        "        stride: int = 1,\n",
        "        attn_drop: float = 0.0,\n",
        "        proj_drop: float = 0.0,\n",
        "        qkv_bias: bool = True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert dim % num_heads == 0, \"dim must be divisible by num_heads\"\n",
        "        if kernel_size <= 0 or kernel_size % 2 == 0:\n",
        "            raise ValueError(\"kernel_size must be odd and >0 (e.g., 3,5,7)\")\n",
        "        if stride <= 0:\n",
        "            raise ValueError(\"stride must be > 0\")\n",
        "\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = dim // num_heads\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "\n",
        "        kk = kernel_size * kernel_size\n",
        "        bias = bool(qkv_bias)\n",
        "\n",
        "        # logits per spatial position\n",
        "        self.attn = nn.Conv2d(dim, num_heads * kk, kernel_size=1, bias=bias)\n",
        "        # values\n",
        "        self.v = nn.Conv2d(dim, dim, kernel_size=1, bias=bias)\n",
        "\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Conv2d(dim, dim, kernel_size=1, bias=True)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        B, C, H, W = x.shape\n",
        "        k = self.kernel_size\n",
        "        s = self.stride\n",
        "        heads = self.num_heads\n",
        "        hd = self.head_dim\n",
        "        kk = k * k\n",
        "\n",
        "        # attn logits: [B, heads*kk, H, W] -> (optional) pool if stride>1\n",
        "        a = self.attn(x)\n",
        "        if s > 1:\n",
        "            a = F.avg_pool2d(a, kernel_size=s, stride=s)\n",
        "        _, _, Hs, Ws = a.shape\n",
        "\n",
        "        # [B, heads, kk, Hs, Ws] -> [B, Hs*Ws, heads, kk]\n",
        "        a = a.view(B, heads, kk, Hs, Ws).flatten(3).permute(0, 3, 1, 2).contiguous()\n",
        "        a = F.softmax(a, dim=-1)\n",
        "        a = self.attn_drop(a)\n",
        "\n",
        "        # values + unfold neighborhoods\n",
        "        v = self.v(x)  # [B,C,H,W]\n",
        "        pad = k // 2\n",
        "        v_unf = F.unfold(v, kernel_size=k, padding=pad, stride=s)  # [B, C*kk, Hs*Ws]\n",
        "\n",
        "        # -> [B, Hs*Ws, heads, hd, kk]\n",
        "        v_unf = v_unf.view(B, heads, hd, kk, Hs * Ws).permute(0, 4, 1, 2, 3).contiguous()\n",
        "\n",
        "        # weighted sum over kk\n",
        "        y = (v_unf * a.unsqueeze(3)).sum(dim=-1)  # [B, Hs*Ws, heads, hd]\n",
        "        y = y.permute(0, 2, 3, 1).contiguous().view(B, C, Hs, Ws)\n",
        "\n",
        "        y = self.proj(y)\n",
        "        y = self.proj_drop(y)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "At2AT2hN0hw8"
      },
      "outputs": [],
      "source": [
        "class DropPath(nn.Module):\n",
        "    \"\"\"\n",
        "    DropPath / Stochastic Depth. Works for any tensor shape with batch in dim 0.\n",
        "    \"\"\"\n",
        "    def __init__(self, drop_prob: float = 0.0):\n",
        "        super().__init__()\n",
        "        self.drop_prob = float(drop_prob)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        if self.drop_prob == 0.0 or (not self.training):\n",
        "            return x\n",
        "        keep_prob = 1.0 - self.drop_prob\n",
        "        # shape: [B, 1, 1, 1, ...]\n",
        "        shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n",
        "        mask = torch.empty(shape, device=x.device, dtype=x.dtype).bernoulli_(keep_prob)\n",
        "        return x * mask / keep_prob\n",
        "\n",
        "\n",
        "class OutlookerBlock2d(nn.Module):\n",
        "    \"\"\"\n",
        "    x (NCHW) -> LN2d -> OutlookAttention2d -> DropPath + res\n",
        "             -> LN2d -> MLP2d            -> DropPath + res\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim: int,\n",
        "        num_heads: int,\n",
        "        kernel_size: int = 3,\n",
        "        stride: int = 1,\n",
        "        mlp_ratio: float = 2.0,\n",
        "        attn_drop: float = 0.0,\n",
        "        proj_drop: float = 0.0,\n",
        "        drop_path: float = 0.0,\n",
        "        mlp_drop: float = 0.0,\n",
        "        act: str = \"gelu\",\n",
        "        norm_eps: float = 1e-6):\n",
        "\n",
        "        super().__init__()\n",
        "        self.norm1 = LayerNorm2d(dim, eps=norm_eps)\n",
        "        self.attn = OutlookAttention2d(\n",
        "            dim=dim,\n",
        "            num_heads=num_heads,\n",
        "            kernel_size=kernel_size,\n",
        "            stride=stride,\n",
        "            attn_drop=attn_drop,\n",
        "            proj_drop=proj_drop)\n",
        "\n",
        "        self.dp1 = DropPath(drop_path) if drop_path > 0 else nn.Identity()\n",
        "\n",
        "        self.norm2 = LayerNorm2d(dim, eps=norm_eps)\n",
        "        self.mlp = MLP2d(dim=dim, mlp_ratio=mlp_ratio, drop=mlp_drop, act=act)\n",
        "        self.dp2 = DropPath(drop_path) if drop_path > 0 else nn.Identity()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = x + self.dp1(self.attn(self.norm1(x)))\n",
        "        x = x + self.dp2(self.mlp(self.norm2(x)))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_InvOziU0nKb",
        "outputId": "17a209dc-f3c8-4129-d847-0592f357eeaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([8, 96, 16, 16]) torch.Size([8, 96, 16, 16])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(8, 96, 16, 16)\n",
        "blk = OutlookerBlock2d(dim=96, num_heads=6, kernel_size=3, stride=1)\n",
        "y = blk(x)\n",
        "print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fV4IUh9G222y"
      },
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "from dataclasses import dataclass\n",
        "\n",
        "class SqueezeExcite(nn.Module):\n",
        "    def __init__(self, channels: int, se_ratio: float = 0.25, act: str = \"silu\"):\n",
        "        super().__init__()\n",
        "        if not (0.0 < se_ratio <= 1.0):\n",
        "            raise ValueError(\"se_ratio must be in (0, 1].\")\n",
        "\n",
        "        hidden = max(1, int(channels * se_ratio))\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc1 = nn.Conv2d(channels, hidden, kernel_size=1, bias=True)\n",
        "        self.act = _make_activation(act)\n",
        "        self.fc2 = nn.Conv2d(hidden, channels, kernel_size=1, bias=True)\n",
        "        self.gate = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        s = self.pool(x)\n",
        "        s = self.fc1(s)\n",
        "        s = self.act(s)\n",
        "        s = self.fc2(s)\n",
        "        return x * self.gate(s)\n",
        "\n",
        "\n",
        "ActType = Literal[\"silu\", \"gelu\", \"relu\"]\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class MBConvConfig:\n",
        "    expand_ratio: float = 4.0\n",
        "    se_ratio: float = 0.25\n",
        "    act: ActType = \"silu\"\n",
        "    use_bn: bool = True\n",
        "    drop_path: float = 0.0\n",
        "\n",
        "class MBConv(nn.Module):\n",
        "    \"\"\"\n",
        "    MBConv block (NCHW):\n",
        "      Expand 1x1 -> Depthwise 3x3 -> SE -> Project 1x1\n",
        "      Residual if stride=1 and in_ch==out_ch\n",
        "    \"\"\"\n",
        "    def __init__(self, in_ch: int, out_ch: int, stride: int = 1, cfg: MBConvConfig = MBConvConfig()):\n",
        "        super().__init__()\n",
        "        if in_ch <= 0 or out_ch <= 0:\n",
        "            raise ValueError(\"in_ch and out_ch must be > 0\")\n",
        "        if stride not in (1, 2):\n",
        "            raise ValueError(\"stride must be 1 or 2\")\n",
        "\n",
        "        self.in_ch = in_ch\n",
        "        self.out_ch = out_ch\n",
        "        self.stride = stride\n",
        "\n",
        "        bn = (lambda c: nn.BatchNorm2d(c)) if cfg.use_bn else (lambda c: nn.Identity())\n",
        "        act = _make_activation(cfg.act)\n",
        "\n",
        "        mid_ch = max(1, int(round(in_ch * cfg.expand_ratio)))\n",
        "\n",
        "        if mid_ch != in_ch:\n",
        "            self.expand = nn.Sequential(\n",
        "                nn.Conv2d(in_ch, mid_ch, kernel_size=1, bias=not cfg.use_bn),\n",
        "                bn(mid_ch),\n",
        "                act,)\n",
        "\n",
        "        else:\n",
        "            self.expand = nn.Identity()\n",
        "\n",
        "        self.depthwise = nn.Sequential(\n",
        "            nn.Conv2d(mid_ch, mid_ch, kernel_size=3, stride=stride, padding=1,\n",
        "                      groups=mid_ch, bias=not cfg.use_bn),\n",
        "            bn(mid_ch),\n",
        "            act,)\n",
        "\n",
        "        self.se = SqueezeExcite(mid_ch, se_ratio=cfg.se_ratio, act=cfg.act) if cfg.se_ratio > 0 else nn.Identity()\n",
        "\n",
        "        self.project = nn.Sequential(\n",
        "            nn.Conv2d(mid_ch, out_ch, kernel_size=1, bias=not cfg.use_bn),\n",
        "            bn(out_ch),)\n",
        "\n",
        "        self.use_res = (stride == 1 and in_ch == out_ch)\n",
        "        self.drop_path = DropPath(cfg.drop_path) if (cfg.drop_path and cfg.drop_path > 0) else nn.Identity()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        out = self.expand(x)\n",
        "        out = self.depthwise(out)\n",
        "        out = self.se(out)\n",
        "        out = self.project(out)\n",
        "\n",
        "        if self.use_res:\n",
        "            out = x + self.drop_path(out)\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYQXRj5I3aIq"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3CfVPEG3Z0Q"
      },
      "outputs": [],
      "source": [
        "def grid_partition(x: torch.Tensor, grid_size: int):\n",
        "    if x.ndim != 4:\n",
        "        raise ValueError(f\"Expected x.ndim==4 (BHWC). Got shape {tuple(x.shape)}\")\n",
        "    B, H, W, C = x.shape\n",
        "    g = grid_size\n",
        "    if g <= 0:\n",
        "        raise ValueError(\"grid_size must be > 0\")\n",
        "    if (H % g) != 0 or (W % g) != 0:\n",
        "        raise ValueError(f\"H and W must be divisible by grid_size. Got H={H}, W={W}, g={g}\")\n",
        "\n",
        "    Hg, Wg = H // g, W // g\n",
        "    x = x.view(B, Hg, g, Wg, g, C)  # [B, Hg, g, Wg, g, C]\n",
        "    grids = x.permute(0, 2, 4, 1, 3, 5).contiguous().view(B * g * g, Hg, Wg, C)\n",
        "    meta = (B, H, W, C, g)\n",
        "    return grids, meta\n",
        "\n",
        "\n",
        "def grid_unpartition(grids: torch.Tensor, meta) -> torch.Tensor:\n",
        "    if grids.ndim != 4:\n",
        "        raise ValueError(f\"Expected grids.ndim==4. Got shape {tuple(grids.shape)}\")\n",
        "    B, H, W, C, g = meta\n",
        "    Hg, Wg = H // g, W // g\n",
        "    if grids.shape[0] != B * g * g:\n",
        "        raise ValueError(f\"grids.shape[0] must be B*g*g = {B*g*g}. Got {grids.shape[0]}\")\n",
        "    if grids.shape[1] != Hg or grids.shape[2] != Wg or grids.shape[3] != C:\n",
        "        raise ValueError(f\"grids shape mismatch. Expected (*,{Hg},{Wg},{C}) got {tuple(grids.shape)}\")\n",
        "\n",
        "    x = grids.view(B, g, g, Hg, Wg, C)\n",
        "    x = x.permute(0, 3, 1, 4, 2, 5).contiguous().view(B, H, W, C)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhrwKG8K3cJU"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Literal\n",
        "\n",
        "\n",
        "AttnMode = Literal[\"grid\"]\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class AttentionConfig:\n",
        "    dim: int\n",
        "    num_heads: int\n",
        "    qkv_bias: bool = True\n",
        "    attn_drop: float = 0.0\n",
        "    proj_drop: float = 0.0\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class LocalAttention2DConfig:\n",
        "    mode: AttnMode\n",
        "    dim: int\n",
        "    num_heads: int\n",
        "    grid_size: int\n",
        "    window_size: int = 1\n",
        "    qkv_bias: bool = True\n",
        "    attn_drop: float = 0.0\n",
        "    proj_drop: float = 0.0\n",
        "\n",
        "\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Standard MHSA for token sequences.\n",
        "\n",
        "    Input:  x [B, N, C]\n",
        "    Output: y [B, N, C]\n",
        "\n",
        "    Works for both window and grid partitions because both can be flattened to [Bgrp, N, C].\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cfg: AttentionConfig):\n",
        "        super().__init__()\n",
        "        if cfg.dim <= 0:\n",
        "            raise ValueError(\"cfg.dim must be > 0\")\n",
        "        if cfg.num_heads <= 0:\n",
        "            raise ValueError(\"cfg.num_heads must be > 0\")\n",
        "        if cfg.dim % cfg.num_heads != 0:\n",
        "            raise ValueError(f\"dim ({cfg.dim}) must be divisible by num_heads ({cfg.num_heads})\")\n",
        "\n",
        "        self.dim = cfg.dim\n",
        "        self.num_heads = cfg.num_heads\n",
        "        self.head_dim = cfg.dim // cfg.num_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "\n",
        "        self.qkv = nn.Linear(cfg.dim, 3 * cfg.dim, bias=cfg.qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(cfg.attn_drop)\n",
        "        self.proj = nn.Linear(cfg.dim, cfg.dim, bias=True)\n",
        "        self.proj_drop = nn.Dropout(cfg.proj_drop)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        if x.ndim != 3:\n",
        "            raise ValueError(f\"Expected x.ndim==3 with shape [B, N, C]. Got {tuple(x.shape)}\")\n",
        "        B, N, C = x.shape\n",
        "        if C != self.dim:\n",
        "            raise ValueError(f\"Expected last dim C={self.dim}. Got C={C}\")\n",
        "\n",
        "        # qkv: [B, N, 3C] -> [B, N, 3, heads, head_dim] -> [3, B, heads, N, head_dim]\n",
        "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "        # attention: [B, heads, N, N]\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        # out: [B, heads, N, head_dim] -> [B, N, C]\n",
        "        out = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        out = self.proj(out)\n",
        "        out = self.proj_drop(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class LocalAttention2D(nn.Module):\n",
        "    \"\"\"\n",
        "    Grid attention wrapper.\n",
        "\n",
        "    Input/Output: x BHWC [B,H,W,C] -> [B,H,W,C]\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg: LocalAttention2DConfig):\n",
        "        super().__init__()\n",
        "        if cfg.mode != \"grid\":\n",
        "            raise ValueError(\"This minimal version only supports mode='grid'\")\n",
        "        self.cfg = cfg\n",
        "        self.mhsa = MultiHeadSelfAttention(\n",
        "            AttentionConfig(\n",
        "                dim=cfg.dim,\n",
        "                num_heads=cfg.num_heads,\n",
        "                qkv_bias=cfg.qkv_bias,\n",
        "                attn_drop=cfg.attn_drop,\n",
        "                proj_drop=cfg.proj_drop,))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        if x.ndim != 4:\n",
        "            raise ValueError(f\"Expected x.ndim==4 (BHWC). Got {tuple(x.shape)}\")\n",
        "        B, H, W, C = x.shape\n",
        "        if C != self.cfg.dim:\n",
        "            raise ValueError(f\"Expected C=={self.cfg.dim}. Got C={C}\")\n",
        "\n",
        "        g = self.cfg.grid_size\n",
        "        grids, meta = grid_partition(x, g)         # [B*g*g, Hg, Wg, C]\n",
        "        Bgrp, Hg, Wg, _ = grids.shape\n",
        "        tokens = grids.view(Bgrp, Hg * Wg, C)      # [Bgrp, N, C]\n",
        "        tokens = self.mhsa(tokens)\n",
        "        grids = tokens.view(Bgrp, Hg, Wg, C)\n",
        "        out = grid_unpartition(grids, meta)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8D_s4nb18n2"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    \"\"\"\n",
        "    MLP para BHWC: aplica sobre el último dim C.\n",
        "    x: [..., C] -> [..., C]\n",
        "    \"\"\"\n",
        "    def __init__(self, dim: int, mlp_ratio: float = 4.0, drop: float = 0.0, act: str = \"gelu\"):\n",
        "        super().__init__()\n",
        "        hidden = max(1, int(dim * mlp_ratio))\n",
        "        self.fc1 = nn.Linear(dim, hidden)\n",
        "        self.act = _make_activation(act)\n",
        "        self.drop1 = nn.Dropout(drop)\n",
        "        self.fc2 = nn.Linear(hidden, dim)\n",
        "        self.drop2 = nn.Dropout(drop)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        if x.shape[-1] != self.fc1.in_features:\n",
        "            raise ValueError(f\"MLP expected last dim={self.fc1.in_features}, got {x.shape[-1]}\")\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class OutGridBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Híbrido: Outlooker (local dinámico) -> MBConv -> Grid-MHSA -> MLP\n",
        "    Input/Output: [B, C, H, W]\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        C = cfg.dim\n",
        "\n",
        "        # Outlooker en NCHW\n",
        "        self.outlook = OutlookerBlock2d(\n",
        "            dim=C,\n",
        "            num_heads=cfg.outlook_heads,          # nuevo hyperparam\n",
        "            kernel_size=cfg.outlook_kernel,       # nuevo hyperparam\n",
        "            stride=1,\n",
        "            mlp_ratio=cfg.outlook_mlp_ratio,      # opcional, puedes fijar 0 o 2\n",
        "            attn_drop=cfg.attn_drop,\n",
        "            proj_drop=cfg.proj_drop,\n",
        "            mlp_drop=cfg.ffn_drop,\n",
        "            drop_path=cfg.drop_path,\n",
        "            act=cfg.mlp_act,)\n",
        "\n",
        "        # MBConv NCHW\n",
        "        self.mbconv = MBConv(\n",
        "            in_ch=C, out_ch=C, stride=1,\n",
        "            cfg=MBConvConfig(\n",
        "                expand_ratio=cfg.mbconv_expand_ratio,\n",
        "                se_ratio=cfg.mbconv_se_ratio,\n",
        "                act=cfg.mbconv_act,\n",
        "                use_bn=cfg.use_bn,\n",
        "                drop_path=0.0,\n",
        "            ),)\n",
        "\n",
        "        # Grid attention BHWC\n",
        "        self.norm2 = nn.LayerNorm(C)\n",
        "        self.grid_attn = LocalAttention2D(\n",
        "            LocalAttention2DConfig(\n",
        "                mode=\"grid\",\n",
        "                dim=C,\n",
        "                num_heads=cfg.num_heads,\n",
        "                window_size=cfg.window_size,\n",
        "                grid_size=cfg.grid_size,\n",
        "                qkv_bias=True,\n",
        "                attn_drop=cfg.attn_drop,\n",
        "                proj_drop=cfg.proj_drop,\n",
        "            ))\n",
        "        self.dp2 = DropPath(cfg.drop_path) if cfg.drop_path > 0 else nn.Identity()\n",
        "\n",
        "        # 4) MLP BHWC\n",
        "        self.norm3 = nn.LayerNorm(C)\n",
        "        self.mlp = MLP(dim=C, mlp_ratio=cfg.mlp_ratio, drop=cfg.ffn_drop, act=cfg.mlp_act)\n",
        "        self.dp3 = DropPath(cfg.drop_path) if cfg.drop_path > 0 else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "\n",
        "        # Outlooker + MBConv (NCHW)\n",
        "        x = self.outlook(x)\n",
        "        x = self.mbconv(x)\n",
        "\n",
        "        # to BHWC for grid + mlp\n",
        "        x_bhwc = x.permute(0, 2, 3, 1).contiguous()\n",
        "\n",
        "        y = self.norm2(x_bhwc)\n",
        "        y = self.grid_attn(y)\n",
        "        x_bhwc = x_bhwc + self.dp2(y)\n",
        "\n",
        "        y = self.norm3(x_bhwc)\n",
        "        y = self.mlp(y)\n",
        "        x_bhwc = x_bhwc + self.dp3(y)\n",
        "\n",
        "        # back to NCHW\n",
        "        return x_bhwc.permute(0, 3, 1, 2).contiguous()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPvZ6KnH4SEG"
      },
      "source": [
        "## Test del nuevo modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9Hj9lsp4TqM"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class DummyCfg:\n",
        "    dim: int = 96\n",
        "\n",
        "    # Outlooker\n",
        "    outlook_heads: int = 6\n",
        "    outlook_kernel: int = 3\n",
        "    outlook_mlp_ratio: float = 2.0\n",
        "\n",
        "    # MBConv\n",
        "    mbconv_expand_ratio: float = 4.0\n",
        "    mbconv_se_ratio: float = 0.25\n",
        "    mbconv_act: str = \"silu\"\n",
        "    use_bn: bool = True\n",
        "\n",
        "    # Grid MHSA\n",
        "    num_heads: int = 6\n",
        "    grid_size: int = 4\n",
        "    window_size: int = 8  # no se usa en grid-only, pero tu ctor lo pasa\n",
        "\n",
        "    # Drops\n",
        "    attn_drop: float = 0.0\n",
        "    proj_drop: float = 0.0\n",
        "    ffn_drop: float = 0.0\n",
        "    drop_path: float = 0.0\n",
        "\n",
        "    # MLP (BHWC)\n",
        "    mlp_ratio: float = 4.0\n",
        "    mlp_act: str = \"gelu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaIRHjm74Wd0"
      },
      "outputs": [],
      "source": [
        "def _assert_shape(x: torch.Tensor, shape: tuple, name: str = \"tensor\"):\n",
        "    assert tuple(x.shape) == tuple(shape), f\"{name}: expected shape {shape}, got {tuple(x.shape)}\"\n",
        "\n",
        "def _assert_ndim(x: torch.Tensor, ndim: int, name: str = \"tensor\"):\n",
        "    assert x.ndim == ndim, f\"{name}: expected ndim={ndim}, got ndim={x.ndim}, shape={tuple(x.shape)}\"\n",
        "\n",
        "def _assert_finite(x: torch.Tensor, name: str = \"tensor\"):\n",
        "    assert torch.isfinite(x).all().item(), f\"{name}: found non-finite values (nan/inf)\"\n",
        "\n",
        "def _assert_divisible_hw(H: int, W: int, g: int):\n",
        "    assert (H % g) == 0 and (W % g) == 0, f\"H,W must be divisible by grid_size g={g}. Got H={H}, W={W}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7ajSLwC4YDU"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def test_outlooker_stage(block: OutGridBlock, x: torch.Tensor):\n",
        "    _assert_ndim(x, 4, \"x\")\n",
        "    B, C, H, W = x.shape\n",
        "    _assert_shape(x, (B, block.outlook.norm1.ln.normalized_shape[0], H, W), \"x (pre)\")  # C check\n",
        "\n",
        "    y = block.outlook(x)\n",
        "    _assert_shape(y, (B, C, H, W), \"outlook(x)\")\n",
        "    _assert_finite(y, \"outlook(x)\")\n",
        "    return y\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_mbconv_stage(block: OutGridBlock, x: torch.Tensor):\n",
        "    B, C, H, W = x.shape\n",
        "    y = block.mbconv(x)\n",
        "    _assert_shape(y, (B, C, H, W), \"mbconv(x)\")\n",
        "    _assert_finite(y, \"mbconv(x)\")\n",
        "    return y\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_grid_stage(block: OutGridBlock, x_nchw: torch.Tensor):\n",
        "    B, C, H, W = x_nchw.shape\n",
        "    x_bhwc = x_nchw.permute(0, 2, 3, 1).contiguous()\n",
        "    _assert_shape(x_bhwc, (B, H, W, C), \"x_bhwc\")\n",
        "\n",
        "    # divisibilidad\n",
        "    g = block.grid_attn.cfg.grid_size\n",
        "    _assert_divisible_hw(H, W, g)\n",
        "\n",
        "    y = block.norm2(x_bhwc)\n",
        "    _assert_shape(y, (B, H, W, C), \"norm2(x_bhwc)\")\n",
        "    y = block.grid_attn(y)\n",
        "    _assert_shape(y, (B, H, W, C), \"grid_attn(norm2(x_bhwc))\")\n",
        "    _assert_finite(y, \"grid_attn output\")\n",
        "\n",
        "    out = x_bhwc + block.dp2(y)\n",
        "    _assert_shape(out, (B, H, W, C), \"residual after grid\")\n",
        "    _assert_finite(out, \"after grid residual\")\n",
        "\n",
        "    return out  # BHWC\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_mlp_stage(block: OutGridBlock, x_bhwc: torch.Tensor):\n",
        "    B, H, W, C = x_bhwc.shape\n",
        "\n",
        "    y = block.norm3(x_bhwc)\n",
        "    _assert_shape(y, (B, H, W, C), \"norm3(x_bhwc)\")\n",
        "    y = block.mlp(y)\n",
        "    _assert_shape(y, (B, H, W, C), \"mlp(norm3(x_bhwc))\")\n",
        "    _assert_finite(y, \"mlp output\")\n",
        "\n",
        "    out = x_bhwc + block.dp3(y)\n",
        "    _assert_shape(out, (B, H, W, C), \"residual after mlp\")\n",
        "    _assert_finite(out, \"after mlp residual\")\n",
        "    return out\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_full_forward_matches_stages(block: OutGridBlock, x: torch.Tensor, atol=1e-6, rtol=1e-5):\n",
        "    block.eval()\n",
        "\n",
        "    # manual pipeline\n",
        "    a = test_outlooker_stage(block, x)\n",
        "    b = test_mbconv_stage(block, a)\n",
        "    c = test_grid_stage(block, b)         # BHWC\n",
        "    d = test_mlp_stage(block, c)          # BHWC\n",
        "    manual = d.permute(0, 3, 1, 2).contiguous()\n",
        "\n",
        "    # direct forward\n",
        "    direct = block(x)\n",
        "\n",
        "    _assert_shape(direct, x.shape, \"block(x)\")\n",
        "    _assert_finite(direct, \"block(x)\")\n",
        "    assert torch.allclose(manual, direct, atol=atol, rtol=rtol), \\\n",
        "        \"Manual staged pipeline != block.forward output (check wiring/residuals/norms).\"\n",
        "\n",
        "    return direct\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAkYN2aS4irq",
        "outputId": "0850564f-8d9b-4a50-88b5-8ffb18ca1c36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All tests passed. y: torch.Size([2, 96, 16, 16])\n"
          ]
        }
      ],
      "source": [
        "def run_all_tests():\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    cfg = DummyCfg(dim=96, grid_size=4)\n",
        "    blk = OutGridBlock(cfg).eval()\n",
        "\n",
        "    x = torch.randn(2, 96, 16, 16)\n",
        "    assert x.shape[2] % cfg.grid_size == 0 and x.shape[3] % cfg.grid_size == 0\n",
        "\n",
        "    y = test_full_forward_matches_stages(blk, x)\n",
        "    print(\"All tests passed. y:\", y.shape)\n",
        "\n",
        "run_all_tests()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffdc4VMM6DuG"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ-aect-5ywp"
      },
      "outputs": [],
      "source": [
        "class MaxOutStage(nn.Module):\n",
        "    def __init__(self, block_cfg, depth: int):\n",
        "        super().__init__()\n",
        "        self.blocks = nn.ModuleList([OutGridBlock(block_cfg) for _ in range(depth)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for b in self.blocks:\n",
        "            x = b(x)\n",
        "        return x\n",
        "\n",
        "class GridOnlyBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    MBConv -> Grid-MHSA -> MLP (sin window attn).\n",
        "    Input/Output: [B,C,H,W]\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        C = cfg.dim\n",
        "\n",
        "        self.mbconv = MBConv(\n",
        "            in_ch=C, out_ch=C, stride=1,\n",
        "            cfg=MBConvConfig(\n",
        "                expand_ratio=cfg.mbconv_expand_ratio,\n",
        "                se_ratio=cfg.mbconv_se_ratio,\n",
        "                act=cfg.mbconv_act,\n",
        "                use_bn=cfg.use_bn,\n",
        "                drop_path=0.0,\n",
        "            ))\n",
        "\n",
        "        self.norm2 = nn.LayerNorm(C)\n",
        "        self.grid_attn = LocalAttention2D(\n",
        "            LocalAttention2DConfig(\n",
        "                mode=\"grid\",\n",
        "                dim=C,\n",
        "                num_heads=cfg.num_heads,\n",
        "                window_size=getattr(cfg, \"window_size\", 1),\n",
        "                grid_size=cfg.grid_size,\n",
        "                qkv_bias=True,\n",
        "                attn_drop=cfg.attn_drop,\n",
        "                proj_drop=cfg.proj_drop,\n",
        "            ))\n",
        "        \n",
        "        self.dp2 = DropPath(cfg.drop_path) if cfg.drop_path > 0 else nn.Identity()\n",
        "\n",
        "        self.norm3 = nn.LayerNorm(C)\n",
        "        self.mlp = MLP(dim=C, mlp_ratio=cfg.mlp_ratio, drop=cfg.ffn_drop, act=cfg.mlp_act)\n",
        "        self.dp3 = DropPath(cfg.drop_path) if cfg.drop_path > 0 else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        x = self.mbconv(x)\n",
        "\n",
        "        x_bhwc = x.permute(0, 2, 3, 1).contiguous()\n",
        "\n",
        "        y = self.norm2(x_bhwc)\n",
        "        y = self.grid_attn(y)\n",
        "        x_bhwc = x_bhwc + self.dp2(y)\n",
        "\n",
        "        y = self.norm3(x_bhwc)\n",
        "        y = self.mlp(y)\n",
        "        x_bhwc = x_bhwc + self.dp3(y)\n",
        "\n",
        "        return x_bhwc.permute(0, 3, 1, 2).contiguous()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OYFcY695-Ct"
      },
      "outputs": [],
      "source": [
        "class StageOutThenGrid(nn.Module):\n",
        "    \"\"\"\n",
        "    Outlooker una vez al inicio del stage, luego varios GridOnlyBlock.\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg, depth: int, out_depth: int = 1):\n",
        "        super().__init__()\n",
        "        self.outlookers = nn.ModuleList([\n",
        "            OutlookerBlock2d(\n",
        "                dim=cfg.dim,\n",
        "                num_heads=cfg.outlook_heads,\n",
        "                kernel_size=cfg.outlook_kernel,\n",
        "                stride=1,\n",
        "                mlp_ratio=cfg.outlook_mlp_ratio,\n",
        "                attn_drop=cfg.attn_drop,\n",
        "                proj_drop=cfg.proj_drop,\n",
        "                mlp_drop=cfg.ffn_drop,\n",
        "                drop_path=cfg.drop_path,\n",
        "                act=cfg.mlp_act,)\n",
        "\n",
        "            for _ in range(out_depth)])\n",
        "\n",
        "        self.blocks = nn.ModuleList([GridOnlyBlock(cfg) for _ in range(depth)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for o in self.outlookers:\n",
        "            x = o(x)\n",
        "        for b in self.blocks:\n",
        "            x = b(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJTafDZ-6Lpv"
      },
      "source": [
        "# DownSampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTosN2946LkG"
      },
      "outputs": [],
      "source": [
        "DownsampleType = Literal[\"conv\", \"pool\"]\n",
        "ActType = Literal[\"silu\", \"gelu\", \"relu\"]\n",
        "\n",
        "def _make_activation(act) -> nn.Module:\n",
        "    act = act.lower()\n",
        "    if act == \"silu\":\n",
        "        return nn.SiLU(inplace=True)\n",
        "    if act == \"relu\":\n",
        "        return nn.ReLU(inplace=True)\n",
        "    if act == \"gelu\":\n",
        "        return nn.GELU()\n",
        "    raise ValueError(f\"Unknown activation '{act}'. Use one of: silu|gelu|relu\")\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class DownsampleConfig:\n",
        "    kind: DownsampleType = \"conv\"  # \"conv\" or \"pool\"\n",
        "    act: ActType = \"silu\"\n",
        "    use_bn: bool = True\n",
        "\n",
        "\n",
        "class Downsample(nn.Module):\n",
        "    \"\"\"\n",
        "    Downsample block:\n",
        "      - \"conv\": Conv3x3 stride2 padding1 (in_ch -> out_ch) + BN + Act\n",
        "      - \"pool\": AvgPool2x2 + Conv1x1 (in_ch -> out_ch) + BN + Act\n",
        "\n",
        "    Input:  [B, in_ch, H, W]\n",
        "    Output: [B, out_ch, H/2, W/2]\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_ch: int, out_ch: int, cfg: DownsampleConfig = DownsampleConfig()):\n",
        "        super().__init__()\n",
        "        if in_ch <= 0 or out_ch <= 0:\n",
        "            raise ValueError(\"in_ch and out_ch must be > 0\")\n",
        "\n",
        "        self.in_ch = in_ch\n",
        "        self.out_ch = out_ch\n",
        "        self.kind = cfg.kind\n",
        "\n",
        "        bn = (lambda c: nn.BatchNorm2d(c)) if cfg.use_bn else (lambda c: nn.Identity())\n",
        "        act = _make_activation(cfg.act)\n",
        "\n",
        "        if cfg.kind == \"conv\":\n",
        "            self.op = nn.Sequential(\n",
        "                nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=2, padding=1, bias=not cfg.use_bn),\n",
        "                bn(out_ch),\n",
        "                act,)\n",
        "        elif cfg.kind == \"pool\":\n",
        "            self.op = nn.Sequential(\n",
        "                nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "                nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=1, padding=0, bias=not cfg.use_bn),\n",
        "                bn(out_ch),\n",
        "                act,)\n",
        "        else:\n",
        "            raise ValueError(\"cfg.kind must be 'conv' or 'pool'\")\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.op(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t68ZJmMX6P8A"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPh2vPeh7FEk"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import List\n",
        "\n",
        "@dataclass\n",
        "class StageCfg:\n",
        "    # core dims\n",
        "    dim: int\n",
        "    depth: int\n",
        "\n",
        "    # grid attention\n",
        "    num_heads: int\n",
        "    grid_size: int\n",
        "    window_size: int = 8  # no se usa en grid-only, pero lo mantenemos compatible\n",
        "\n",
        "    # outlooker\n",
        "    outlook_heads: int = 6\n",
        "    outlook_kernel: int = 3\n",
        "    outlook_mlp_ratio: float = 2.0\n",
        "\n",
        "    # MBConv\n",
        "    mbconv_expand_ratio: float = 4.0\n",
        "    mbconv_se_ratio: float = 0.25\n",
        "    mbconv_act: str = \"silu\"\n",
        "    use_bn: bool = True\n",
        "\n",
        "    # drops\n",
        "    attn_drop: float = 0.0\n",
        "    proj_drop: float = 0.0\n",
        "    ffn_drop: float = 0.0\n",
        "    drop_path: float = 0.0\n",
        "\n",
        "    # MLP (BHWC)\n",
        "    mlp_ratio: float = 4.0\n",
        "    mlp_act: str = \"gelu\"\n",
        "\n",
        "\n",
        "def make_dpr(total_blocks: int, dpr_max: float) -> List[float]:\n",
        "    if total_blocks <= 1:\n",
        "        return [dpr_max]\n",
        "    return [dpr_max * i / (total_blocks - 1) for i in range(total_blocks)]\n",
        "\n",
        "\n",
        "class ConvStem(nn.Module):\n",
        "    def __init__(self, in_ch: int, out_ch: int, act: str = \"silu\", use_bn: bool = True):\n",
        "        super().__init__()\n",
        "        bn = (lambda c: nn.BatchNorm2d(c)) if use_bn else (lambda c: nn.Identity())\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=not use_bn),\n",
        "            bn(out_ch),\n",
        "            _make_activation(act),)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.stem(x)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JarHZhH77WcT"
      },
      "outputs": [],
      "source": [
        "class OutlookerFrontGridNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Modelo A:\n",
        "      Stem -> OutlookerFront (L bloques) -> (Stage: GridOnlyBlock x depth + Downsample) -> Head\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes: int,\n",
        "        stages: List[StageCfg],\n",
        "        in_ch: int = 3,\n",
        "        stem_dim: int = 64,\n",
        "        outlooker_front_depth: int = 2,   # <- varios outlookers \"tipo VOLO\"\n",
        "        dpr_max: float = 0.1,\n",
        "        down_cfg: DownsampleConfig = DownsampleConfig(kind=\"conv\", act=\"silu\", use_bn=True),):\n",
        "\n",
        "        super().__init__()\n",
        "        assert len(stages) >= 1\n",
        "        self.stem = ConvStem(in_ch, stem_dim, act=\"silu\", use_bn=True)\n",
        "\n",
        "        # proyección para entrar a dim del stage1 si stem_dim != stage1.dim\n",
        "        self.proj_in = nn.Identity()\n",
        "        if stem_dim != stages[0].dim:\n",
        "            self.proj_in = nn.Conv2d(stem_dim, stages[0].dim, kernel_size=1, bias=True)\n",
        "\n",
        "        # schedule global de drop_path por bloque (front + sum(stage.depth))\n",
        "        total_blocks = outlooker_front_depth + sum(s.depth for s in stages)\n",
        "        dprs = make_dpr(total_blocks, dpr_max)\n",
        "        idx = 0\n",
        "\n",
        "        # Outlooker front (NCHW) con residual + DropPath interno\n",
        "        front_cfg = stages[0]\n",
        "        self.front = nn.ModuleList()\n",
        "        for _ in range(outlooker_front_depth):\n",
        "            c = front_cfg\n",
        "            self.front.append(\n",
        "                OutlookerBlock2d(\n",
        "                    dim=c.dim,\n",
        "                    num_heads=c.outlook_heads,\n",
        "                    kernel_size=c.outlook_kernel,\n",
        "                    stride=1,\n",
        "                    mlp_ratio=c.outlook_mlp_ratio,\n",
        "                    attn_drop=c.attn_drop,\n",
        "                    proj_drop=c.proj_drop,\n",
        "                    mlp_drop=c.ffn_drop,\n",
        "                    drop_path=dprs[idx],\n",
        "                    act=c.mlp_act,))\n",
        "\n",
        "            idx += 1\n",
        "\n",
        "        # stages: GridOnlyBlock stacks + downsample between stages\n",
        "        self.stages = nn.ModuleList()\n",
        "        self.downs = nn.ModuleList()\n",
        "\n",
        "        for si, scfg in enumerate(stages):\n",
        "            blocks = nn.ModuleList()\n",
        "            for _ in range(scfg.depth):\n",
        "                # clonar cfg pero con drop_path asignado por bloque\n",
        "                bcfg = StageCfg(**{**scfg.__dict__, \"drop_path\": dprs[idx]})\n",
        "                blocks.append(GridOnlyBlock(bcfg))\n",
        "                idx += 1\n",
        "            self.stages.append(blocks)\n",
        "\n",
        "            # downsample (except after last stage)\n",
        "            if si < len(stages) - 1:\n",
        "                self.downs.append(Downsample(scfg.dim, stages[si+1].dim, cfg=down_cfg))\n",
        "\n",
        "        # head\n",
        "        self.head_norm = nn.BatchNorm2d(stages[-1].dim)\n",
        "        self.classifier = nn.Linear(stages[-1].dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.proj_in(x)\n",
        "\n",
        "        # front outlooker\n",
        "        for blk in self.front:\n",
        "            x = blk(x)\n",
        "\n",
        "        # grid-only stages\n",
        "        for si, blocks in enumerate(self.stages):\n",
        "            for blk in blocks:\n",
        "                x = blk(x)\n",
        "            if si < len(self.downs):\n",
        "                x = self.downs[si](x)\n",
        "\n",
        "        # global pool + cls\n",
        "        x = self.head_norm(x)\n",
        "        x = x.mean(dim=(2, 3))\n",
        "\n",
        "        return self.classifier(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STtT8-Jq7i16"
      },
      "outputs": [],
      "source": [
        "class MaxOutNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Modelo B:\n",
        "      Stem -> (Stage: MaxOutBlock x depth + Downsample) -> Head\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes: int,\n",
        "        stages: List[StageCfg],\n",
        "        in_ch: int = 3,\n",
        "        stem_dim: int = 64,\n",
        "        dpr_max: float = 0.1,\n",
        "        down_cfg: DownsampleConfig = DownsampleConfig(kind=\"conv\", act=\"silu\", use_bn=True),):\n",
        "\n",
        "        super().__init__()\n",
        "        assert len(stages) >= 1\n",
        "        self.stem = ConvStem(in_ch, stem_dim, act=\"silu\", use_bn=True)\n",
        "\n",
        "        self.proj_in = nn.Identity()\n",
        "\n",
        "        if stem_dim != stages[0].dim:\n",
        "            self.proj_in = nn.Conv2d(stem_dim, stages[0].dim, kernel_size=1, bias=True)\n",
        "\n",
        "        total_blocks = sum(s.depth for s in stages)\n",
        "        dprs = make_dpr(total_blocks, dpr_max)\n",
        "        idx = 0\n",
        "\n",
        "        self.stages = nn.ModuleList()\n",
        "        self.downs = nn.ModuleList()\n",
        "\n",
        "        for si, scfg in enumerate(stages):\n",
        "            blocks = nn.ModuleList()\n",
        "            for _ in range(scfg.depth):\n",
        "                bcfg = StageCfg(**{**scfg.__dict__, \"drop_path\": dprs[idx]})\n",
        "\n",
        "                blocks.append(OutGridBlock(bcfg))\n",
        "                idx += 1\n",
        "            self.stages.append(blocks)\n",
        "\n",
        "            if si < len(stages) - 1:\n",
        "                self.downs.append(Downsample(scfg.dim, stages[si+1].dim, cfg=down_cfg))\n",
        "\n",
        "        self.head_norm = nn.BatchNorm2d(stages[-1].dim)\n",
        "        self.classifier = nn.Linear(stages[-1].dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.proj_in(x)\n",
        "\n",
        "        for si, blocks in enumerate(self.stages):\n",
        "            for blk in blocks:\n",
        "                x = blk(x)\n",
        "            if si < len(self.downs):\n",
        "                x = self.downs[si](x)\n",
        "\n",
        "        x = self.head_norm(x)\n",
        "        x = x.mean(dim=(2, 3))\n",
        "        return self.classifier(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KC8-JW5-7ryG"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrUgyIa-7tH7",
        "outputId": "8aeb5f56-bded-4f98-ae87-00cf14be2575"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 100]) torch.Size([2, 100])\n"
          ]
        }
      ],
      "source": [
        "def cifar64_stages_tiny():\n",
        "    # resoluciones esperadas: 64 -> 32 -> 16 -> 8 -> 4\n",
        "    '''\n",
        "    dim: #canales del feature map en ese stage\n",
        "    depth: cuántos bloques repites en ese stage\n",
        "    num_heads: #heads de la Grid-MHSA en ese stage\n",
        "    grid_size: cómo se parte la imagen para grid attention (debe dividir H y W)\n",
        "    outlook_heads: #heads del Outlooker (si ese modelo lo usa en ese stage)\n",
        "    '''\n",
        "\n",
        "    return [\n",
        "        StageCfg(dim=96,  depth=2, num_heads=3, grid_size=8, outlook_heads=3),\n",
        "        StageCfg(dim=192, depth=2, num_heads=6, grid_size=8, outlook_heads=6),\n",
        "        StageCfg(dim=384, depth=5, num_heads=12, grid_size=4, outlook_heads=12),\n",
        "        StageCfg(dim=768, depth=2, num_heads=12, grid_size=2, outlook_heads=12),]\n",
        "\n",
        "\n",
        "stages = cifar64_stages_tiny()\n",
        "\n",
        "mA = OutlookerFrontGridNet(num_classes=100, stages=stages, stem_dim=96, outlooker_front_depth=2, dpr_max=0.1)\n",
        "mB = MaxOutNet(num_classes=100, stages=stages, stem_dim=96, dpr_max=0.1)\n",
        "\n",
        "x = torch.randn(2, 3, 64, 64)\n",
        "yA = mA(x)\n",
        "yB = mB(x)\n",
        "print(yA.shape, yB.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_91feMK85Xy"
      },
      "source": [
        "---\n",
        "\n",
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9XteOq588JY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import time\n",
        "import random\n",
        "import inspect\n",
        "from dataclasses import dataclass\n",
        "from contextlib import contextmanager, nullcontext\n",
        "from typing import Optional, Dict, Tuple, Any\n",
        "import torch\n",
        "\n",
        "def seed_everything(seed: int = 0, deterministic: bool = False):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    if deterministic:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    else:\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "\n",
        "\n",
        "DTYPE_MAP = {\n",
        "    \"bf16\": torch.bfloat16, \"bfloat16\": torch.bfloat16,\n",
        "    \"fp16\": torch.float16,  \"float16\": torch.float16,\n",
        "    \"fp32\": torch.float32,  \"float32\": torch.float32,}\n",
        "\n",
        "def _cuda_dtype_supported(dtype: torch.dtype) -> bool:\n",
        "    if not torch.cuda.is_available():\n",
        "        return False\n",
        "    return dtype in (torch.float16, torch.bfloat16)\n",
        "\n",
        "def make_grad_scaler(device: str = \"cuda\", enabled: bool = True):\n",
        "    if not enabled:\n",
        "        return None\n",
        "\n",
        "    if hasattr(torch, \"amp\") and hasattr(torch.amp, \"GradScaler\"):\n",
        "        try:\n",
        "            sig = inspect.signature(torch.amp.GradScaler)\n",
        "            if len(sig.parameters) >= 1:\n",
        "                return torch.amp.GradScaler(device if device in (\"cuda\", \"cpu\") else \"cuda\")\n",
        "            return torch.amp.GradScaler()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    if hasattr(torch.cuda, \"amp\") and hasattr(torch.cuda.amp, \"GradScaler\"):\n",
        "        return torch.cuda.amp.GradScaler()\n",
        "    return None\n",
        "\n",
        "\n",
        "@contextmanager\n",
        "def autocast_ctx(\n",
        "    device: str = \"cuda\",\n",
        "    enabled: bool = True,\n",
        "    dtype: str = \"fp16\",\n",
        "    cache_enabled: bool = True,):\n",
        "    \"\"\"\n",
        "    Context manager de autocast:\n",
        "      - cuda: fp16 por defecto (ideal en T4)\n",
        "      - cpu: bfloat16 si está disponible\n",
        "    \"\"\"\n",
        "    if not enabled:\n",
        "        with nullcontext():\n",
        "            yield\n",
        "        return\n",
        "\n",
        "    if device == \"cuda\":\n",
        "        want = DTYPE_MAP.get(dtype.lower(), torch.float16)\n",
        "        use = want if _cuda_dtype_supported(want) else torch.float16\n",
        "        with torch.amp.autocast(device_type=\"cuda\", dtype=use, cache_enabled=cache_enabled):\n",
        "            yield\n",
        "        return\n",
        "\n",
        "    if device == \"cpu\":\n",
        "        try:\n",
        "            with torch.amp.autocast(device_type=\"cpu\", dtype=torch.bfloat16, cache_enabled=cache_enabled):\n",
        "                yield\n",
        "        except Exception:\n",
        "            with nullcontext():\n",
        "                yield\n",
        "        return\n",
        "\n",
        "    with nullcontext():\n",
        "        yield"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYQ732DP9CCM"
      },
      "outputs": [],
      "source": [
        "\n",
        "def save_checkpoint(\n",
        "    path: str,\n",
        "    model,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    scaler,\n",
        "    epoch: int,\n",
        "    best_top1: float,\n",
        "    extra: dict | None = None,):\n",
        "\n",
        "    ckpt = {\n",
        "        \"model\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict() if optimizer is not None else None,\n",
        "        \"scheduler\": scheduler.state_dict() if scheduler is not None else None,\n",
        "        \"scaler\": scaler.state_dict() if scaler is not None else None,\n",
        "        \"epoch\": epoch,\n",
        "        \"best_top1\": best_top1,\n",
        "        \"extra\": extra or {},}\n",
        "    torch.save(ckpt, path)\n",
        "\n",
        "\n",
        "def load_checkpoint(\n",
        "    path: str,\n",
        "    model,\n",
        "    optimizer=None,\n",
        "    scheduler=None,\n",
        "    scaler=None,\n",
        "    map_location=\"cpu\",\n",
        "    strict: bool = True,):\n",
        "    ckpt = torch.load(path, map_location=map_location)\n",
        "    model.load_state_dict(ckpt[\"model\"], strict=strict)\n",
        "\n",
        "    if optimizer is not None and ckpt.get(\"optimizer\") is not None:\n",
        "        optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
        "    if scheduler is not None and ckpt.get(\"scheduler\") is not None:\n",
        "        scheduler.load_state_dict(ckpt[\"scheduler\"])\n",
        "    if scaler is not None and ckpt.get(\"scaler\") is not None:\n",
        "        scaler.load_state_dict(ckpt[\"scaler\"])\n",
        "    return ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toJSWec19P2s"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def accuracy_topk(logits: torch.Tensor, targets: torch.Tensor, ks=(1, 3, 5)) -> Dict[int, float]:\n",
        "    \"\"\"\n",
        "    targets can be:\n",
        "      - int64 class indices [B]\n",
        "      - soft targets [B, num_classes] (we'll argmax for accuracy reporting)\n",
        "    \"\"\"\n",
        "    if targets.ndim == 2:\n",
        "        targets = targets.argmax(dim=1)\n",
        "\n",
        "    max_k = max(ks)\n",
        "    B = targets.size(0)\n",
        "    _, pred = torch.topk(logits, k=max_k, dim=1)\n",
        "    correct = pred.eq(targets.view(-1, 1).expand_as(pred))\n",
        "    out = {}\n",
        "    for k in ks:\n",
        "        out[k] = 100.0 * correct[:, :k].any(dim=1).float().sum().item() / B\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvJc7YKo9UdD"
      },
      "outputs": [],
      "source": [
        "def _one_hot(targets: torch.Tensor, num_classes: int) -> torch.Tensor:\n",
        "    return F.one_hot(targets, num_classes=num_classes).float()\n",
        "\n",
        "\n",
        "def soft_target_cross_entropy(logits: torch.Tensor, targets_soft: torch.Tensor) -> torch.Tensor:\n",
        "    logp = F.log_softmax(logits, dim=1)\n",
        "    return -(targets_soft * logp).sum(dim=1).mean()\n",
        "\n",
        "\n",
        "def apply_mixup_cutmix(\n",
        "    images: torch.Tensor,\n",
        "    targets: torch.Tensor,\n",
        "    num_classes: int,\n",
        "    mixup_alpha: float = 0.0,\n",
        "    cutmix_alpha: float = 0.0,\n",
        "    prob: float = 1.0,):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      images_aug: [B,3,H,W]\n",
        "      targets_soft: [B,K]\n",
        "    \"\"\"\n",
        "    if prob <= 0.0 or (mixup_alpha <= 0.0 and cutmix_alpha <= 0.0):\n",
        "        return images, _one_hot(targets, num_classes)\n",
        "\n",
        "    if random.random() > prob:\n",
        "        return images, _one_hot(targets, num_classes)\n",
        "\n",
        "    use_cutmix = (cutmix_alpha > 0.0) and (mixup_alpha <= 0.0 or random.random() < 0.5)\n",
        "    B, _, H, W = images.shape\n",
        "    perm = torch.randperm(B, device=images.device)\n",
        "\n",
        "    y1 = _one_hot(targets, num_classes)\n",
        "    y2 = _one_hot(targets[perm], num_classes)\n",
        "\n",
        "    if use_cutmix:\n",
        "        lam = torch.distributions.Beta(cutmix_alpha, cutmix_alpha).sample().item()\n",
        "        cut_w = int(W * math.sqrt(1.0 - lam))\n",
        "        cut_h = int(H * math.sqrt(1.0 - lam))\n",
        "        cx = random.randint(0, W - 1)\n",
        "        cy = random.randint(0, H - 1)\n",
        "\n",
        "        x1 = max(cx - cut_w // 2, 0)\n",
        "        x2 = min(cx + cut_w // 2, W)\n",
        "        y1b = max(cy - cut_h // 2, 0)\n",
        "        y2b = min(cy + cut_h // 2, H)\n",
        "\n",
        "        images_aug = images.clone()\n",
        "        images_aug[:, :, y1b:y2b, x1:x2] = images[perm, :, y1b:y2b, x1:x2]\n",
        "\n",
        "        # adjust lambda based on actual area swapped\n",
        "        area = (x2 - x1) * (y2b - y1b)\n",
        "        lam = 1.0 - area / float(W * H)\n",
        "    else:\n",
        "        lam = torch.distributions.Beta(mixup_alpha, mixup_alpha).sample().item()\n",
        "        images_aug = images * lam + images[perm] * (1.0 - lam)\n",
        "\n",
        "    targets_soft = y1 * lam + y2 * (1.0 - lam)\n",
        "    return images_aug, targets_soft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qO-QWNsY9XU7"
      },
      "outputs": [],
      "source": [
        "def build_param_groups_no_wd(model: nn.Module, weight_decay: float):\n",
        "    decay, no_decay = [], []\n",
        "    for name, p in model.named_parameters():\n",
        "        if not p.requires_grad:\n",
        "            continue\n",
        "\n",
        "        name_l = name.lower()\n",
        "        # no decay for biases + norms + positional/class tokens\n",
        "        if (\n",
        "            name.endswith(\".bias\")\n",
        "            or (\"norm\" in name_l)\n",
        "            or (\"bn\" in name_l)\n",
        "            or (\"ln\" in name_l)\n",
        "            or (\"pos\" in name_l)         # pos_embed / pos\n",
        "            or (\"cls_token\" in name_l)\n",
        "        ):\n",
        "            no_decay.append(p)\n",
        "        else:\n",
        "            decay.append(p)\n",
        "\n",
        "    return [\n",
        "        {\"params\": decay, \"weight_decay\": weight_decay},\n",
        "        {\"params\": no_decay, \"weight_decay\": 0.0}]\n",
        "\n",
        "\n",
        "class WarmupCosineLR:\n",
        "    \"\"\"Warmup linear for warmup_steps, then cosine to min_lr. Step-based.\"\"\"\n",
        "    def __init__(self, optimizer, total_steps: int, warmup_steps: int, min_lr: float = 0.0):\n",
        "        self.optimizer = optimizer\n",
        "        self.total_steps = int(total_steps)\n",
        "        self.warmup_steps = int(warmup_steps)\n",
        "        self.min_lr = float(min_lr)\n",
        "        self.base_lrs = [g[\"lr\"] for g in optimizer.param_groups]\n",
        "        self.step_num = 0\n",
        "\n",
        "    def step(self):\n",
        "        self.step_num += 1\n",
        "        t = self.step_num\n",
        "\n",
        "        for i, group in enumerate(self.optimizer.param_groups):\n",
        "            base = self.base_lrs[i]\n",
        "            if t <= self.warmup_steps and self.warmup_steps > 0:\n",
        "                lr = base * (t / self.warmup_steps)\n",
        "            else:\n",
        "                tt = min(t, self.total_steps)\n",
        "                denom = max(1, self.total_steps - self.warmup_steps)\n",
        "                progress = (tt - self.warmup_steps) / denom\n",
        "                cosine = 0.5 * (1.0 + math.cos(math.pi * progress))\n",
        "                lr = self.min_lr + (base - self.min_lr) * cosine\n",
        "            group[\"lr\"] = lr\n",
        "\n",
        "    def state_dict(self):\n",
        "        return {\"step_num\": self.step_num}\n",
        "\n",
        "    def load_state_dict(self, d):\n",
        "        self.step_num = int(d.get(\"step_num\", 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vW315s-J9axB"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(\n",
        "    model: nn.Module,\n",
        "    dataloader,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    scheduler,\n",
        "    device: str = \"cuda\", \n",
        "    scaler=None,\n",
        "    autocast_dtype: str = \"bf16\",\n",
        "    use_amp: bool = True,\n",
        "    grad_clip_norm: Optional[float] = 1.0,\n",
        "    label_smoothing: float = 0.1,\n",
        "    mixup_alpha: float = 0.0,\n",
        "    cutmix_alpha: float = 0.0,\n",
        "    mix_prob: float = 1.0,\n",
        "    num_classes: int = 100,\n",
        "    channels_last: bool = False,\n",
        "    print_every: int = 100,) -> Tuple[float, Dict[str, float]]:\n",
        "    \"\"\"\n",
        "    Single-process train loop (no DDP, no EMA).\n",
        "\n",
        "    Expects helpers already defined in your file:\n",
        "      - autocast_ctx\n",
        "      - apply_mixup_cutmix\n",
        "      - soft_target_cross_entropy\n",
        "      - accuracy_topk\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "\n",
        "    use_scaler = (scaler is not None) and use_amp and autocast_dtype.lower() in (\"fp16\", \"float16\")\n",
        "\n",
        "    running_loss = 0.0\n",
        "    total = 0\n",
        "    c1 = c3 = c5 = 0.0\n",
        "\n",
        "    t0 = time.time()\n",
        "    for step, (images, targets) in enumerate(dataloader, start=1):\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "        if channels_last:\n",
        "            images = images.contiguous(memory_format=torch.channels_last)\n",
        "\n",
        "        B = targets.size(0)\n",
        "\n",
        "        # mixup/cutmix => soft targets\n",
        "        images_aug, targets_soft = apply_mixup_cutmix(\n",
        "            images, targets,\n",
        "            num_classes=num_classes,\n",
        "            mixup_alpha=mixup_alpha,\n",
        "            cutmix_alpha=cutmix_alpha,\n",
        "            prob=mix_prob,)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        with autocast_ctx(device=device, enabled=use_amp, dtype=autocast_dtype, cache_enabled=True):\n",
        "            logits = model(images_aug)  # [B, K]\n",
        "\n",
        "        # loss in fp32\n",
        "        if (mixup_alpha > 0.0) or (cutmix_alpha > 0.0):\n",
        "            # With mixup/cutmix, label smoothing is usually redundant.\n",
        "            loss = soft_target_cross_entropy(logits.float(), targets_soft)\n",
        "        else:\n",
        "            loss = F.cross_entropy(logits.float(), targets, label_smoothing=label_smoothing)\n",
        "\n",
        "        if use_scaler:\n",
        "            scaler.scale(loss).backward()\n",
        "            if grad_clip_norm is not None:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_norm)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            if grad_clip_norm is not None:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_norm)\n",
        "            optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        # metrics\n",
        "        running_loss += loss.item() * B\n",
        "        total += B\n",
        "        accs = accuracy_topk(\n",
        "            logits.detach(),\n",
        "            targets_soft if targets_soft.ndim == 2 else targets,\n",
        "            ks=(1, 3, 5),)\n",
        "\n",
        "        c1 += accs[1] * B / 100.0\n",
        "        c3 += accs[3] * B / 100.0\n",
        "        c5 += accs[5] * B / 100.0\n",
        "\n",
        "        if print_every and (step % print_every == 0):\n",
        "            dt = time.time() - t0\n",
        "            imgs_sec = total / max(dt, 1e-9)\n",
        "            print(\n",
        "                f\"[train step {step}/{len(dataloader)}] \"\n",
        "                f\"loss {running_loss/total:.4f} | \"\n",
        "                f\"top1 {100*c1/total:.2f}% | top3 {100*c3/total:.2f}% | top5 {100*c5/total:.2f}% | \"\n",
        "                f\"{imgs_sec:.1f} img/s | lr {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "    avg_loss = running_loss / max(1, total)\n",
        "    metrics = {\n",
        "        \"top1\": 100.0 * c1 / max(1, total),\n",
        "        \"top3\": 100.0 * c3 / max(1, total),\n",
        "        \"top5\": 100.0 * c5 / max(1, total),}\n",
        "\n",
        "    return avg_loss, metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7MaseFT_Rqd"
      },
      "outputs": [],
      "source": [
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_one_epoch(\n",
        "    model: nn.Module,\n",
        "    dataloader,\n",
        "    device: str = \"cuda\",\n",
        "    autocast_dtype: str = \"bf16\",\n",
        "    use_amp: bool = True,\n",
        "    label_smoothing: float = 0.0,\n",
        "    channels_last: bool = False) -> Tuple[float, Dict[str, float]]:\n",
        "    \"\"\"\n",
        "    Single-process evaluation loop (no DDP, no EMA).\n",
        "\n",
        "    Expects helpers already defined in your file:\n",
        "      - autocast_ctx\n",
        "      - accuracy_topk\n",
        "    \"\"\"\n",
        "    model.eval().to(device)\n",
        "\n",
        "    running_loss = 0.0\n",
        "    total = 0\n",
        "    c1 = c3 = c5 = 0.0\n",
        "\n",
        "    for images, targets in dataloader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "        if channels_last:\n",
        "            images = images.contiguous(memory_format=torch.channels_last)\n",
        "\n",
        "        B = targets.size(0)\n",
        "\n",
        "        with autocast_ctx(device=device, enabled=use_amp, dtype=autocast_dtype, cache_enabled=True):\n",
        "            logits = model(images)\n",
        "\n",
        "        loss = F.cross_entropy(logits.float(), targets, label_smoothing=label_smoothing)\n",
        "\n",
        "        running_loss += loss.item() * B\n",
        "        total += B\n",
        "\n",
        "        accs = accuracy_topk(logits, targets, ks=(1, 3, 5))\n",
        "        c1 += accs[1] * B / 100.0\n",
        "        c3 += accs[3] * B / 100.0\n",
        "        c5 += accs[5] * B / 100.0\n",
        "\n",
        "    avg_loss = running_loss / max(1, total)\n",
        "    metrics = {\n",
        "        \"top1\": 100.0 * c1 / max(1, total),\n",
        "        \"top3\": 100.0 * c3 / max(1, total),\n",
        "        \"top5\": 100.0 * c5 / max(1, total),}\n",
        "\n",
        "    return avg_loss, metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWPxUzjx_Ehy"
      },
      "outputs": [],
      "source": [
        "def train_model(\n",
        "    model: nn.Module,\n",
        "    train_loader,\n",
        "    epochs: int,\n",
        "    val_loader=None,\n",
        "    device: str = \"cuda\",\n",
        "    lr: float = 5e-4,\n",
        "    weight_decay: float = 0.05,\n",
        "    autocast_dtype: str = \"fp16\",\n",
        "    use_amp: bool = True,\n",
        "    grad_clip_norm: float | None = 1.0,\n",
        "    warmup_ratio: float = 0.05,\n",
        "    min_lr: float = 0.0,\n",
        "    label_smoothing: float = 0.1,\n",
        "    print_every: int = 100,\n",
        "    save_path: str = \"best_model.pt\",\n",
        "    last_path: str = \"last_model.pt\",\n",
        "    resume_path: str | None = None,\n",
        "    mixup_alpha: float = 0.0,\n",
        "    cutmix_alpha: float = 0.0,\n",
        "    mix_prob: float = 1.0,\n",
        "    num_classes: int = 100,\n",
        "    channels_last: bool = False,\n",
        "    early_stop: bool = True,\n",
        "    early_stop_metric: str = \"top1\",          # \"top1\" or \"loss\"\n",
        "    early_stop_patience: int = 10,\n",
        "    early_stop_min_delta: float = 0.0,\n",
        "    early_stop_require_monotonic: bool = False,) -> Tuple[Dict[str, list], nn.Module]:\n",
        "\n",
        "    \"\"\"\n",
        "    Single-process trainer (no DDP, no EMA).\n",
        "\n",
        "    Expects helpers already defined in your file:\n",
        "      - build_param_groups_no_wd\n",
        "      - WarmupCosineLR\n",
        "      - make_grad_scaler\n",
        "      - save_checkpoint / load_checkpoint\n",
        "      - train_one_epoch (the one above)\n",
        "      - evaluate_one_epoch\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "\n",
        "    # Optimizer\n",
        "    param_groups = build_param_groups_no_wd(model, weight_decay=weight_decay)\n",
        "    optimizer = torch.optim.AdamW(param_groups, lr=lr, betas=(0.9, 0.999), eps=1e-8)\n",
        "\n",
        "    # Scheduler warmup + cosine (step-based)\n",
        "    total_steps = epochs * len(train_loader)\n",
        "    warmup_steps = int(total_steps * warmup_ratio)\n",
        "    scheduler = WarmupCosineLR(\n",
        "        optimizer,\n",
        "        total_steps=total_steps,\n",
        "        warmup_steps=warmup_steps,\n",
        "        min_lr=min_lr)\n",
        "\n",
        "    # AMP scaler\n",
        "    scaler = None\n",
        "    if use_amp and autocast_dtype.lower() in (\"fp16\", \"float16\"):\n",
        "        scaler = make_grad_scaler(device=device, enabled=True)\n",
        "\n",
        "    # Resume\n",
        "    start_epoch = 0\n",
        "    best_val_top1 = -float(\"inf\")\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_epoch = 0\n",
        "\n",
        "    if resume_path is not None:\n",
        "        ckpt = load_checkpoint(\n",
        "            resume_path, model,\n",
        "            optimizer=optimizer, scheduler=scheduler, scaler=scaler,\n",
        "            map_location=device,\n",
        "            strict=True,)\n",
        "\n",
        "        start_epoch = int(ckpt.get(\"epoch\", 0))\n",
        "        best_val_top1 = float(ckpt.get(\"best_top1\", best_val_top1))\n",
        "        extra = ckpt.get(\"extra\", {}) or {}\n",
        "        best_val_loss = float(extra.get(\"best_val_loss\", best_val_loss))\n",
        "        best_epoch = int(extra.get(\"best_epoch\", best_epoch))\n",
        "        print(f\"Resumed from {resume_path} at epoch {start_epoch} | best_top1 {best_val_top1:.2f}% | best_loss {best_val_loss:.4f}\")\n",
        "\n",
        "    history = {\n",
        "        \"train_loss\": [], \"train_top1\": [], \"train_top3\": [], \"train_top5\": [],\n",
        "        \"val_loss\": [], \"val_top1\": [], \"val_top3\": [], \"val_top5\": [],\n",
        "        \"lr\": [],}\n",
        "\n",
        "    metric = early_stop_metric.lower()\n",
        "    assert metric in (\"top1\", \"loss\")\n",
        "    mode = \"max\" if metric == \"top1\" else \"min\"\n",
        "    best_metric = best_val_top1 if metric == \"top1\" else best_val_loss\n",
        "    patience = int(early_stop_patience)\n",
        "    bad_epochs = 0\n",
        "    last_vals: list[float] = []\n",
        "\n",
        "    def _is_improvement(curr: float, best: float) -> bool:\n",
        "        d = float(early_stop_min_delta)\n",
        "        return (curr > (best + d)) if mode == \"max\" else (curr < (best - d))\n",
        "\n",
        "    def _degradation_monotonic(vals: list[float]) -> bool:\n",
        "        if not early_stop_require_monotonic or len(vals) < 2:\n",
        "            return True\n",
        "        if mode == \"max\":\n",
        "            return all(vals[i] >= vals[i + 1] for i in range(len(vals) - 1))\n",
        "        else:\n",
        "            return all(vals[i] <= vals[i + 1] for i in range(len(vals) - 1))\n",
        "\n",
        "    for epoch in range(start_epoch + 1, epochs + 1):\n",
        "        print(f\"\\n=== Epoch {epoch}/{epochs} ===\")\n",
        "        t_epoch = time.time()\n",
        "\n",
        "        # If a sampler supports set_epoch, reshuffle deterministically per epoch (works even without DDP)\n",
        "        if hasattr(train_loader, \"sampler\") and hasattr(train_loader.sampler, \"set_epoch\"):\n",
        "            train_loader.sampler.set_epoch(epoch)\n",
        "        if val_loader is not None and hasattr(val_loader, \"sampler\") and hasattr(val_loader.sampler, \"set_epoch\"):\n",
        "            val_loader.sampler.set_epoch(epoch)\n",
        "\n",
        "        # --- Train ---\n",
        "        tr_loss, tr_m = train_one_epoch(\n",
        "            model=model,\n",
        "            dataloader=train_loader,\n",
        "            optimizer=optimizer,\n",
        "            scheduler=scheduler,\n",
        "            device=device,\n",
        "            scaler=scaler,\n",
        "            autocast_dtype=autocast_dtype,\n",
        "            use_amp=use_amp,\n",
        "            grad_clip_norm=grad_clip_norm,\n",
        "            label_smoothing=label_smoothing,\n",
        "            mixup_alpha=mixup_alpha,\n",
        "            cutmix_alpha=cutmix_alpha,\n",
        "            mix_prob=mix_prob,\n",
        "            num_classes=num_classes,\n",
        "            channels_last=channels_last,\n",
        "            print_every=print_every,)\n",
        "\n",
        "        history[\"train_loss\"].append(tr_loss)\n",
        "        history[\"train_top1\"].append(tr_m[\"top1\"])\n",
        "        history[\"train_top3\"].append(tr_m[\"top3\"])\n",
        "        history[\"train_top5\"].append(tr_m[\"top5\"])\n",
        "        history[\"lr\"].append(float(optimizer.param_groups[0][\"lr\"]))\n",
        "\n",
        "        print(\n",
        "            f\"[Train] loss {tr_loss:.4f} | top1 {tr_m['top1']:.2f}% | top3 {tr_m['top3']:.2f}% | \"\n",
        "            f\"top5 {tr_m['top5']:.2f}% | lr {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "        # Save \"last\" checkpoint every epoch\n",
        "        save_checkpoint(\n",
        "            last_path, model, optimizer, scheduler, scaler,\n",
        "            epoch=epoch, best_top1=best_val_top1,\n",
        "            extra={\n",
        "                \"autocast_dtype\": autocast_dtype,\n",
        "                \"use_amp\": use_amp,\n",
        "                \"best_val_loss\": best_val_loss,\n",
        "                \"best_epoch\": best_epoch,\n",
        "                \"early_stop_metric\": metric,\n",
        "                \"early_stop_patience\": patience,\n",
        "                \"early_stop_min_delta\": float(early_stop_min_delta),},)\n",
        "\n",
        "        stop_now = False\n",
        "\n",
        "        # --- Val ---\n",
        "        if val_loader is not None:\n",
        "            va_loss, va_m = evaluate_one_epoch(\n",
        "                model=model,\n",
        "                dataloader=val_loader,\n",
        "                device=device,\n",
        "                autocast_dtype=autocast_dtype,\n",
        "                use_amp=use_amp,\n",
        "                label_smoothing=0.0,\n",
        "                channels_last=channels_last,)\n",
        "\n",
        "            history[\"val_loss\"].append(va_loss)\n",
        "            history[\"val_top1\"].append(va_m[\"top1\"])\n",
        "            history[\"val_top3\"].append(va_m[\"top3\"])\n",
        "            history[\"val_top5\"].append(va_m[\"top5\"])\n",
        "\n",
        "            print(\n",
        "                f\"[Val]   loss {va_loss:.4f} | top1 {va_m['top1']:.2f}% | top3 {va_m['top3']:.2f}% | top5 {va_m['top5']:.2f}%\")\n",
        "\n",
        "            # Best checkpoint by val_top1\n",
        "            if va_m[\"top1\"] > best_val_top1:\n",
        "                best_val_top1 = float(va_m[\"top1\"])\n",
        "                if va_loss < best_val_loss:\n",
        "                    best_val_loss = float(va_loss)\n",
        "                    best_epoch = int(epoch)\n",
        "\n",
        "                save_checkpoint(\n",
        "                    save_path, model, optimizer, scheduler, scaler,\n",
        "                    epoch=epoch, best_top1=best_val_top1,\n",
        "                    extra={\n",
        "                        \"autocast_dtype\": autocast_dtype,\n",
        "                        \"use_amp\": use_amp,\n",
        "                        \"best_val_loss\": best_val_loss,\n",
        "                        \"best_epoch\": best_epoch,},)\n",
        "\n",
        "                print(f\"Best saved to {save_path} (val top1 {best_val_top1:.2f}%)\")\n",
        "\n",
        "            # Early stop on chosen metric\n",
        "            if early_stop:\n",
        "                curr_metric = float(va_m[\"top1\"]) if metric == \"top1\" else float(va_loss)\n",
        "\n",
        "                last_vals.append(curr_metric)\n",
        "                if len(last_vals) > patience:\n",
        "                    last_vals = last_vals[-patience:]\n",
        "\n",
        "                if _is_improvement(curr_metric, best_metric):\n",
        "                    best_metric = curr_metric\n",
        "                    bad_epochs = 0\n",
        "                else:\n",
        "                    bad_epochs += 1\n",
        "\n",
        "                if bad_epochs >= patience and _degradation_monotonic(last_vals):\n",
        "                    print(f\"Early-stop: no improvement on val_{metric} for {patience} epochs.\")\n",
        "                    stop_now = True\n",
        "\n",
        "        if stop_now:\n",
        "            break\n",
        "\n",
        "        dt = time.time() - t_epoch\n",
        "        print(f\"Epoch time: {dt/60:.2f} min\")\n",
        "\n",
        "    return history, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIv5mdnqAX74",
        "outputId": "8f6a3f63-463b-488f-b090-492d75d0d27e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CUDA] allocated=0.0 MB | reserved(cache)=0.0 MB\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "\n",
        "def free_all_cuda(*names, verbose=True, globals_dict=None, locals_dict=None):\n",
        "    \"\"\"\n",
        "    Borra variables por nombre (strings) de globals/locals para evitar referencias colgadas en notebooks.\n",
        "    \"\"\"\n",
        "    if globals_dict is None: globals_dict = globals()\n",
        "    if locals_dict is None:  locals_dict  = locals()\n",
        "\n",
        "    for n in names:\n",
        "        if n in locals_dict:\n",
        "            del locals_dict[n]\n",
        "        if n in globals_dict:\n",
        "            del globals_dict[n]\n",
        "\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.synchronize()\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.ipc_collect()\n",
        "\n",
        "    if verbose and torch.cuda.is_available():\n",
        "        alloc = torch.cuda.memory_allocated() / 1024**2\n",
        "        res   = torch.cuda.memory_reserved() / 1024**2\n",
        "        print(f\"[CUDA] allocated={alloc:.1f} MB | reserved(cache)={res:.1f} MB\")\n",
        "\n",
        "free_all_cuda(\"model\", \"optimizer\", \"scaler\", \"scheduler\", \"batch\", \"loss\", \"outputs\", \"logits\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWflG0_8_doZ",
        "outputId": "b7a07792-aa32-4217-8654-76ee2299a580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 1/50 ===\n",
            "[train step 100/352] loss 4.4824 | top1 3.52% | top3 8.54% | top5 12.80% | 116.3 img/s | lr 5.68e-05\n",
            "[train step 200/352] loss 4.3496 | top1 5.12% | top3 12.41% | top5 18.10% | 120.4 img/s | lr 1.14e-04\n",
            "[train step 300/352] loss 4.2459 | top1 6.55% | top3 15.18% | top5 21.68% | 121.8 img/s | lr 1.70e-04\n",
            "[Train] loss 4.2034 | top1 7.19% | top3 16.40% | top5 23.26% | lr 2.00e-04\n",
            "[Val]   loss 3.7152 | top1 13.10% | top3 27.08% | top5 36.98%\n",
            "Best saved to best_maxout_medium.pt (val top1 13.10%)\n",
            "Epoch time: 6.52 min\n",
            "\n",
            "=== Epoch 2/50 ===\n",
            "[train step 100/352] loss 3.7666 | top1 13.28% | top3 28.25% | top5 37.82% | 124.1 img/s | lr 2.57e-04\n",
            "[train step 200/352] loss 3.6872 | top1 14.67% | top3 30.08% | top5 39.87% | 124.3 img/s | lr 3.14e-04\n",
            "[train step 300/352] loss 3.6362 | top1 15.90% | top3 32.04% | top5 41.82% | 124.5 img/s | lr 3.70e-04\n",
            "[Train] loss 3.5984 | top1 16.66% | top3 33.18% | top5 43.03% | lr 4.00e-04\n",
            "[Val]   loss 3.1387 | top1 22.26% | top3 41.72% | top5 51.90%\n",
            "Best saved to best_maxout_medium.pt (val top1 22.26%)\n",
            "Epoch time: 6.28 min\n",
            "\n",
            "=== Epoch 3/50 ===\n",
            "[train step 100/352] loss 3.3235 | top1 22.07% | top3 40.70% | top5 51.19% | 124.2 img/s | lr 4.57e-04\n",
            "[train step 200/352] loss 3.3131 | top1 22.66% | top3 41.90% | top5 52.16% | 124.2 img/s | lr 5.00e-04\n",
            "[train step 300/352] loss 3.2181 | top1 24.46% | top3 44.23% | top5 54.47% | 124.2 img/s | lr 5.00e-04\n",
            "[Train] loss 3.1865 | top1 25.34% | top3 45.32% | top5 55.53% | lr 5.00e-04\n",
            "[Val]   loss 2.5816 | top1 33.74% | top3 56.80% | top5 67.38%\n",
            "Best saved to best_maxout_medium.pt (val top1 33.74%)\n",
            "Epoch time: 6.29 min\n",
            "\n",
            "=== Epoch 4/50 ===\n",
            "[train step 100/352] loss 2.8811 | top1 31.88% | top3 52.71% | top5 62.73% | 124.0 img/s | lr 5.00e-04\n",
            "[train step 200/352] loss 2.8754 | top1 32.56% | top3 53.46% | top5 63.39% | 124.2 img/s | lr 4.99e-04\n",
            "[train step 300/352] loss 2.8531 | top1 33.13% | top3 54.12% | top5 63.94% | 124.2 img/s | lr 4.99e-04\n",
            "[Train] loss 2.8413 | top1 33.42% | top3 54.47% | top5 64.25% | lr 4.99e-04\n",
            "[Val]   loss 2.2664 | top1 41.64% | top3 63.34% | top5 73.00%\n",
            "Best saved to best_maxout_medium.pt (val top1 41.64%)\n",
            "Epoch time: 6.29 min\n",
            "\n",
            "=== Epoch 5/50 ===\n",
            "[train step 100/352] loss 2.7554 | top1 36.68% | top3 57.63% | top5 67.02% | 124.2 img/s | lr 4.98e-04\n",
            "[train step 200/352] loss 2.6385 | top1 38.87% | top3 60.48% | top5 69.99% | 124.3 img/s | lr 4.98e-04\n",
            "[train step 300/352] loss 2.6300 | top1 39.17% | top3 60.99% | top5 70.30% | 124.3 img/s | lr 4.97e-04\n",
            "[Train] loss 2.6306 | top1 39.17% | top3 60.76% | top5 69.97% | lr 4.97e-04\n",
            "[Val]   loss 2.0569 | top1 46.62% | top3 68.92% | top5 77.44%\n",
            "Best saved to best_maxout_medium.pt (val top1 46.62%)\n",
            "Epoch time: 6.29 min\n",
            "\n",
            "=== Epoch 6/50 ===\n",
            "[train step 100/352] loss 2.5570 | top1 41.14% | top3 62.41% | top5 71.21% | 124.3 img/s | lr 4.96e-04\n",
            "[train step 200/352] loss 2.4851 | top1 42.60% | top3 63.87% | top5 72.66% | 124.4 img/s | lr 4.95e-04\n",
            "[train step 300/352] loss 2.4134 | top1 44.18% | top3 65.59% | top5 74.33% | 124.4 img/s | lr 4.94e-04\n",
            "[Train] loss 2.3705 | top1 45.01% | top3 66.49% | top5 75.15% | lr 4.93e-04\n",
            "[Val]   loss 1.8467 | top1 49.38% | top3 72.60% | top5 81.04%\n",
            "Best saved to best_maxout_medium.pt (val top1 49.38%)\n",
            "Epoch time: 6.28 min\n",
            "\n",
            "=== Epoch 7/50 ===\n",
            "[train step 100/352] loss 2.2133 | top1 48.03% | top3 68.20% | top5 76.55% | 124.4 img/s | lr 4.92e-04\n",
            "[train step 200/352] loss 2.2511 | top1 47.77% | top3 68.21% | top5 76.45% | 124.4 img/s | lr 4.91e-04\n",
            "[train step 300/352] loss 2.2122 | top1 48.56% | top3 69.24% | top5 77.38% | 124.4 img/s | lr 4.90e-04\n",
            "[Train] loss 2.2026 | top1 48.93% | top3 69.58% | top5 77.64% | lr 4.89e-04\n",
            "[Val]   loss 1.6619 | top1 54.58% | top3 75.72% | top5 83.36%\n",
            "Best saved to best_maxout_medium.pt (val top1 54.58%)\n",
            "Epoch time: 6.29 min\n",
            "\n",
            "=== Epoch 8/50 ===\n",
            "[train step 100/352] loss 2.1667 | top1 50.24% | top3 70.57% | top5 78.34% | 124.2 img/s | lr 4.88e-04\n",
            "[train step 200/352] loss 2.2344 | top1 49.14% | top3 69.39% | top5 77.31% | 124.3 img/s | lr 4.86e-04\n",
            "[train step 300/352] loss 2.2027 | top1 49.58% | top3 69.84% | top5 77.74% | 124.3 img/s | lr 4.85e-04\n",
            "[Train] loss 2.1837 | top1 49.96% | top3 70.37% | top5 78.17% | lr 4.84e-04\n",
            "[Val]   loss 1.6012 | top1 55.48% | top3 77.80% | top5 85.08%\n",
            "Best saved to best_maxout_medium.pt (val top1 55.48%)\n",
            "Epoch time: 6.29 min\n",
            "\n",
            "=== Epoch 9/50 ===\n",
            "[train step 100/352] loss 2.1034 | top1 52.78% | top3 73.38% | top5 80.63% | 124.0 img/s | lr 4.82e-04\n",
            "[train step 200/352] loss 2.1069 | top1 52.96% | top3 73.37% | top5 80.89% | 124.3 img/s | lr 4.80e-04\n",
            "[train step 300/352] loss 2.1078 | top1 52.71% | top3 73.01% | top5 80.49% | 124.4 img/s | lr 4.78e-04\n",
            "[Train] loss 2.0979 | top1 52.86% | top3 73.10% | top5 80.61% | lr 4.77e-04\n",
            "[Val]   loss 1.5034 | top1 59.00% | top3 79.38% | top5 86.46%\n",
            "Best saved to best_maxout_medium.pt (val top1 59.00%)\n",
            "Epoch time: 6.28 min\n",
            "\n",
            "=== Epoch 10/50 ===\n",
            "[train step 100/352] loss 1.8581 | top1 57.03% | top3 77.27% | top5 83.52% | 124.1 img/s | lr 4.75e-04\n",
            "[train step 200/352] loss 1.9676 | top1 55.17% | top3 74.93% | top5 81.55% | 124.1 img/s | lr 4.73e-04\n",
            "[train step 300/352] loss 1.9823 | top1 55.11% | top3 74.75% | top5 81.53% | 124.2 img/s | lr 4.71e-04\n",
            "[Train] loss 1.9929 | top1 54.99% | top3 74.55% | top5 81.42% | lr 4.70e-04\n",
            "[Val]   loss 1.4354 | top1 61.54% | top3 80.80% | top5 87.46%\n",
            "Best saved to best_maxout_medium.pt (val top1 61.54%)\n",
            "Epoch time: 6.29 min\n",
            "\n",
            "=== Epoch 11/50 ===\n",
            "[train step 100/352] loss 1.9344 | top1 57.34% | top3 77.02% | top5 83.65% | 124.1 img/s | lr 4.68e-04\n",
            "[train step 200/352] loss 1.8634 | top1 58.38% | top3 77.76% | top5 84.16% | 124.3 img/s | lr 4.65e-04\n",
            "[train step 300/352] loss 1.9139 | top1 57.36% | top3 76.61% | top5 83.23% | 124.3 img/s | lr 4.63e-04\n",
            "[Train] loss 1.9122 | top1 57.27% | top3 76.63% | top5 83.13% | lr 4.62e-04\n",
            "[Val]   loss 1.3606 | top1 63.28% | top3 82.72% | top5 88.94%\n",
            "Best saved to best_maxout_medium.pt (val top1 63.28%)\n",
            "Epoch time: 6.29 min\n",
            "\n",
            "=== Epoch 12/50 ===\n",
            "[train step 100/352] loss 1.7725 | top1 61.30% | top3 79.74% | top5 85.98% | 124.1 img/s | lr 4.59e-04\n",
            "[train step 200/352] loss 1.8422 | top1 59.66% | top3 78.14% | top5 84.52% | 124.3 img/s | lr 4.56e-04\n",
            "[train step 300/352] loss 1.8640 | top1 59.47% | top3 78.38% | top5 84.65% | 124.3 img/s | lr 4.54e-04\n",
            "[Train] loss 1.8735 | top1 59.20% | top3 78.15% | top5 84.44% | lr 4.52e-04\n",
            "[Val]   loss 1.3538 | top1 63.10% | top3 82.78% | top5 88.92%\n",
            "Epoch time: 6.28 min\n",
            "\n",
            "=== Epoch 13/50 ===\n",
            "[train step 100/352] loss 1.6372 | top1 62.61% | top3 81.23% | top5 87.07% | 124.3 img/s | lr 4.50e-04\n",
            "[train step 200/352] loss 1.7869 | top1 59.89% | top3 78.52% | top5 84.88% | 124.3 img/s | lr 4.47e-04\n",
            "[train step 300/352] loss 1.8104 | top1 59.94% | top3 78.59% | top5 84.92% | 124.3 img/s | lr 4.44e-04\n",
            "[Train] loss 1.8093 | top1 60.15% | top3 78.78% | top5 85.15% | lr 4.42e-04\n",
            "[Val]   loss 1.2943 | top1 64.20% | top3 83.90% | top5 89.48%\n",
            "Best saved to best_maxout_medium.pt (val top1 64.20%)\n",
            "Epoch time: 6.29 min\n",
            "\n",
            "=== Epoch 14/50 ===\n",
            "[train step 100/352] loss 1.8028 | top1 61.98% | top3 80.66% | top5 86.74% | 124.0 img/s | lr 4.39e-04\n",
            "[train step 200/352] loss 1.7823 | top1 62.16% | top3 80.48% | top5 86.50% | 124.1 img/s | lr 4.36e-04\n",
            "[train step 300/352] loss 1.7811 | top1 61.92% | top3 80.32% | top5 86.38% | 124.2 img/s | lr 4.33e-04\n",
            "[Train] loss 1.7537 | top1 62.16% | top3 80.38% | top5 86.39% | lr 4.31e-04\n",
            "[Val]   loss 1.2579 | top1 65.70% | top3 84.02% | top5 89.70%\n",
            "Best saved to best_maxout_medium.pt (val top1 65.70%)\n",
            "Epoch time: 6.29 min\n",
            "\n",
            "=== Epoch 15/50 ===\n",
            "[train step 100/352] loss 1.5372 | top1 66.00% | top3 82.76% | top5 88.27% | 124.2 img/s | lr 4.28e-04\n",
            "[train step 200/352] loss 1.5850 | top1 65.61% | top3 82.88% | top5 88.23% | 124.6 img/s | lr 4.25e-04\n",
            "[train step 300/352] loss 1.6055 | top1 65.19% | top3 82.56% | top5 87.94% | 124.6 img/s | lr 4.21e-04\n",
            "[Train] loss 1.6077 | top1 65.16% | top3 82.58% | top5 87.87% | lr 4.19e-04\n",
            "[Val]   loss 1.2226 | top1 65.78% | top3 84.84% | top5 90.36%\n",
            "Best saved to best_maxout_medium.pt (val top1 65.78%)\n",
            "Epoch time: 6.28 min\n",
            "\n",
            "=== Epoch 16/50 ===\n",
            "[train step 100/352] loss 1.6648 | top1 63.43% | top3 81.03% | top5 86.47% | 124.2 img/s | lr 4.16e-04\n",
            "[train step 200/352] loss 1.6859 | top1 63.93% | top3 81.59% | top5 86.95% | 124.4 img/s | lr 4.12e-04\n",
            "[train step 300/352] loss 1.6816 | top1 64.15% | top3 81.93% | top5 87.23% | 124.6 img/s | lr 4.09e-04\n",
            "[Train] loss 1.6802 | top1 63.98% | top3 81.70% | top5 87.12% | lr 4.07e-04\n",
            "[Val]   loss 1.1720 | top1 67.86% | top3 85.88% | top5 91.18%\n",
            "Best saved to best_maxout_medium.pt (val top1 67.86%)\n",
            "Epoch time: 6.27 min\n",
            "\n",
            "=== Epoch 17/50 ===\n",
            "[train step 100/352] loss 1.6380 | top1 64.52% | top3 81.57% | top5 86.95% | 124.3 img/s | lr 4.03e-04\n",
            "[train step 200/352] loss 1.6800 | top1 64.12% | top3 81.31% | top5 86.81% | 124.4 img/s | lr 4.00e-04\n",
            "[train step 300/352] loss 1.6059 | top1 65.50% | top3 82.45% | top5 87.69% | 124.5 img/s | lr 3.96e-04\n",
            "[Train] loss 1.6026 | top1 65.51% | top3 82.32% | top5 87.61% | lr 3.94e-04\n",
            "[Val]   loss 1.1343 | top1 68.84% | top3 86.06% | top5 91.66%\n",
            "Best saved to best_maxout_medium.pt (val top1 68.84%)\n",
            "Epoch time: 6.28 min\n",
            "\n",
            "=== Epoch 18/50 ===\n",
            "[train step 100/352] loss 1.5897 | top1 67.96% | top3 83.98% | top5 88.92% | 124.2 img/s | lr 3.90e-04\n",
            "[train step 200/352] loss 1.6115 | top1 67.04% | top3 83.49% | top5 88.61% | 124.4 img/s | lr 3.86e-04\n",
            "[train step 300/352] loss 1.5818 | top1 67.35% | top3 84.00% | top5 88.99% | 124.5 img/s | lr 3.82e-04\n",
            "[Train] loss 1.5868 | top1 66.94% | top3 83.66% | top5 88.66% | lr 3.80e-04\n",
            "[Val]   loss 1.0996 | top1 69.46% | top3 87.06% | top5 92.12%\n",
            "Best saved to best_maxout_medium.pt (val top1 69.46%)\n",
            "Epoch time: 6.28 min\n",
            "\n",
            "=== Epoch 19/50 ===\n",
            "[train step 100/352] loss 1.4447 | top1 71.78% | top3 87.24% | top5 91.46% | 124.6 img/s | lr 3.76e-04\n",
            "[train step 200/352] loss 1.5354 | top1 68.95% | top3 85.09% | top5 89.68% | 124.7 img/s | lr 3.72e-04\n",
            "[train step 300/352] loss 1.5625 | top1 68.02% | top3 84.28% | top5 89.11% | 124.8 img/s | lr 3.68e-04\n",
            "[Train] loss 1.5531 | top1 68.30% | top3 84.59% | top5 89.35% | lr 3.66e-04\n",
            "[Val]   loss 1.0790 | top1 70.46% | top3 87.12% | top5 91.86%\n",
            "Best saved to best_maxout_medium.pt (val top1 70.46%)\n",
            "Epoch time: 6.26 min\n",
            "\n",
            "=== Epoch 20/50 ===\n",
            "[train step 100/352] loss 1.3439 | top1 70.69% | top3 85.73% | top5 90.02% | 124.1 img/s | lr 3.61e-04\n",
            "[train step 200/352] loss 1.4315 | top1 70.48% | top3 85.94% | top5 90.29% | 124.4 img/s | lr 3.57e-04\n",
            "[train step 300/352] loss 1.3837 | top1 71.07% | top3 86.35% | top5 90.62% | 124.4 img/s | lr 3.53e-04\n",
            "[Train] loss 1.4216 | top1 70.36% | top3 85.79% | top5 90.18% | lr 3.51e-04\n",
            "[Val]   loss 1.0720 | top1 70.24% | top3 87.06% | top5 92.14%\n",
            "Epoch time: 6.27 min\n",
            "\n",
            "=== Epoch 21/50 ===\n",
            "[train step 100/352] loss 1.4903 | top1 69.37% | top3 84.76% | top5 89.58% | 124.3 img/s | lr 3.46e-04\n",
            "[train step 200/352] loss 1.4560 | top1 70.06% | top3 85.38% | top5 90.04% | 124.5 img/s | lr 3.42e-04\n",
            "[train step 300/352] loss 1.4663 | top1 70.02% | top3 85.44% | top5 90.08% | 124.5 img/s | lr 3.38e-04\n",
            "[Train] loss 1.4493 | top1 69.98% | top3 85.37% | top5 90.01% | lr 3.35e-04\n",
            "[Val]   loss 1.0318 | top1 70.94% | top3 88.38% | top5 92.40%\n",
            "Best saved to best_maxout_medium.pt (val top1 70.94%)\n",
            "Epoch time: 6.28 min\n",
            "\n",
            "=== Epoch 22/50 ===\n",
            "[train step 100/352] loss 1.4238 | top1 71.01% | top3 85.85% | top5 90.24% | 124.2 img/s | lr 3.31e-04\n",
            "[train step 200/352] loss 1.4374 | top1 70.25% | top3 85.29% | top5 89.91% | 124.5 img/s | lr 3.27e-04\n",
            "[train step 300/352] loss 1.4240 | top1 70.76% | top3 85.65% | top5 90.13% | 124.6 img/s | lr 3.22e-04\n",
            "[Train] loss 1.4323 | top1 70.70% | top3 85.65% | top5 90.18% | lr 3.20e-04\n",
            "[Val]   loss 1.0553 | top1 71.14% | top3 87.56% | top5 92.26%\n",
            "Best saved to best_maxout_medium.pt (val top1 71.14%)\n",
            "Epoch time: 6.27 min\n",
            "\n",
            "=== Epoch 23/50 ===\n",
            "[train step 100/352] loss 1.2418 | top1 74.09% | top3 88.05% | top5 91.87% | 124.0 img/s | lr 3.15e-04\n",
            "[train step 200/352] loss 1.3144 | top1 72.97% | top3 87.30% | top5 91.36% | 124.3 img/s | lr 3.11e-04\n",
            "[train step 300/352] loss 1.2780 | top1 74.12% | top3 88.16% | top5 92.05% | 124.3 img/s | lr 3.06e-04\n",
            "[Train] loss 1.3024 | top1 73.51% | top3 87.75% | top5 91.72% | lr 3.04e-04\n",
            "[Val]   loss 1.0641 | top1 71.90% | top3 87.64% | top5 92.10%\n",
            "Best saved to best_maxout_medium.pt (val top1 71.90%)\n",
            "Epoch time: 6.29 min\n",
            "\n",
            "=== Epoch 24/50 ===\n",
            "[train step 100/352] loss 1.2293 | top1 76.10% | top3 89.88% | top5 93.32% | 123.9 img/s | lr 2.99e-04\n",
            "[train step 200/352] loss 1.2360 | top1 75.21% | top3 89.18% | top5 92.77% | 124.2 img/s | lr 2.95e-04\n",
            "[train step 300/352] loss 1.2532 | top1 74.86% | top3 88.95% | top5 92.61% | 124.4 img/s | lr 2.90e-04\n",
            "[Train] loss 1.2577 | top1 74.67% | top3 88.72% | top5 92.42% | lr 2.87e-04\n",
            "[Val]   loss 0.9797 | top1 72.44% | top3 88.66% | top5 93.24%\n",
            "Best saved to best_maxout_medium.pt (val top1 72.44%)\n",
            "Epoch time: 6.28 min\n",
            "\n",
            "=== Epoch 25/50 ===\n",
            "[train step 100/352] loss 1.3451 | top1 74.61% | top3 87.83% | top5 91.61% | 124.2 img/s | lr 2.83e-04\n",
            "[train step 200/352] loss 1.2477 | top1 76.68% | top3 89.64% | top5 93.00% | 124.3 img/s | lr 2.78e-04\n",
            "[train step 300/352] loss 1.2304 | top1 76.65% | top3 89.80% | top5 93.12% | 124.4 img/s | lr 2.74e-04\n",
            "[Train] loss 1.2666 | top1 75.66% | top3 89.07% | top5 92.64% | lr 2.71e-04\n",
            "[Val]   loss 1.0109 | top1 72.40% | top3 89.08% | top5 93.38%\n",
            "Epoch time: 6.27 min\n",
            "\n",
            "=== Epoch 26/50 ===\n",
            "[train step 100/352] loss 1.1214 | top1 77.27% | top3 89.31% | top5 92.75% | 124.0 img/s | lr 2.66e-04\n",
            "[train step 200/352] loss 1.1939 | top1 75.91% | top3 88.72% | top5 92.40% | 124.4 img/s | lr 2.62e-04\n",
            "[train step 300/352] loss 1.2553 | top1 74.86% | top3 88.18% | top5 91.97% | 124.5 img/s | lr 2.57e-04\n",
            "[Train] loss 1.2955 | top1 74.40% | top3 87.88% | top5 91.79% | lr 2.55e-04\n",
            "[Val]   loss 0.9700 | top1 73.10% | top3 89.00% | top5 93.40%\n",
            "Best saved to best_maxout_medium.pt (val top1 73.10%)\n",
            "Epoch time: 6.27 min\n",
            "\n",
            "=== Epoch 27/50 ===\n",
            "[train step 100/352] loss 1.2731 | top1 77.83% | top3 90.51% | top5 94.03% | 124.2 img/s | lr 2.50e-04\n",
            "[train step 200/352] loss 1.2973 | top1 76.22% | top3 89.25% | top5 93.00% | 124.2 img/s | lr 2.45e-04\n",
            "[train step 300/352] loss 1.2550 | top1 76.01% | top3 88.94% | top5 92.66% | 124.4 img/s | lr 2.41e-04\n",
            "[Train] loss 1.2712 | top1 75.55% | top3 88.62% | top5 92.40% | lr 2.38e-04\n",
            "[Val]   loss 0.9285 | top1 73.50% | top3 89.40% | top5 93.76%\n",
            "Best saved to best_maxout_medium.pt (val top1 73.50%)\n",
            "Epoch time: 6.28 min\n",
            "\n",
            "=== Epoch 28/50 ===\n",
            "[train step 100/352] loss 0.9674 | top1 80.22% | top3 91.04% | top5 93.98% | 124.2 img/s | lr 2.33e-04\n",
            "[train step 200/352] loss 1.0958 | top1 78.81% | top3 90.63% | top5 93.68% | 124.2 img/s | lr 2.29e-04\n",
            "[train step 300/352] loss 1.1269 | top1 78.37% | top3 90.26% | top5 93.44% | 124.4 img/s | lr 2.24e-04\n",
            "[Train] loss 1.1593 | top1 77.67% | top3 89.82% | top5 93.10% | lr 2.22e-04\n",
            "[Val]   loss 0.9325 | top1 73.64% | top3 89.58% | top5 93.68%\n",
            "Best saved to best_maxout_medium.pt (val top1 73.64%)\n",
            "Epoch time: 6.28 min\n",
            "\n",
            "=== Epoch 29/50 ===\n",
            "[train step 100/352] loss 1.2889 | top1 75.85% | top3 88.86% | top5 92.51% | 124.7 img/s | lr 2.17e-04\n",
            "[train step 200/352] loss 1.2546 | top1 76.38% | top3 89.18% | top5 92.80% | 124.8 img/s | lr 2.12e-04\n",
            "[train step 300/352] loss 1.2349 | top1 76.81% | top3 89.45% | top5 93.01% | 124.8 img/s | lr 2.08e-04\n",
            "[Train] loss 1.2314 | top1 77.06% | top3 89.52% | top5 93.02% | lr 2.05e-04\n",
            "[Val]   loss 0.9168 | top1 74.78% | top3 90.08% | top5 93.72%\n",
            "Best saved to best_maxout_medium.pt (val top1 74.78%)\n",
            "Epoch time: 6.26 min\n",
            "\n",
            "=== Epoch 30/50 ===\n"
          ]
        }
      ],
      "source": [
        "def cifar64_stages_t4_tinyplus(drop_path=0.08):\n",
        "    # resoluciones: 64 -> 32 -> 16 -> 8\n",
        "    return [\n",
        "        StageCfg(dim=64,  depth=2, num_heads=2,  grid_size=8, outlook_heads=2,  drop_path=drop_path),\n",
        "        StageCfg(dim=128, depth=2, num_heads=4,  grid_size=8, outlook_heads=4,  drop_path=drop_path),\n",
        "        StageCfg(dim=256, depth=3, num_heads=8,  grid_size=4, outlook_heads=8,  drop_path=drop_path),\n",
        "        StageCfg(dim=384, depth=1, num_heads=6,  grid_size=2, outlook_heads=6,  drop_path=drop_path),\n",
        "    ]\n",
        "\n",
        "stages = cifar64_stages_t4_tinyplus()\n",
        "model = OutlookerFrontGridNet(num_classes=100, stages=stages, stem_dim=64, outlooker_front_depth=1, dpr_max=0.1)\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "history, model = train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    epochs=50,\n",
        "    val_loader=val_loader,\n",
        "    device=device,\n",
        "\n",
        "    lr=5e-4,\n",
        "    weight_decay=0.05,\n",
        "\n",
        "    autocast_dtype=\"fp16\" if device == \"cuda\" else \"fp32\",\n",
        "    use_amp=(device == \"cuda\"),\n",
        "    grad_clip_norm=1.0,\n",
        "\n",
        "    warmup_ratio=0.05,\n",
        "    min_lr=1e-6,\n",
        "\n",
        "    label_smoothing=0.0,\n",
        "\n",
        "    print_every=100,\n",
        "    save_path=\"best_maxout_medium.pt\",\n",
        "    last_path=\"last_maxout_medium.pt\",\n",
        "    resume_path=None,\n",
        "\n",
        "    # Augmentations\n",
        "    mix_prob=0.5,\n",
        "    mixup_alpha=0.0,\n",
        "    cutmix_alpha=1.0,\n",
        "\n",
        "    num_classes=100,\n",
        "    channels_last=True)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
