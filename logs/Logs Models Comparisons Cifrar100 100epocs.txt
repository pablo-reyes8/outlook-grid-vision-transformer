ALL THE MODELS ARE TRAINED WITH THIS COFIG: 


=== Run config ===
device=cuda | amp=True | autocast_dtype=fp16 | channels_last=True
epochs=100 | steps/epoch=704 | total_steps=70400 | warmup_steps=3520
batch_size=64 | input_shape=(64, 3, 32, 32) | num_classes=100
opt=AdamW | lr=0.0005 | wd=0.05 | grad_clip_norm=1.0
aug: mix_prob=0.5 | mixup_alpha=0.8 | cutmix_alpha=1.0 | label_smoothing=0.1


history, _ = train_model(
        model=model,
        train_loader=train loader,
        epochs=100,
        val_loader=val_loader,
        device=device,

        lr=5e-4,
        weight_decay=0.05,

        # Mixed Precision
        autocast_dtype="fp16" if device == "cuda" else "fp32",
        use_amp=(device == "cuda"),
        grad_clip_norm=1.0,

        warmup_ratio=0.05,
        min_lr=1e-6,

        label_smoothing=0.1,

        print_every=400,
        mix_prob=0.5,
        mixup_alpha=0.8,
        cutmix_alpha=1.0,

        num_classes=100,
        channels_last=True)


--------------------------------- OutGrid (OURS) ---------------------------------

Trainable parameters: 7,518,102


loss: 0.75493
top1: 79.72 | top3: 92.29 | top5: 95.1
throughput: 1131.8 imgs/s | epoch: 8.84s | ms/batch: 49.98
GPU mem: alloc=281 MiB | reserved=2228 MiB | peak=485 MiB
model: params=7,518,102 | param_size=28.7 MiB
Compute (per forward): 448.02 MFLOPs | 224.01 MMACs




--------------------------------- CONVEXT ---------------------------------

model_convnext_tiny = timm.create_model(
    "convnext_tiny",
    pretrained=False,
    num_classes=100)

model_convnext_tiny.stem[0] = nn.Conv2d(
    in_channels=3, 
    out_channels=96, 
    kernel_size=2, 
    stride=2, 
    padding=0)


Trainable parameters: 27,893,572

loss: 1.1613
top1: 72.60 | top3: 86.71 | top5: 90.92
throughput: 1832.8 imgs/s | epoch: 5.46s | ms/batch: 34.26
model: params=27,895,012 | param_size=106.4 MiB
Compute (per forward): 364.07 MFLOPs | 182.03 MMACs


--------------------------------- Deit_Nano ---------------------------------

Trainable parameters: 5,380,132

model_vit1 = timm.create_model(
    "deit_tiny_patch16_224",
    pretrained=False,
    num_classes=100,
    img_size=32,
    patch_size=4).to(device)

loss: 1.4651
top1: 63.77 | top3: 80.55 | top5: 85.93
throughput: 5077.2 imgs/s | epoch: 1.97s | ms/batch: 10.60
model: params=5,380,132 | param_size=20.5 MiB
Compute (per forward): 347.22 MFLOPs | 173.61 MMACs


--------------------------------- Deit_Tiny ---------------------------------

Trainable parameters: 21,376,996


model_vit_small = timm.create_model(
    "deit_small_patch16_224",
    pretrained=False,
    num_classes=100,
    img_size=32,
    patch_size=4  
).to(device)


loss: 1.6656
top1: 59.00 | top3: 76.31 | top5: 82.59
throughput: 3432.9 imgs/s | epoch: 2.91s | ms/batch: 17.68
model: params=21,376,996 | param_size=81.5 MiB
Compute (per forward): 1.38 GFLOPs | 692.26 MMACs


--------------------------------- efficientnetv2_small ---------------------------------

Trainable parameters: 20,305,588

model_v2_s = timm.create_model("efficientnetv2_s", pretrained=False, num_classes=100)
out_channels = model_v2_s.conv_stem.out_channels

model_v2_s.conv_stem = nn.Conv2d(
    in_channels=3, 
    out_channels=out_channels, 
    kernel_size=3, 
    stride=1,      
    padding=1, 
    bias=False)


loss: 1.3438
top1: 64.62 | top3: 82.81 | top5: 88.10
throughput: 2099.3 imgs/s | epoch: 4.76s | ms/batch: 28.75
model: params=20,305,588 | param_size=77.5 MiB
Compute (per forward): 238.02 MFLOPs | 119.01 MMACs


--------------------------------- MaxVit_Nano  ---------------------------------

MaxViT-Nano Surgery Successful. Params: 17.38M

model_maxvit_nano = timm.create_model(
    "maxvit_tiny_tf_224",
    pretrained=False,
    num_classes=100,
    img_size=32,
    embed_dim=[64, 96, 192, 384] )

model_maxvit_nano.stem.conv1 = nn.Conv2d(
    in_channels=3, 
    out_channels=64, 
    kernel_size=3, 
    stride=1, 
    padding=1, 
    bias=False)


model_maxvit_nano.stem.norm1 = nn.BatchNorm2d(
    num_features=64, 
    eps=1e-3,    
    momentum=0.1)

model_maxvit_nano.stem.conv2 = nn.Conv2d(
    in_channels=64, 
    out_channels=64, 
    kernel_size=3, 
    stride=1, 
    padding=1, 
    bias=False)

model_maxvit_nano = model_maxvit_nano.to(device)

loss: 0.9906
top1: 75.41 | top3: 88.87 | top5: 92.34
throughput: 1253.9 imgs/s | epoch: 7.97s | ms/batch: 45.15
model: params=17,379,140 | param_size=66.3 MiB
Compute (per forward): 305.58 MFLOPs | 152.79 MMACs


--------------------------------- MaxVit_Tiny ---------------------------------

MaxViT-Tiny Trainable parameters: 30.43M

model_maxvit = timm.create_model(
    "maxvit_tiny_tf_224",
    pretrained=False,
    num_classes=100,
    img_size=32)

in_ch_1 = model_maxvit.stem.conv1.in_channels
out_ch_1 = model_maxvit.stem.conv1.out_channels
model_maxvit.stem.conv1 = nn.Conv2d(
    in_ch_1, out_ch_1, kernel_size=3, stride=1, padding=1, bias=False)

in_ch_2 = model_maxvit.stem.conv2.in_channels
out_ch_2 = model_maxvit.stem.conv2.out_channels
model_maxvit.stem.conv2 = nn.Conv2d(
    in_ch_2, out_ch_2, kernel_size=3, stride=1, padding=1, bias=False)


model_maxvit = model_maxvit.to('cuda')


loss: 0.9566
top1: 75.90 | top3: 89.50 | top5: 92.78
throughput: 980.4 imgs/s | epoch: 10.20s | ms/batch: 57.23
model: params=30,426,476 | param_size=116.1 MiB
Compute (per forward): 443.91 MFLOPs | 221.96 MMACs


--------------------------------- Resnet18  ---------------------------------


Trainable parameters: 11,220,132


model = timm.create_model("resnet18", pretrained=False, num_classes=100).to(device)

model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
model.maxpool = nn.Identity()


top1: 73.25 | top3: 88.25 | top5: 91.96
throughput: 5393.2 imgs/s | epoch: 1.85s | ms/batch: 8.33
model: params=11,220,132 | param_size=42.8 MiB
Compute (per forward): 556.71 MFLOPs | 278.35 MMACs


--------------------------------- Resnet50  ---------------------------------


Trainable parameters: 23,712,932



model_resnet50 = timm.create_model(
    "resnet50",
    pretrained=False,
    num_classes=100).to(device)

model_resnet50.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
model_resnet50.maxpool = nn.Identity()


loss: 0.8587
top1: 77.42 | top3: 90.70 | top5: 93.94
throughput: 1918.7 imgs/s | epoch: 5.21s | ms/batch: 29.72
model: params=23,705,252 | param_size=90.4 MiB
Compute (per forward): 1.30 GFLOPs | 652.46 MMACs


--------------------------------- SwinVit  ---------------------------------

Trainable parameters: 27,571,054



model_vit3 = timm.create_model(
    "swin_tiny_patch4_window7_224",
    pretrained=False,
    num_classes=100,
    img_size=32,
    window_size=4)

current_dim = model_vit3.patch_embed.proj.out_channels

model_vit3.patch_embed.proj = nn.Conv2d(
    in_channels=3, 
    out_channels=current_dim, 
    kernel_size=2, 
    stride=2)

model_vit3.patch_embed.patch_size = (2, 2)
model_vit3 = model_vit3.to(device)


loss: 1.5384
top1: 59.89 | top3: 78.55 | top5: 84.57
throughput: 3360.6 imgs/s | epoch: 2.98s | ms/batch: 17.50
model: params=27,571,054 | param_size=105.2 MiB
Compute (per forward): 358.45 MFLOPs | 179.23 MMACs